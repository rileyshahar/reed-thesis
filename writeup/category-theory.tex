% vim:ft=tex

The notion of a \emph{category}, originally developed as an abstraction for
certain ideas in pure mathematics, turns out to be the natural algebraic
axiomatization of a collection of strongly typed, composable processes, such as
functions in a strongly typed programming language. More philosophically, we can
think of a category as an \emph{algebra of composition}, and category theory as
the mathematical study of composition. In this chapter, we will
develop the basic theory of categories, prioritizing examples from computer
science where possible.

Basic texts on category theory include \cite{maclane-1971} and
\cite{riehl-2017}, while the connection to computer science is explored
in~\cite{pierce-1991} and~\cite{barr-wells-1990}. A more advanced treatment of
the connection, especially applications to programming language theory,
is~\cite{jacobs-1999}.

\section{Basic Notions}

\subsection{Categories}

\begin{dfn}[category]\label{def:category}
	A \emph{category} $\cat{C}$ consists of the following data:
	\begin{itemize}
		\item a collection\footnote{We use the word \emph{collection} for foundational reasons: in
			      many important examples, the objects and morphisms do not form sets. We ignore
			      such foundational issues here; they are discussed in~\cite[subsection
				      1.6]{maclane-1971}.} of objects, overloadingly also called $\cat{C}$;
		\item for each pair of objects $x,y \in  \cat{C}$, a collection of \emph{morphisms} $\cat{C}(x, y)$;
		\item for each object $x \in \cat{C}$, a designated \emph{identity morphism} $x \xrightarrow{1_x}  x$;
		\item for each pair of morphisms $x \xrightarrow{f}  y \xrightarrow{g}  z$, a designated \emph{composite morphism} $x \xrightarrow{gf}  z$.
	\end{itemize}
	This data must satisfy the following axioms:
	\begin{itemize}
		\item \emph{unitality}: for any $x \xrightarrow{f}  y$, $1_yf = f = f1_x$;
		\item \emph{associativity}: for any $x \xrightarrow{f} 		y \xrightarrow{g} z \xrightarrow{h} w$, $(hg)f = h(gf)$.
	\end{itemize}
\end{dfn}

\begin{ntn}
  In addition to those used above, many syntaxes are common in the literature for basic
  categorical notions. For convenience, we survey some here, though we will try
  to be consistent in our notation.\begin{itemize}
    \item A morphism $f\in\cat{C}(x, y)$ is often written $f\colon x\to y$ or $x\xto{f} y$; $x$ is
      called its \emph{domain} or \emph{source} and $y$ is called it \emph{codomain}
      or \emph{target}.
    \item Morphisms may be called maps, arrows, or homomorphisms; the class of morphisms $\cat{C}(x, y)$ may also be written
      $\Hom_{\cat{C}}(x, y)$ or just $\Hom(x, y)$, and is often called a \emph{hom-set}.
    \item Composition is written $gf$ or $g\circ f$; in the literature it is
      sometimes written in the left-to-right order $fg$; we will never do this.
    \item Identities are written $1_x$, $\id_x$, or just $x$ where the context
      is clear; we will never do the latter.
    \end{itemize}
\end{ntn}

\begin{ex}[functional programming languages]\label{ex:functional programming}
  Consider some strongly-typed functional programming language $L$, whose functions
  are never side-effecting. Then under very modest assumptions about $L$, we
  can make a category $\cat{L}$, as follows:
  \begin{itemize}
    \item the objects of $\cat{L}$ are the types of $L$;
    \item the morphisms $\cat{L}(A, B)$ are the functions of type $A\to B$;
    \item the identities $1_A$ are the identity functions $A\to A$;
    \item composition of morphisms are the usual function composition.
  \end{itemize}

  If $L$ is truly non-side-effecting, then it's straightforward to check
  that this construction does indeed satisfy the axioms of a category; see for
  instance~\cite[subsection 2.2]{barr-wells-1990} to see the necessary assumptions
  spelled out rigorously.
\end{ex}

\noindent
Categories are also widespread in mathematics, as the following examples show.

\begin{ex}[concrete categories]\label{ex:concrete categories}The following are all categories:
	\begin{itemize}
		\item $\scat{Set}$ is the category of sets and functions.
		\item $\scat{Grp}$ is the category of groups and group homomorphisms.
		\item $\scat{Ring}$ is the category of rings and ring homomorphisms.
		\item $\scat{Top}$ is the category of topological spaces and homeomorphisms.
		\item For any field $\kk$, $\scat{Vect}_\kk$ is the category of vector
		      spaces over $\kk$ and linear transformations.
	\end{itemize}
\end{ex}

\noindent
We call such categories, whose objects are structured sets and whose morphisms
are structure-preserving set-functions, \emph{concrete}. On the other hand, many
categories look quite different.

\begin{ex}\label{ex:abstract categories}The following are also categories:
	\begin{itemize}
		\item The \emph{empty category} has no objects and no morphisms.
		\item The \emph{trivial category} has a single object and its identity morphism.
		\item Any group (or, more generally, monoid) can be thought of as a category
		      with a single object, a morphism for every element, and composition
		      given by the monoid multiplication.
		\item Any poset (or, more generally, preorder) $(P, \leq)$ can be thought
		      of as a category whose objects are the elements of $P$, with a unique
		      morphism $x\rightarrow y$ if and only if $x\leq y$. In this sense,
		      composition is a ``higher-dimensional'' transitivity, and identities are
		      higher-dimensional reflexivity.
		      % This higher dimensional stuff is cool and it's how I think about these
		      % objects, but probably not necessary for our purposes. --riley
		\item Associated to any directed graph is the \emph{free category} on the
		      graph, whose objects are nodes and whose morphisms are paths. In
          particular, the identities are just the empty paths, while composition
          concatenates two paths.
    \item Let $M = (Q, \delta)$ be an automaton over an alphabet $\Sigma$, so
          that $\delta: Q\times \Sigma\to Q$ is a transition function (one may
          replace $Q$ with $\cP(Q)$ in the codomain to represent a nondeterministic
          automaton). There is an associated category $\cM$ whose objects are
          exactly the states and whose morphisms $\cM(q_1, q_2)$ are the words
          $w\in\Sigma^*$ such that, if $M$ is in the state $q_1$ and receives $w$ as
          input, it ends in the state $q_2$. The identity morphism $1_q$ is the
          empty word, and composition is concatenation of words\footnote{I believe
          this example is due to~\cite[Example 2.2]{goguen-et-al-1973}.}.
		\item There is a category whose objects are (roughly) multisets of molecules
		      and whose morphisms are chemical reactions. See \cite{baez-2017} for a
		      formalization of this notion.
	\end{itemize}
\end{ex}

% One more example will be critical for our purposes.

% \begin{ex}[Categories of $\mathbb{A}$-computable maps]\label{ex:categories of computable maps}
%   Let $\mathbb{A}$ be a class of algorithms which is closed under composition.
%   Then we can define a category whose objects are finite sets and whose
%   morphisms are the $\mathbb{A}$-computable maps between them.
%   The most important examples for our purposes are: \begin{itemize}
%     \item the category $\scat{Poly}$ of finite sets and polynomial-time
%       computable maps;
%     \item the category $\scat{PPT}$ of finite sets and probabilistic
%       polynomial-time computable stochastic maps;
%     \item the category $\scat{NUPPT}$ of finite sets and non-uniform
%       probabilistic polynomial-time computable stochastic maps.
%   \end{itemize}
% \end{ex}

\noindent
When working with categories, we often want to show that two complex composites
of morphisms equate. In this case, we prefer graphical notation to the more
traditional symbolic equalities of
\Cref{def:category}. A diagram in a category
$\cat{C}$ looks something like so\footnote{
  The notion of a diagram can be made precise fairly easily; see~\cite[subsection 1.6]{riehl-2017}.
}:
\[
  \begin{tikzcd}
    w\ar[r, "f"]\ar[d, "h"'] & x\ar[d, "g"] \\
    y\ar[r, "k"'] & z\punctuation{.}
  \end{tikzcd}
\]

This diagram identifies four objects $w,x,y,z\in\cat{C}$, and four morphisms
$f\in\cat{C}(w, x)$, $g\in\cat{C}(x, z)$, $h\in\cat{C}(w, y)$, and
$k\in\cat{C}(y, z)$.

We say that a diagram \emph{commutes} if, for any pair of paths
through the diagram with the same start and end, the composite morphisms are
equal. In this language, the previous diagram commutes if and only if $gf = kh$.

\begin{ex}
	The axioms of \Cref{def:category} are expressed by commutativity of the
	following three diagrams:
  \[
		\begin{tikzcd}
			x\ar[r, "f"]\ar[rr, "gf", bend left=60] &
			y\ar[r, "g"]\ar[rr, "hg"', bend right=60] &
			z\ar[r, "h"] & w
		\end{tikzcd}
		\begin{tikzcd}
			x\ar[r, "1_x"]\ar[rd, "f"'] & x\ar[d, "f"] \\
			& y
		\end{tikzcd}
		\begin{tikzcd}
			x\ar[r, "f"]\ar[rd, "f"'] & y\ar[d, "1_y"] \\
			& y\punctuation{.}
		\end{tikzcd}
  \]
\end{ex}

The key idea is that commutative diagrams
can be ``pasted'', allowing us to build up complex equalities from simpler ones.
For instance, if
\[
  \begin{tikzcd}
    w\ar[r, "f"]\ar[d, "h"'] & x\ar[d, "g"] \\
    y\ar[r, "k"'] & z
  \end{tikzcd}\quad
  \text{and}\quad
  \begin{tikzcd}
    x\ar[r, "l"]\ar[rd, "g"'] & v\ar[d, "m"] \\
    & z
  \end{tikzcd}
\] both commute, then by pasting along the shared morphism $g$, so does
\[
  \begin{tikzcd}
    w\ar[r, "f"]\ar[d, "h"'] & x\ar[r, "l"] & v\ar[d, "m"] \\
    y\ar[rr, "k"'] && z\punctuation{.}
  \end{tikzcd}
\]

Note that, in order for these diagrams to be well-defined, we need composition
to be associative: otherwise the top-right path of the previous diagram would be
ambiguous. In some sense, the algebraic axioms are chosen exactly so that the
diagrammatic calculus is coherent. This will be a repeated theme for us.

Regardless, this pasting property is essentially just a re-expression of the
transitivity and substitution properties of equality, but gives an
extraordinarily useful geometric intuition to categorical arguments.

\subsection{(Iso)morphisms}

The philosophy of category theory is that \begin{center}
  \emph{to study an object, one should study its morphisms.}
\end{center}
Indeed, in every category, morphisms give enough information
to recover the data of an object.

\begin{ex}\label{ex:recovering structure} In the following categories, we can
  reconstruct an object by ``probing'' it with morphisms from suitable choices
  of other objects.
  \begin{itemize}
    \item Let $X$ be a set. A function $f: \{*\}\to X$ is exactly a choice of
      $f(*)\in X$, so the morphisms $\scat{Set}(\{*\}, X)$ identify exactly the
      elements of $X$, i.e. the entire data of a set.
    \item Let $X$ be a topological space. A continuous map $f: \{*\}\to X$ picks
      out the points of $X$, as before. Let $S = \{0, 1\}$, with $\{1\}$ open;
      this is the \emph{Sierpinski space}. Then a continuous map $f: X\to S$
      consists of a choice of open set $f^{-1}(1)\subseteq X$, so the morphisms
      $\scat{Top}(X, S)$ identify exactly the open sets of $X$. Together with
      the points, this is the entire data of a topological space.
    \item Let $G$ be a group. A group homomorphism $f: \ZZ\to G$ is determined by a
      choice of $f(1)\in G$, so these pick out the elements. Letting $-$ be
      the group homomorphism $\ZZ\to\ZZ$ which takes $z$ to $-z$, the composite
      $f-$ picks out the inverse of the element identified by $f$. To recover
      the multiplicative structure, we consider the \emph{free product group}
      $G\bullet H$, whose elements are words $g_1h_1g_2h_2\cdots g_nh_n$ modulo
      the relations of $G$ and $H$, and whose multiplication is concatenation.
      There is a canonical map $\varphi: \ZZ\to\ZZ\bullet\ZZ$ given by $1\mapsto
      11'$ (we represent elements in the second copy of $\ZZ$ with $'$s).
      Given two morphisms $f,g: \ZZ\to G$, we can define a map $f\bullet g:
      \ZZ\bullet\ZZ\to G$ by $z_1z_1'\cdots z_nz_n' \mapsto f(z_1)g(z_1')\cdots
      f(z_n)g(z_n')$. Because the map $(f\bullet g)\varphi: \ZZ\to G$ picks out
      exactly the element $f(1)g(1)$, we have recovered the entire structure of $G$
      purely by studying $\scat{Grp}(\ZZ, G)$.
  \end{itemize}
\end{ex}

These examples are instances of a much more general theory, which we begin to
develop here. We first need to formalize what we mean by ``recovering the
data'' of an object.

\begin{dfn}[isomorphism]\label{def:isomorphism}
  A morphism $f: x\to y$ in a category $\cat{C}$ is an \emph{isomorphism} if
  there exists an \emph{inverse morphism} $g: y\to x$ such that $gf = 1_x$ and
  $fg = 1_y$. Two objects $x$ and $y$ are \emph{isomorphic}, written $x\cong y$,
  if there exists an isomorphism between them.
\end{dfn}

\begin{ex} The general notion of isomorphism recovers the familiar notions in
  virtually every common setting.
  \begin{itemize}
    \item Every identity morphism is an isomorphism with itself as the inverse.
    \item Isomorphisms in $\scat{Set}$ are bijections; in $\scat{Grp}$ are group
      isomorphisms; in $\scat{Vect}_\kk$ are vector space isomorphisms; and in
      $\scat{Top}$ are homeomorphisms.
    \item Let $G$ be a group with associated category $\cG$. Then since
      composition is group multiplication, every morphism in $\cG$ is an
      isomorphism. (In fact, we can take this as a definition: a \emph{monoid} is a
      category with one object, while a \emph{group} is a monoid in which every
      morphism is an isomorphism. A \emph{groupoid} is then a category in which
      every morphism is an isomorphism; groupoids, which generalize groups, are a very interesting
      algebraic object in their own right.)
    \item Let $P$ be a poset with associated category $\cP$. Then antisymmetry of
      a poset implies that the only isomorphisms in are the identities. (A
      \emph{preorder} is a category in which every hom-set has at most one
      element; a \emph{poset} is a preorder in which the only isomorphisms are
      the identities.)
    \item Let $M = (Q, \delta)$ be a non-deterministic automaton over the
      alphabet $\Sigma$, so that $\delta: Q\times \Sigma\to \cP(Q)$ is the
      transition function. Recall that the identities in $\cM$ are the empty
      words. As such, an isomorphism between two states $q_1$ and $q_2$ is a
      word $w$ which takes $q_1$ to $q_2$, together with a word $w'$ which takes
      $q_2$ to $q_1$, such that the concatenate $ww'$ is the empty string. In
      other words, $w$ and $w'$ are both empty---so two states are isomorphic if
      and only if the machine can freely move between them at any point.
  \end{itemize}
\end{ex}

Isomorphisms satisfy the basic properties we expect.

\begin{prop}
  Inverses are unique. Explicitly, if $f: x\to y$ is an isomorphism with
  inverses $g, h: y\to x$, then $g = h$.
\end{prop}

\begin{proof}
  We have \[
    g = 1_xg = (hf)g = h(fg) = h1_y = h.\qedhere
  \]
\end{proof}

\begin{ntn}
  We are now justified in unambiguously writing the inverse of an isomorphism
  $f$ as $f^{-1}$.
\end{ntn}

\begin{prop}
  Being isomorphic is an equivalence relation on the class of objects in a category $\cat{C}$.
\end{prop}

\begin{proof}
  We need to show:
  \begin{itemize}
    \item Reflexivity. The identity $1_x$ is an isomorphism $x\cong x$.
    \item Symmetry. Given an isomorphism $f: x\to y$, $f^{-1}$ is an isomorphism
      $y\to x$ with inverse $f$.
    \item Transitivity. Given isomorphisms $f: x\to y$ and $g: y\to z$,
      $gf$ is an isomorphism $x\to z$ with inverse $f^{-1}g^{-1}$. \qedhere
  \end{itemize}
\end{proof}

We now take a first step towards justifying the assertion as the beginning of
the section.

\begin{prop}\label{thm:iso-implies-hom-iso}
  Let $x\cong y$ in a category $\cat{C}$. Then:
  \begin{enumerate}
    \item for every $z\in\cat{C}$, $\cat{C}(z, x)\cong\cat{C}(z, y)$
      \label{item:iso-equiv-post};
    \item for every $z\in\cat{C}$, $\cat{C}(x, z)\cong\cat{C}(y, z)$
      \label{item:iso-equiv-pre}.
  \end{enumerate}
\end{prop}

\begin{proof}
  Let $f: x\to y$ be an isomorphism.

  First, define a map $f_*: \cat{C}(z, x)\to\cat{C}(z, y)$ by post-composition,
  i.e. $f_*(g) = fg$. We claim that $f^{-1}_*$, defined similarly, is an inverse
  of $f_*$. Letting $h\in\cat{C}(z, x)$, we have \[ f^{-1}_*(f_*(h)) =
  f^{-1}(fh) = (f^{-1}f)h = 1_xh = h, \]and the same on the other side.

  Similarly, define a map $f^*: \cat{C}(y, z)\to\cat{C}(x, z)$ by
  pre-composition, i.e. $f^*(g) = gf$. Then an identical check shows that
  $(f^{-1})^*$, defined similarly, is an inverse of $f^*$.
\end{proof}

To show the other direction,  we will need a little bit more machinery. Once
shown, this result will indeed imply that the entire structure of an object can
be identified by studying its morphisms. We will finally do this in the form of
\Cref{thm:hom-iso-implies-iso}.

\subsection{Functors}

Enmeshed in the categorical mindset, we understand that
morphisms---relationships---between objects are of crucial importance. Since we
now want to study categories, we ask the natural question: what is the right
notion of morphism between categories? The answer is a \emph{functor}, which is
just a structure-preserving map between categories.

\begin{dfn}[functor]\label{def:functor}
  A \emph{functor} $F: \cat{C}\to\cat{D}$ consists of the following data:
  \begin{itemize}
    \item for each object $x\in\cat{C}$, an object $Fx\in\cat{D}$;
    \item for each morphism $f\in\cat{C}(x, y)$, a morphism $Ff\in\cat{D}(Fx, Fy)$.
  \end{itemize}
  This data must preserve the structure of the category, namely identities and
  composites, meaning:
  \begin{itemize}
    \item for each object $x\in\cat{C}$, $F1_x = 1_{Fx}$;
    \item for each pair of morphisms $x\xto{f}y\xto{g} z$ in $\cat{C}$, $F(gf) =
      (Fg)(Ff)$.
  \end{itemize}
\end{dfn}

\begin{ex}\label{ex:functors}
  In mathematics, functors are ubiquitous as representations of procedures for
  producing structures of one sort from structures of another. For instance, the
  following are all functors:
  \begin{itemize}
    \item On any category $\cat{C}$, there is an \emph{identity functor}
      $1_\cat{C}: \cat{C}\to\cat{C}$ which takes each object and morphism to
      itself.
    \item There is a functor $\cP_\exists: \scat{Set}\to\scat{Set}$ which takes
      a set $X$ to its powerset, and a set-function $f: X\to Y$ to the direct
      image map given by \[
        f_\exists(A) = \{y\in Y: \exists a\in A \text{ such that } y = f(a)\}.
      \]
    \item There is a distinct functor $\cP_\forall: \scat{Set}\to\scat{Set}$
      which takes a set $X$ to its powerset, and a set-function $f: X\to Y$ to
      the map given by \[
        f_\forall(A) = \{y\in Y: \forall x\in X, f(x) = y \text{ implies } x\in A\}.
      \] As these examples show, the action of a functor on morphisms is not
      determined by its action on objects. (In fact, as usual in category
      theory, it is the action on morphisms---in particular, on the
      identities---which determines the action on objects.)
    \item There is a functor $\text{GL}_n: \scat{Ring}\to\scat{Grp}$ which takes a
      ring $R$ to the multiplicative group $\text{GL}_n(R)$ of invertible $n$-by-$n$
      matrices with coefficients in $R$, with entry-wise action of homomorphisms.
      The functor $\text{GL}_1$ has a special interpretation as the functor
      which takes a ring $R$ to the multiplicative group of units in $R$. We
      write $(-)^\times: \scat{Ring}\to\scat{Grp}$.
    \item There is a functor $\texttt{Maybe}: \scat{Set}\to\scat{Set}$ which takes a
      set $X$ to the set $X\sqcup \{\bot\}$, where $\bot$ is a new element, and
      a function $f$ to its extension by $f(\bot) = \bot$.
    \item Similarly, there is a functor $\texttt{List}: \scat{Set}\to\scat{Set}$ which
      takes a set $X$ to the set of all finite lists of elements in $X$, and a
      set-function $f$ to its mapping over lists, i.e. \[
        (\texttt{List}f)([x_1, \ldots, x_n]) = [f(x_1), \ldots, f(x_n)].
      \]  In other contexts, this functor is also called the \emph{free
      monoid} or the \emph{Kleene star}.
    \item For any field $\kk$, there is a functor $\scat{Set}\to\scat{Vect}_\kk$ which
      takes a set $X$ to the $\kk$-span of $X$, and a set-function $f$ to
      its linear extension. This is also called the \emph{free vector space}.
      More generally, any free construction---such as the free group, free ring,
      etc.---forms a functor.
    \item Let $\cat{C}$ be a concrete category, such as those of
      \Cref{ex:concrete categories}. Then
      the \emph{forgetful functor} $U: \cat{C}\to\scat{Set}$ takes each object
      to its underlying set, and each morphism to its underlying set-function,
      ``forgetting'' the additional structure.
    \item There is also a forgetful functor $\scat{Ring}\to\scat{Grp}$ which
      takes each ring to its underlying additive group, and each ring
      homomorphism to its underlying group homomorphism.
  \end{itemize}
\end{ex}

\begin{ex}\label{ex:abstract-functors}
  As the following examples show, whenever we can think of each instance of a
  certain mathematical structure as a category, functors reproduce the right
  notion of structure-preserving transformation between those structures.
  \begin{itemize}
    \item Let $P$ and $Q$ be posets with associated categories $\cP$ and $\cQ$,
      and let $F: \cP\to\cQ$ be a functor. Let $p_1\leq_P p_2$, so that there is
      a unique morphism $p_1\to p_2$ in $\cP$. Since $F$ must take this morphism
      to a morphism $Fp_1\to Fp_2$, it must hold that $Fp_1\leq_Q Fp_2$.
      Furthermore, this is the only requirement on functors, as the statements
      about identities and composites assert equalities between morphisms, but
      any two morphisms with the same domain and codomain are equal in a poset.
      As such, functors between posets are exactly monotone maps.
    \item Let $G$ and $H$ be groups with associated categories $\cG$ and
      $\cH$. A functor $F: \cG\to\cH$ assigns the single object of $\cG$ to the
      single object of $\cH$, and each morphism in $\cG$, which is an element $g\in
      G$, to a morphism (element) $Fg\in H$. That this preserves composites tells us
      that it preserves group multiplication, and hence it is a homomorphism. The
      fact that $F$ preserves identities is extraneous, since every group
      homomorphism preserves identities. As such, functors between groups are exactly
      group homomorphisms.
    \item Let $L_1$ and $L_2$ be functional programming languages with associated
      categories $\cL_1$ and $\cL_2$. We think of a functor $F: \cL_1\to\cL_2$ as an
      embedding---or, more technically, a \emph{model}---of $\cL_1$ in $\cL_2$.
      Specifically, for any function in $\cL_1$, $F$ identifies a corresponding
      function in $\cL_2$, and so $F$ allows us to think of computations in $L_2$ as
      ``simulating'' computations in $L_1$.
  \end{itemize}
\end{ex}

The following class of functors are especially important.

\begin{dfn}[hom-functors]\label{def:hom-functors}
  Let $x\in\cat{C}$. There is a functor \[
    \cat{C}(x, -):\cat{C}\to\scat{Set},
  \] the \emph{covariant hom-functor at $x$}, which takes an object $y$ to the
  hom-set $\cat{C}(x, y)$, and a morphism $f: y\to z$ to its action by
  post-composition, $f_*(g) = fg$\footnote{The analogous functor $\cat{C}(-, x)$
    requires a little bit of machinery---the notions of \emph{opposite
  categories} and \emph{contravariant functors}---which are outside our scope.
  It is defined in any introductory text on category theory.}.
\end{dfn}

Since isomorphic objects are meant to look identical to all the machinery of
category theory, we should expect the following result.

\begin{prop}\label{thm:functors-preserve-iso}
  Let $F: \cat{C}\to\cat{D}$ be a functor and let $f: x\to y$ be an isomorphism
  in $\cat{C}$. Then $Ff: Fx\to Fy$ is an isomorphism.
\end{prop}

\begin{proof}
  We have that \[
    FfFf^{-1} = F(ff^{-1}) = F1_x = 1_{Fx},
  \]and the same works on the other side.
\end{proof}

Notice that both functorality axioms are exactly what is required to prove this
result.

\vspace{1em}

If functors are morphisms between categories, then we should expect that there
is a category of categories. This is indeed the case, but we first need to show
that functors can be composed.

\begin{prop}
  Let $F: \cat{C}\to\cat{D}$ and $G: \cat{D}\to\cat{E}$ be functors. Then there
  is a \emph{composite functor} $GF: \cat{C}\to\cat{E}$, defined by $(GF)x =
  G(Fx)$ and $(GF)f = G(Ff)$. Furthermore, this composition is associative and
  unital, with identities $1_{\cat{C}}$.
\end{prop}

\begin{ex}
  The composite of the forgetful functors $\scat{Ring}\to\scat{Grp}$ and
  $\scat{Grp}\to\scat{Set}$ is exactly the forgetful functor
  $\scat{Ring}\to\scat{Set}$.
\end{ex}

\begin{dfn}
  The \emph{category of categories} $\scat{Cat}$ has categories as objects and
  functors as morphisms.
\end{dfn}

The foundationally-inclined reader will correctly object to this definition,
which implies that $\scat{Cat}$ should be an object of itself, leading to issues
involving Russell's paradox. There are several resolutions to this---for
instance, letting $\scat{Cat}$ be the category of so-called \emph{locally small}
categories, whose hom-sets $\cat{C}(x, y)$ each form sets. We ignore these
issues here.

% There are several additional properties we may want a functor to satisfy,
% analogous to injectivity and surjectivity of ordinary functions.

% \begin{dfn}
%   A functor $F$ is \emph{faithful} if it is injective on morphisms, i.e. if $Ff =
%   Fg$ implies $f = g$. It is \emph{full} if it is surjective on hom-sets, i.e. if for
%   any $Fx\xto{g} Fy$ there is some $x\xto{f} y$ with $Ff = g$.  Note that a
%   functor may be full even if it does not 
%   \end{itemize}
% \end{dfn}

\subsection{Natural Transformations}

The notion of a \emph{natural transformation} can be somewhat mysterious, but is
ultimately a workhorse of categorical machinery. We can think of a category
$\cat{C}$ geometrically as a single point, in which case a functor $F:
\cat{C}\to\cat{D}$ is an oriented line---an arrow. Two functors $F,G:
\cat{C}\to\cat{D}$ look like \[
  \begin{tikzcd}
    C \ar[rr, "F", bend left=50]\ar[rr, "G"', bend right=50] & \phantom{\Downarrow\alpha} & D\punctuation{.}
  \end{tikzcd}
\]
A natural transformation is a square---or, if you prefer, a disk---which ``fills
in the hole'': \[
  \begin{tikzcd}
    C \ar[rr, "F", bend left=50]\ar[rr, "G"', bend right=50] & \Downarrow\alpha& D\punctuation{.}
  \end{tikzcd}
\]
In other words, a natural transformation is a morphism between functors.

More concretely, recall that functors can be thought of as tools which, given a
structure of one kind, produce one of another. In this sense, natural
transformations are a mechanism for converting between such constructions. For
each object $x\in\cat{C}$, we have two ways to construct an object of $\cat{D}$,
i.e. $Fx$ and $Gx$. Of course, objects of $\cat{D}$ are related by morphisms, so
a natural transformation $\alpha: F\To G$ should identify a morphism $\alpha_x:
Fx\to Gx$ for each $x\in\cat{C}$.

This is not quite enough. We want to ensure that the morphisms $\alpha_x$ are
somehow ``consistent'' with the morphisms of $\cat{C}$. We formalize that
intuition now.

\begin{dfn}[natural transformation]\label{def:natural transformation}
  Let $F, G: \cat{C}\to\cat{D}$ be functors. A \emph{natural transformation}
  $\alpha: F\To G$ consists of, for every object $x\in\cat{C}$, a
  \emph{component} $\alpha_x: Fx\to Gx$ such that, for every morphism $f: x\to
  y$ in $\cat{C}$, the following diagram (a \emph{naturality square}) commutes:
  \[
    \begin{tikzcd}
      Fx\ar[r, "\alpha_x"]\ar[d, "Ff"'] & Gx\ar[d, "Gf"] \\
      Fy\ar[r, "\alpha_y"'] & Gy\punctuation{.}
    \end{tikzcd}
  \]
\end{dfn}

The idea is that it does not matter whether we first move from $x$ to $y$ via
\emph{any morphism} $f$, or first move from $F$ to $G$ via $\alpha$; natural
transformations commute with any morphism. This is the sense in which natural
transformations are natural.

\begin{ex}
  There are many important examples of natural transformations.
  \begin{itemize}
    \item For any functor $F$, there is an \emph{identity natural transformation
      $1_F: F\To F$}, whose components are each the identities $(1_F)_x = 1_{Fx}$.
    \item There is a natural transformation $\alpha: 1_\scat{Set}\To
      \cP_\exists$ with components $\alpha_X: x\mapsto \{x\}$.
    \item The \emph{dual} of a vector space $V$ over $\kk$ is the vector space
      of linear maps into $\kk$, i.e. $V^* = \scat{Vect}_\kk(V, \kk)$. There is
      a natural transformation $\alpha: 1_{\scat{Vect}}\To (-)^{**}$ whose
      components $\alpha_V$ take any $v\in V$ to the map $\text{ev}_v:
      \VV^*\to\kk$ given by $T\mapsto Tv$.
    \item There is a natural transformation $\det:\text{GL}_n\To (-)^\times$, where
      $R^*$ is the ring of units from \Cref{ex:functors}, which
      takes the determinant of an invertible matrix.
    \item Recall from \Cref{ex:abstract-functors} that functors between posets
      are exactly monotone maps. A natural transformation $\alpha: F\To G$
      between two monotone maps $\cP\to\cQ$ consists of, for each $p\in\cP$, a
      morphism $Fp\to Gp$. Since $\cQ$ is a poset, there is at most one such
      morphism, and it exists if and only if $Fp\leq Gp$. As such, there can
      only be one such natural transformation, and it exists if and only if
      $F\leq G$ in the pointwise ordering.
    \item Let $F,G:\cL_1\to\cL_2$ be models of a programming language $L_1$ in
      $L_2$. A natural transformation $\alpha: F\To G$ is a \emph{transpilation}
      between the models: it tells us how to convert programs written in the
      model $F$ into programs written in the model $G$. The naturality squares
      assert exactly that this transpilation is \emph{sound}, i.e. that it
      preserves the meaning of programs.
 \end{itemize}
\end{ex}

\begin{ex}
  Here are three natural transformations common in functional programming.
  \begin{itemize}
    \item Let $\texttt{reverse}_X$ be the function which reverses lists of
      elements in $X$, i.e. \[
        [x_1, \ldots, x_n]\mapsto [x_n, \ldots, x_1].
      \] Then $\texttt{reverse}$ is a natural transformation $\texttt{List}\To
      \texttt{List}$.
    \item Let $\texttt{head}_X$ be the function which gets the first element of
      a list if it exists, i.e. \[
        [x_1, \ldots, x_n]\mapsto x_1,\quad\quad []\mapsto\bot.
      \] Then $\texttt{head}$ is a natural transformation
      $\texttt{List}\To\texttt{Maybe}$.
    \item Let $\texttt{toList}_X$ be the function $\texttt{Maybe}
      X\to\texttt{List} X$ given by \[
        x\mapsto [x], \quad\quad \bot\mapsto[].
      \] Then $\texttt{toList}$ is a natural transformation
      $\texttt{Maybe}\To\texttt{List}$.
  \end{itemize}
  Each of these are special cases of the so-called \emph{Reynolds
  abstraction theorem} from programming language theory, which says that
  (parametrically) polymorphic functions are natural~\cite{reynolds-1983}.
  This theorem is explored in great detail by~\cite{wadler-1989}.
\end{ex}

If we think of natural transformations as morphisms between functors
$\cat{C}\to\cat{D}$, then following the category-theoretic philosophy, there
should be a category of functors. Indeed, natural transformations can be
composed, as follows.

\begin{prop}
  Let $F,G,H: \cat{C}\to\cat{D}$ be functors and let $\alpha: F\To G$ and
  $\beta: G\To H$ be natural transformations. Then there is a \emph{vertical
  composite  natural transformation} $\beta\alpha: F\To H$, whose components are
  $(\beta\alpha)_x = \beta_x\alpha_x$. Furthermore, this composition is
  associative and unital, with identities $1_F$.
\end{prop}

The name \emph{vertical composite} comes from the following picture: \[
  \begin{tikzcd}[baseline=(current bounding box.center)]
    & \Downarrow\alpha \\[-28pt]
    C\ar[rr, "F", bend left=50]\ar[rr, "G", near start]\ar[rr, "H"', bend right=50] && D & \rightsquigarrow & C \ar[rr, "F", bend left=50]\ar[rr, "H"', bend right=50] & \Downarrow\beta\alpha & D\punctuation{.} \\[-25pt]
    & \Downarrow\beta
  \end{tikzcd}
\]
As the name implies, there is a horizontal composite, defined in
e.g.~\cite[Lemma 1.7.4]{riehl-2017}.

\begin{dfn}[functor category]\label{def:functor category}
  Let $\cat{C}$ and $\cat{D}$ be categories. The \emph{functor category}
  $[\cat{C}, \cat{D}]$ has functors $\cat{C}\to\cat{D}$ as objects and natural
  transformations as morphisms.
\end{dfn}

Here is one example of the advantage of working with categorical structure: we
already know what the notion of an isomorphism of functors has to be.

\begin{dfn}[natural isomorphism]\label{def:natural isomorphism}
  Let $F,G:\cat{C}\to\cat{D}$ be functors. A natural transformation $\alpha: F\To G$ is a \emph{natural isomorphism} if
  it is an isomorphism in the category $[\cat{C}, \cat{D}]$.
\end{dfn}

\begin{prop}
  Let $F,G:\cat{C}\to\cat{D}$ be functors. A natural transformation $\alpha:
  F\To G$ is a natural isomorphism if and only each of its components $\alpha_x:
  Fx\to Gx$ are isomorphisms in $\cat{D}$.
\end{prop}

We can now state the correct form of the converse to \Cref{thm:iso-implies-hom-iso}.

\begin{thm}\label{thm:hom-iso-implies-iso}
  Let $x$ and $y$ be objects in a category $\cat{C}$ such that $\cat{C}(x,
  -)\cong\cat{C}(y, -)$. Then $x\cong y$.
\end{thm}

\begin{proof}
  Let $\eta: \cat{C}(x, -)\To\cat{C}(y, -)$ be a natural isomorphism. Define \[
    t = \eta_x(1_x),
    \] which is a morphism $y\to x$, and \[
    u = \eta_y^{-1}(1_y),
  \]
  which is a morphism $x\to y$. We claim these are inverses.

  Naturality of $\eta$ applied to $u$ asserts that \[
    \begin{tikzcd}
      \cat{C}(x, x)\ar[r, "\eta_x"]\ar[d, "u_*"'] & \cat{C}(y, x)\ar[d, "u_*"] \\
      \cat{C}(x, y)\ar[r, "\eta_y"'] & \cat{C}(y, y)
    \end{tikzcd}
  \]
  commutes. Following $1_x$ around the top and right, we get \[
    u_*(\eta_x(1_x)) = u_*(t) = ut,
  \] while on the left and bottom we get \[
    \eta_y(u_*(1_x)) = \eta_y(u) = 1_y,
  \]
  so commutativity implies $ut = 1_y$.

  Similarly, naturality of $\eta^{-1}$ applied to $t$ asserts that \[
    \begin{tikzcd}
      \cat{C}(y, y)\ar[r, "\eta_y^{-1}"]\ar[d, "t_*"'] & \cat{C}(x, y)\ar[d, "t_*"] \\
      \cat{C}(y, x)\ar[r, "\eta_x^{-1}"'] & \cat{C}(x, x)
    \end{tikzcd}
  \]
  commutes. Following $1_y$ around the top and right, we get \[
    t_*(\eta_y^{-1}(1_y)) = t_*(u) = tu,
  \] while on the left and bottom we get \[
    \eta_x^{-1}(t_*(1_y)) = \eta_x^{-1}(t) = 1_x,
  \]
  so again $tu = 1_x$. This completes the proof.
\end{proof}

This theorem is a special case of the \emph{Yoneda lemma}, arguably the most
important theorem in category theory. The contravariant result, with the
functors $\cat{C}(-, x)$, is also true, but outside our scope. Together, these
theorems tell us that objects in a category are indeed determined by their
morphisms.

\section{Monoidal Categories}

In ordinary categories, composition is sequential: if morphisms are interpreted
as computational processes, the composite $gf$ means roughly ``first do $f$,
then do $g$.'' In many settings, we want to consider both sequential and
parallel (or concurrent) composition. The categorical axiomatization of this idea is
\emph{monoidal categories}.

\subsection{The Definition}
\label{sec:monoidal definition}

To model parallel composition, we want a binary operation $\otimes$ which
assigns, to each pair of processes (morphisms) $f:x\to y$ and $g:w\to z$, their
parallel composite $f\otimes g$. If we think of objects as types, this parallel
composite can only run given inputs of both types $x$ and $w$, to feed to $f$
and $g$ respectively, and should produce two outputs of types $y$ and $z$. To
represent this notion, we also need a way to pair types (objects), which means a
binary operation also called $\otimes$ on objects. This dual assignment on
both objects and morphisms suggests functorality: we will ask that $\otimes$ is
a functor $\cat{C}\times\cat{C}\to\cat{C}$.

What axioms should this data satisfy? As in most well-behaved algebraic
structures, there should be an identity for $\otimes$ on objects, which we will
write $I$. Computationally, we may think of $I$ as a ``trivial resource,'' which
may freely be created and has no uses. This $I$ induces an identity, the
morphism $1_I$, for $\otimes$ on morphisms, so we do not need to add an identity
on morphisms as an extra axiom. We would also like parallel composition to
associate, so that we can sensibly talk about performing $n$ processes in
parallel. It is therefore tempting to list the following axioms:

\[
  I\otimes x = x = x\otimes I; \quad\quad (x\otimes y)\otimes z =
  x\otimes(y\otimes z).
\]

While this notion, called a \emph{strict monoidal category}, is useful, it is
not the most natural axiomatization. For instance, even the category
$\scat{Set}$, with the ordinary Cartesian product, is not strictly monoidal: the
identity is $\{*\}$, but $\{*\}\times X$ is not equal to $X$, instead merely
isomorphic. The point is that there is interesting structure in the way that
even isomorphic objects relate to each other; we do not want to lose it by
forcing strict equality.

However, we do not want to allow the structure of these natural isomorphisms to
be too strange. For instance, one can imagine two ways to convert from $I\otimes (x\otimes y)$
to $x\otimes y$: \[
  I\otimes(x\otimes y) \cong x\otimes y \quad\text{ and }\quad
  I\otimes(x\otimes y) \cong (I\otimes x)\otimes y \cong x\otimes y.
\]The first directly uses unitality, while the second associates and then uses
unitality. A \emph{coherence axiom} asserts that choices like this do not
matter: every pair of composites of our canonical isomorphisms with the same
domain and codomain should commute.

We are not quite ready; there is one remaining technical issue, though this
paragraph may be safely skipped. It may happen that two
domains equate ``accidentally'', so that, for instance,
\begin{equation}\label{eqn:accidental equality}
  ((x\otimes y)\otimes z)\otimes w = x\otimes(y\otimes(z\otimes w)).
\end{equation}
In this case, the version of the coherence axiom stated above implies that the
isomorphisms \[
  ((x\otimes y)\otimes z)\otimes w \cong (x\otimes y)\otimes (z\otimes w)
  \quad\text{ and }\quad
  x\otimes(y\otimes(z\otimes w)) \cong (x\otimes y)\otimes (z\otimes w)
\] should commute; they do, after all, have the same domain and codomain. But
the first re-associates from the left to the right, and the second re-associates
from the right to the left: these are structurally different actions, which only
``look the same'' because of the accident of \Cref{eqn:accidental equality},
so our theory should not require them to commute. There is a way to formalize
a correct abstract notion of coherence---see for instance~\cite[subsection
VII.2]{maclane-1971}---but fortunately, Mac Lane's \emph{coherence theorem}
enables an easier axiomatization.

We are finally now ready to state the definition of a monoidal category.

\begin{dfn}[monoidal category]\label{def:monoidal category}
  A \emph{monoidal category} $\cat{C}$ consists of the following data:
  \begin{itemize}
    \item an underlying category $\cat{C}$;
    \item a functor $\otimes: \cat{C}\times\cat{C}\to\cat{C}$, called the
      \emph{monoidal product};
    \item an object $I\in\cat{C}$, called the \emph{monoidal unit};
    \item a natural isomorphism $\alpha_{x,y,z}: (x\otimes y)\otimes z\to
      x\otimes(y\otimes z)$, called the \emph{associator};
    \item a natural isomorphism $\lambda_x: I\otimes x\to x$, called the
      \emph{left unitor}\footnote{The letters $\lambda$ and $\rho$ are chosen
      for their association with L and R, respectively.};
    \item a natural isomorphism $\rho_x: x\otimes I\to x$, called the
      \emph{right unitor}.
  \end{itemize}

  This data must make the following diagrams, called the \emph{triangle} and
  \emph{pentagon} identities, commute:
	\begin{figure}[H]
		\centering
		\begin{tikzcd}
			(x\otimes I)\otimes y & & x\otimes(I\otimes y) \\
			& x\otimes y &
			\arrow["\alpha_{x,1_\otimes,y}", from=1-1, to=1-3]
			\arrow["\rho_x", from=1-1, to=2-2, swap]
			\arrow["\lambda_x", from=1-3, to=2-2]
		\end{tikzcd}
		\begin{tikzcd}
			& (x\otimes y)\otimes(z\otimes w) & \\
			((x\otimes y)\otimes z)\otimes w & & x\otimes (y\otimes (z\otimes w)) \\
			(x\otimes (y\otimes z))\otimes w & & x\otimes ((y\otimes z)\otimes w)\punctuation{.}
			\arrow["\alpha_{x\otimes y, z, w}", from=2-1, to=1-2]
			\arrow["\alpha_{x, y, z\otimes w}", from=1-2, to=2-3]
			\arrow["\alpha_{x, y, z}\otimes 1_w", from=2-1, to=3-1, swap]
			\arrow["1_x\otimes\alpha_{y, z, w}", from=3-3, to=2-3, swap]
			\arrow["\alpha_{x, y\otimes z, w}", from=3-1, to=3-3, swap]
		\end{tikzcd}
	\end{figure}
\end{dfn}

The above diagrams look arbitrary, but as mentioned, they are exactly what is
required for the correct notion of coherence. On first exposure to these ideas,
it is safe to ignore the exact statement of the identities and work with the
intuition that any two ways of associating or unitalizing should be the same.

In the above definition, the natural isomorphisms $\alpha,$ $\lambda,$ and
$\rho$ feel in some sense more like axioms than data. This is another key
component of the category-theoretic philosophy, one which should feel
comfortable to computer scientists, who often assume the existence of concrete
objects which structure our models:\begin{center}
  \emph{
    structure is a kind of data.
  }
\end{center}
If we think of categories as algebras of structure, it is natural that we should
think of axiomatic structure as an algebraic object which may be
manipulated\footnote{
  Of course, \Cref{def:monoidal category}
  still carries a traditional-looking equational theory in the form of the
  triangle and pentagon identities. The key difference is that this theory is an
  assumption about the ``two-dimensional'' structure of the natural
  transformations, whereas associativity and unitality are assumptions about the
  ``one-dimensional'' structure of the functor $\otimes$. We could continue to
  generalize, instead asking that these diagrams are themselves witnessed by
  ``three-dimensional'' isomorphisms between the natural isomorphisms $\alpha$,
  $\lambda$, and $\rho$. Repeating this process \emph{ad infinitum}, the natural
  endpoint of the structure-as-data philosophy is so-called
  \emph{$\infty$-category theory}.
}.

\subsection{Examples}
\label{sec:monoidal examples}

The notion of a monoidal category is quite general; we survey some important
examples here.

\begin{ex}\label{ex:set-monoidal}
  Let us very explicitly construct the required data to show that
  \scat{Set} is a monoidal category under the Cartesian product. The monoidal unit
  is the singleton $\{*\}$. The associator is the natural isomorphism with
  components \begin{align*}
    \alpha_{X,Y,Z} \colon (X\times Y)\times Z &\to X\times(Y\times Z)\\
    ((x, y), z) &\mapsto (x, (y, z)).
  \end{align*}
  The left and right unitors are the natural isomorphism with components
  \begin{multicols}{2}
    \noindent
    \begin{align*}
      \lambda_X \colon \{*\}\times X &\to X \\
      (*, x) &\mapsto x,
    \end{align*}
    \begin{align*}
      \rho_X \colon X\times\{*\} &\to X \\
      (x, *) &\mapsto x.
    \end{align*}
  \end{multicols}

  A common complaint about category theory is at play here: we now have a
  large number of relationships to demonstrate, including
  functorality of $\times$, naturality of $\alpha$, $\lambda$, and $\rho$, and
  the pentagon and triangle identities. The author's opinion is that this work
  will ultimately save effort, by allowing us to use a powerful abstract theory
  across any structure we have shown to be monoidal, but if the reader is not
  convinced, one solution is to work even more generally. For instance, by
  showing that the Cartesian product satisfies a simple property called the
  \emph{universal property of the product}, we could automatically conclude on
  the grounds of a general theorem that it is monoidal. Abstraction of this sort
  ultimately saves effort, but it is not always comfortable at first.
  Regardless, in order to exemplify the definition in all its detail, we
  continue with the explicit demonstration.

  To show functorality of $\times$, we need to determine its action on
  morphisms. Letting $f: X\to Y$ and $g: W\to Z$, we define \begin{align*}
    f\times g\colon X\times W &\to Y\times Z \\
                       (x, y) &\mapsto (f(x), g(y)).
  \end{align*}
  This is functorial: it takes an identity $1_{(X, W)} = (1_X, 1_W)$ to
  $1_{X\times W}$, and the composite of two pairs of morphisms to composite of
  their action on pairs.

  To show naturality of $\alpha$, let $(f, g, h): (X, Y, Z)\to (X', Y', Z')$ be
  a morphism in $\scat{Set}^3$. We need to show that the following diagram
  commutes: \[
    \begin{tikzcd}
      (X\times Y)\times Z\ar[r, "\alpha_{X,Y,Z}"]\ar[dd, "(f\times g)\times h"'] &
      X\times(Y\times Z)\ar[dd, "f\times(g\times h)"] \\
      \\
      (X'\times Y')\times Z'\ar[r, "\alpha_{X',Y',Z'}"'] & X'\times(Y'\times Z').
    \end{tikzcd}
  \]

  Tracking the action of a triple $((x, y), z)$ through both paths, we see the
  needed equality: \[
    \begin{tikzcd}
      ((x, y), z)\ar[r, mapsto, "\alpha_{X,Y,Z}"]\ar[dd, mapsto, "(f\times g)\times h"'] & (x, (y, z))\ar[dd, mapsto, "f\times(g\times h)"] \\
      \\
      ((f(x), g(y)), h(z))\ar[r, mapsto, "\alpha_{X',Y',Z'}"'] & (f(x), (g(y), h(z))).
    \end{tikzcd}
  \]

  To show naturality of $\lambda$, let $f: X\to Y$. Since the only morphism
  $\{*\}\to\{*\}$ is $1_{\{*\}}$, naturality is entailed by commutativity of the
  following diagram: \[
    \begin{tikzcd}
      \{*\}\times X\ar[r, "\lambda_X"]\ar[d, "1_{\{*\}}\times f"'] & X\ar[d, "f"] \\
      \{*\}\times Y\ar[r, "\lambda_Y"'] & Y,
    \end{tikzcd}
    \quad\text{ i.e. }\quad
    \begin{tikzcd}
      (*, x)\ar[r, mapsto, "\lambda_X"]\ar[d, mapsto, "1_{\{*\}}\times f"'] & x\ar[d, mapsto, "f"] \\
      (*, f(x))\ar[r, mapsto, "\lambda_Y"'] & f(x).
    \end{tikzcd}
  \]

  Naturality of $\rho$ is similar. We show the pentagon identity by its action
  on $(((x, y), z), w)$: \[
		\begin{tikzcd}
			& ((x, y), (z, w)) & \\
      (((x, y), z), w) & & (x, (y, (z, w))) \\
      ((x, (y, z)), w) & & (x, ((y, z), w))\punctuation{.}
			\arrow[mapsto, "\alpha_{X\times Y, Z, W}", from=2-1, to=1-2]
			\arrow[mapsto, "\alpha_{X, Y, Z\times W}", from=1-2, to=2-3]
			\arrow[mapsto, "\alpha_{X, Y, Z}\times 1_W", from=2-1, to=3-1, swap]
			\arrow[mapsto, "1_X\times\alpha_{Y, Z, W}", from=3-3, to=2-3, swap]
			\arrow[mapsto, "\alpha_{X, Y\times Z, W}", from=3-1, to=3-3, swap]
		\end{tikzcd}
  \]

  The triangle identity is similar.
\end{ex}

While we will never again be so explicit, we hope the previous example makes the
axioms of a monoidal category more concrete.

\begin{ex}
  There are many more examples of monoidal categories throughout mathematics.
  \begin{itemize}
    \item $\scat{Vect}_\kk$ is monoidal with the tensor product of vector spaces.
    \item $\scat{Cat}$ is monoidal with the product category.
    % \item The categories of \Cref{ex:categories of computable maps}
    %   are monoidal with the Cartesian product of sets. In particular, the
    %   cartesian product of two $\mathbb{A}$-computable functions is computable
    %   by an algorithm which simply first computes the first function, and then
    %   computes the second function.
    \item Let $L$ be a strongly-typed functional programming language with
      \emph{product types} $A\times B$, for instance the simply-typed lambda
      calculus. Then the category $\cL$ is monoidal with forming product types as the
      monoidal product and the unit type as the monoidal unit.
  \end{itemize}
\end{ex}

\begin{ex}[concurrent programming~{\cite{meseguer-montanari-1990}}]
  Returning to our motivation of parallelism, here is a very different example.
  Let $L$ be a strongly-typed functional \emph{concurrent} programming language,
  by which we mean that it can run computations concurrently on different
  machine threads. Then again under reasonable assumptions, $\cL$ is monoidal,
  with concurrent branching as the monoidal product and the do-nothing program as
  the monoidal unit.
\end{ex}

\subsection{String Diagrams}
\label{sec:string diagrams}

In monoidal categories, there are two ``formal mechanisms'' for building
morphisms: sequential composition $\circ$ and parallel composition $\otimes$.
String diagrams are a graphical calculus for morphisms using these mechanisms.
String diagrams and related calculi are explored in great detail
by~\cite{selinger-2011}; we give a basic outline here.


Consider a monoidal category $\cat{C}$ with three morphisms $f: x\to y$, $g:
w\to z$, and $h: y\otimes z\to u$. We can can form a new morphism $h\circ
(f\otimes g): x\otimes w\to u$. We encode this new morphism in the following
\emph{string diagram}, written bottom-up: \[
  \begin{pic}
    \node[morphism] (f) at (0,0) {$f$};
    \draw (f.south) to ++(0,-.5) node[left] {$x$};
    \node[morphism] (g) at (.8,0) {$g$};
    \draw (g.south) to ++(0,-.5) node[right] {$w$} node[right, xshift=5mm, yshift=2mm] {\normalsize.};;
    \setlength\minimummorphismwidth{10mm}
    \node[morphism] (h) at (.4, 1.2) {$h$};
    \draw (f.north) -- (h.south west) node[midway, left] {$y$};
    \draw (g.north) -- (h.south east) node[midway, right] {$z$};
    \draw (h.north) to ++(0, .5) node[left] {$u$};
    % \draw (f.north) to ++(0,1.05) node[left] {$x'$};
		% \draw ([xshift=2.5pt]A.south east) to ++(0,-.5) node[state,scale=0.75] {\normalsize$\$$};
  %   \draw ([xshift=2.5pt]A.north east) to ++(0,.5) node[right] {};
  %   \draw[dotted] (-.8, -1.5) rectangle (.9, 1);
  %   \node at (1.2, -1.3) {$\cA'$\punctuation{.}};
  \end{pic}
\]

Explicitly, the idea is as follows. A morphism is a labelled box, with
``wires''\footnote{As the word ``wire'' suggests, a string diagram
can be thought of as a circuit, where the morphisms/boxes are thought of as
gates. This correspondence has recently been made precise by
~\cite{boisseau-sobocinski-2022}, but the analogy is much older, and it is a
useful intuition even without any rigor. This analogy and many others are
discussed in~\cite{baez-stay-2011}.} coming into and out of labelled with
the domain and codomain. We can hook up two wires representing the same
object---this is sequential composition. We can also place boxes or wires
side-by-side---this is parallel composition. Accordingly: \[
  \begin{pic}
    \node[morphism] (g) at (0,.75) {$g\vphantom{f}$};
    \node[morphism] (f) at (0,0) {$f\vphantom{g}$};
    \draw (f.south) to ++(0,-.3) node[right] {$x$};
    \draw (g.south) to  (f.north);
    \draw (g.north) to ++(0,.3) node[right] {$z$};
  \end{pic}
  \hspace{.4em}
  =
  \hspace{.8em}
  \begin{pic}
    \node[morphism] (f) {$g \circ f$};
    \draw (f.south) to ++(0,-.5) node[left] {$x$};
    \draw (f.north) to ++(0,.5) node[left] {$z$};
  \end{pic}
  \quad\quad
  \text{and}
  \quad\quad
  \begin{pic}
    \node[morphism] (f) at (0,0) {$f$};
    \draw (f.south) to ++(0,-.5) node[left] {$x$};
    \draw (f.north) to ++(0,.5) node[left] {$y$};
    \node[morphism] (g) at (.8,0) {$g$};
    \draw (g.south) to ++(0,-.5) node[left] {$w$};
    \draw (g.north) to ++(0,.5) node[left] {$z$};
  \end{pic}
  \hspace{.7em}
  =
  \begin{pic}
    \node[morphism] (fg) at (0,0) {$f\otimes g$};
    \draw (f.south) to ++(0,-.5) node[left] {$x\otimes w$};
    \draw (f.north) to ++(0,.5) node[left] {$y\otimes z$};
  \end{pic}
  \hspace{.7em}
  =
  \hspace{.2em}
  \begin{pic}
    \node[morphism] (fg) at (0,0) {$f\otimes g$};
    \setlength\minimummorphismwidth{6mm}
    \draw ([xshift=-2.5pt]fg.south west) to ++(0,-.5) node[left] {$x$};
    \draw ([xshift=-2.5pt]fg.north west) to ++(0,.5) node[left] {$y$};
    \draw ([xshift=2.5pt]fg.south east) to ++(0,-.5) node[right] {$w$} node[right, xshift=5mm, yshift=1mm] {\normalsize,};
    \draw ([xshift=2.5pt]fg.north east) to ++(0,.5) node[right] {$z$};
  \end{pic}
\]where in the first equality we have assumed $y = w$, so that the composition
makes sense. As the left hand side of the first equality suggests, we often
suppress the label of ``intermediate'' wires, as they are implicit from the
types of the morphisms; in fact, we may even at times suppress the labels of the
input and output wires. Finally, if there is no box, then a wire may be read as
the identity for its type.

Consider the following diagram: \[
  \begin{pic}
    \node[morphism] (f) at (0,0) {$f$};
    \draw (f.south) to ++(0,-.5) node[left] {$x$};
    \draw (f.north) to ++(0,.5) node[left] {$y$};
    \node[morphism] (g) at (.8,0) {$g$};
    \draw (g.south) to ++(0,-.5) node[left] {$w$};
    \draw (g.north) to ++(0,.5) node[left] {$z$};
    \node[morphism] (h) at (1.6,0) {$h$};
    \draw (h.south) to ++(0,-.5) node[left] {$u$};
    \draw (h.north) to ++(0,.5) node[left] {$v$};
  \end{pic}
\] Do we read this as $(f\otimes g)\otimes h$ or $f\otimes(g\otimes h)$? There
is not an unambiguous choice, but fortunately the coherence theorem, discussed in
\Cref{sec:monoidal definition}, means that there is a unique natural isomorphism
equating these morphisms. As such, the general rule is that \emph{string
diagrams define morphisms up to unique natural isomorphism}.

Similarly, since wires of type $I$ can be created or destroyed at will using
$\lambda$ and $\rho$, we just do not draw such wires. A morphism with domain or
codomain $I$ is represented with a triangle, so that for instance if $f: I\to x$
and $g: x\to I$, then \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[state,rotate=180,scale=.75] (g) at (0,.7) {\rotatebox{180}{$g$}};
    \node[state,scale=.75] (f) at (0,0) {$f$};
    \draw (f.north) -- (g.south);
  \end{pic}
\]is the morphism $gf: I\to I$.

Sometimes, we work in settings which have some ``distinguished'' morphisms, in
which case we will often write them merely with dots. For instance, recall that
a \emph{classical monoid} is a set $X$ together with an associative unital
binary operation. Recalling from \Cref{ex:recovering structure} that
the distinguished unit element $e\in X$ can be associated with the unique
set-function $\{*\}\to X$ defined by $*\mapsto e$, we generalize the notion of a
monoid as follows.

\begin{dfn}[monoid object]\label{def:monoid object}
  Let $\cat{C}$ be a monoidal category. A \emph{monoid object} in $\cat{C}$ is
  an object $m$ together with distinguished morphisms $\mu: m\otimes m\to m$ and
  $\eta: I\to m$, depicted as \[
    \begin{pic}
      \node[dot, fill=black] (mu) at (0,0) {};
      \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[left] {$m$};
      \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right] {$m$};
      \draw (mu) to ++(0, .7) node[left] {$m$};
    \end{pic}
    \quad\quad
    \text{and}
    \hspace{1em}
    \quad\quad
    \begin{pic}
      \node[dot, fill=black] (eta) at (0,0) {} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
      \draw (eta) to ++(0, .7) node[left] {$m$};
    \end{pic}
  \] called the \emph{multiplication} and \emph{unit}. This data must make the equalities
  \begin{equation}\label{eqn:monoid associative}
    \begin{pic}
      \node[dot, fill=black] (a) at (0,0) {};
      \node[dot, fill=black] (b) at (-.5,-.5) {};
      \draw (a) to[out=180, in=90] (b);
      \draw (a) to[out=0, in=90] ++(.7, -.7) to ++(0, -.5) node[right] {};
      \draw (b) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[left] {};
      \draw (b) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[left] {};
      \draw (a) to ++(0, .7) node[left] {};
    \end{pic}
    =
    \begin{pic}
      \node[dot, fill=black] (a) at (0,0) {};
      \node[dot, fill=black] (b) at (.5,-.5) {};
      \draw (a) to[out=0, in=90] (b);
      \draw (a) to[out=180, in=90] ++(-.7, -.7) to ++(0, -.5) node[left] {};
      \draw (b) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right] {};
      \draw (b) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[right] {};
      \draw (a) to ++(0, .7) node[left] {};
    \end{pic}
  \end{equation}
  and
  \begin{equation}\label{eqn:monoid unital}
    \begin{pic}
      \node[dot, fill=black] (a) at (0,0) {};
      \node[dot, fill=black] (b) at (.5,-.5) {};
      \draw (a) to[out=0, in=90] (b);
      \draw (a) to ++(0, .7) node[left] {};
      \draw (a) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.4) node[left] {};
    \end{pic}
    \hspace{.4em}
    =
    \begin{pic}
      \draw(0, 0) node[left] {} to (0, 1.5) node[left]{};
    \end{pic}
    \hspace{.6em}
    =
    \hspace{.5em}
    \begin{pic}
      \node[dot, fill=black] (a) at (0,0) {};
      \node[dot, fill=black] (b) at (-.5,-.5) {};
      \draw (a) to[out=180, in=90] (b);
      \draw (a) to ++(0, .7) node[left] {};
      \draw (a) to[out=0, in=90] ++(.5, -.5) to ++(0, -.4) node[right] {};
    \end{pic}
  \end{equation}
  hold.
\end{dfn}

Let us be very explicit about what these equalities say.
\Cref{eqn:monoid associative} takes in three wires of type $m$. On
the left, it associates them to the left, so we start with $(m\otimes m)\otimes
m$. We first multiply on the left while doing nothing on the right, and then
multiply the product with the thing on the right: this is the composite morphism
\[
  \begin{tikzcd}
    (m\otimes m)\otimes m\ar[r, "\mu\otimes 1_m"] & m\otimes m\ar[r, "\mu"] & m\punctuation{.}
  \end{tikzcd}
\] On the right, the $m$s are associated to the right, so we have the composite
morphism \[
  \begin{tikzcd}
    m\otimes (m\otimes m)\ar[r, "1_m\otimes \mu"] & m\otimes m\ar[r, "\mu"] & m\punctuation{.}
  \end{tikzcd}
\] It may be worrying that these morphisms have different domains, but as
discussed, string diagrams merely identify morphisms up to coherence
isomorphism. As such, for the axiom to make sense, there should be a canonical
natural isomorphism making the domains and codomains of these morphisms equate,
and indeed there is: $\alpha_{m,m,m}$ for the domains, and just the identity for
the codomains. Thus, \Cref{eqn:monoid associative} asserts
commutativity of the diagram \[
  \begin{tikzcd}
    (m\otimes m)\otimes m\ar[rr, "\alpha_{m,m,m}"]\ar[d, "\mu\otimes 1_m"'] & & m\otimes (m\otimes m)\ar[d, "1_m\otimes\mu"] \\
    m\otimes m\ar[dr, "\mu"'] & & m\otimes m\ar[dl, "\mu"] \\
                             & m\punctuation{.}
  \end{tikzcd}
\]

Meanwhile, \Cref{eqn:monoid unital} features three morphisms. On the left, we have \[
  \begin{tikzcd}
    m\otimes I\ar[r, "1_m\otimes\eta"] & m\otimes m\ar[r, "\mu"] & m\punctuation{,}
  \end{tikzcd}
\] in the middle we have the identity $1_m: m\to m$, while on the right we have \[
  \begin{tikzcd}
    I\otimes m\ar[r, "\eta\otimes 1_m"] & m\otimes m\ar[r, "\mu"] & m\punctuation{.}
  \end{tikzcd}
\] Again, the domains are related by the canonical isomorphisms $\lambda$ and
$\rho$. We can write this equality as commutativity of the diagram \[
  \begin{tikzcd}
    I\otimes m\ar[r, "\eta\otimes 1_m"]\ar[dr, "\lambda_m"'] & m\otimes m\ar[d,
    "\mu"] & m\otimes I\ar[l, "1_m\otimes\eta"']\ar[dl, "\rho_m"]\\
                                        & m\punctuation{,}
  \end{tikzcd}
\]
where we suppress the identity $1_m$, which could appear at the bottom of the
diagram.

In the following two sections, we will give several examples of definitions---in
particular \emph{braided monoidal categories}, \emph{symmetric monoidal
categories}, and \emph{monoidal functors}---whose coherence axioms are better
understood diagramatically than symbolically. While the axioms themselves are
useful to understand, for our purposes it is more important to understand the
intuition of the structures in question and their relationship to the graphical
calculi. If the reader understands how the diagrams relate to each other, it is
generally safe to move on even without a complete understanding of how they are
translated into symbolic equalities. The interested reader may find a symbolic
statement of the coherence laws in~\cite[Chapter XI]{maclane-1971}.

\subsection{Symmetry}
\label{sec:smcs}

While monoidal categories are necessarily associative, nothing in the definition
guarantees that the monoidal product is commutative. As usual, it is too strict
to ask for commutativity $x\otimes y = y\otimes x$ as an equational axiom. When
we want commutativity, we instead add a natural isomorphism $\gamma_{x,y}:
x\otimes y\to y\otimes x$, called the \emph{braiding}, to the data, so named
because of its string-diagrammatic representation: \[
  \begin{pic}
    \draw (0,0) node[left] {$x$} to[out=80,in=-100] (.6,1) node[right] {$x$};
    \draw[style=braid] (.6,0) node[right] {$y$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.} to[out=100,in=-80] (0,1) node[left] {$y$};
  \end{pic}
\]

This notation suggests a nice graphical representation of the inverse
$\gamma_{x,y}^{-1}: y\otimes x\to x\otimes y$:
\[
  \begin{pic}
    \draw (.6,0) node[right] {$x$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.} to[out=100,in=-80] (0,1) node[left] {$x$};
    \draw[style=braid] (0,0) node[left] {$y$} to[out=80,in=-100] (.6,1) node[right] {$y$};
  \end{pic}
\]
In particular, $\gamma_{x,y}^{-1}$ is indeed an inverse asserts that \[
  \begin{pic}
    \draw (0,0) node[left] {$x$} to[out=80,in=-90] (.6,1) to[out=90,in=-80] (0,2) node[left] {$x$};
    \draw[style=braid] (.6,0) node[right] {$y$} to[out=100,in=-90] (0,1) to[out=90,in=-100] (.6,2) node[right] {$y$};
  \end{pic} = \begin{pic}
    \draw (0,0) node[left] {$x$} to (0,1) node[left] {$x$};
    \draw (.4,0) node[right] {$y$} to (.4,1) node[right] {$y$};
  \end{pic} = \begin{pic}
  \draw (.6,0) node[right] {$y$} node[right, xshift=3mm, yshift=3mm] {\normalsize,} to[out=100,in=-90] (0,1) to[out=90,in=-100] (.6,2) node[right] {$y$};
    \draw[style=braid] (0,0) node[left] {$x$} to[out=80,in=-90] (.6,1) to[out=90,in=-80] (0,2) node[left] {$x$};
    \end{pic}
\] as is suggested by our geometric intuitions\footnote{
  It is, in fact, possible to formalize string diagrams geometrically, using the
  technology of knot theory; this is due to~\cite{joyal-street-1991}.
}.

Note that there are two possible braids we could draw $x\otimes y\to y\otimes x$, 
each of which is \emph{a priori} a different morphism: \[
  \gamma_{x,y} = \begin{pic}
    \draw (0,0) node[left] {$x$} to[out=80,in=-100] (.6,1) node[right] {$x$};
    \draw[style=braid] (.6,0) node[right] {$y$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize,} to[out=100,in=-80] (0,1) node[left] {$y$};
  \end{pic}\quad
  \gamma_{y,x}^{-1} = \begin{pic}
    \draw (.6,0) node[right] {$y$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.} to[out=100,in=-80] (0,1) node[left] {$y$};
    \draw[style=braid] (0,0) node[left] {$x$} to[out=80,in=-100] (.6,1) node[right] {$x$};
  \end{pic}
\]

What coherence axioms should this satisfy---in other words, what manipulations
should we be allowed to make to the our diagrams? It should certainly be coherent with
the identity:
\begin{equation}\label{eqn:braid id}
  \begin{pic}
    \draw (0,0) node[left] {$x$} to (0, .5) to[out=80,in=-100] (.6,1.5) to (.6,2) node[right] {$x$};
    \draw[style=braid] (.6,.5) node[state,scale=.5] {} to[out=100,in=-80] (0,1.5) node[rotate=180,state,scale=.5] {};
    \end{pic} = \begin{pic}
    \draw(0,0) node[left] {$x$} to (0,1) node[left] {$x$};
    \end{pic} \hspace{.7em} = \begin{pic}
    \draw (0,.5) node[state,scale=.5] {} to[out=100,in=-80] (.6,1.5) node[rotate=180,state,scale=.5] {};
    \draw[style=braid] (.6,0) node[right] {$x$} node[right, xshift=3mm, yshift=3mm]
    {\normalsize.} to (.6, .5) to[out=80,in=-100] (0,1.5) to (0,2) node[left] {$x$};
    \end{pic}
  \end{equation}

It should also not matter if we braid twice, or braid once with a product, in the
sense that: \begin{equation}\label{eqn:braid coherence}
  \begin{pic}
    \draw (0,0) node[left] {$x$} to[out=80,in=-90] (.6,1) to[out=90,in=-90] (1.2,2) node[right]{$x$};
    \draw[style=braid] (.6,0) node[right] {$y$} to[out=100,in=-90] (0,1) to (0,2) node[left]{$y$};
    \draw[style=braid] (1.2,0) node[right] {$z$} to (1.2,1) to[out=90,in=-90] (.6,2) node[left]{$z$};
  \end{pic} = \begin{pic}
    \draw (0,0) node[left] {$x$} to[out=80,in=-100] (.6,1) node[right] {$x$};
    \draw[style=doublebraid,text=black] (.6,0) node[right] {$y\otimes z$} to[out=100,in=-80] (0,1) node[left] {$y\otimes z$};
  \end{pic}
  \quad\quad\text{and}\quad\quad
  \begin{pic}
    \draw (0,0) node[left] {$x$} to (0,1) to[out=90,in=-90] (.6,2) node[right]{$x$};
    \draw (.6,0) node[left] {$y$} to[out=80,in=-90] (1.2,1) to (1.2,2) node[right]{$y$};
    \draw[style=braid] (1.2,0) node[right] {$z$} to[out=100,in=-90] (.6,1) to[out=90,in=-90] (0,2) node[left]{$z$};
  \end{pic} = \begin{pic}
    \draw[double] (0,0) node[left] {$x\otimes y$} to[out=80,in=-100] (.6,1) node[right] {$x\otimes y$};
    \draw[style=braid] (.6,0) node[right] {$z$} node[right,xshift=3mm,
    yshift=3mm] {\normalsize.} to[out=100,in=-80] (0,1) node[left] {$z$};
  \end{pic}
\end{equation} The previous two axioms define a \emph{braided monoidal category}.

We will care primarily about the stronger case in which
\begin{equation}\label{eqn:braid symmetry}
  \begin{pic}
    \draw (0,0) to[out=80,in=-100] (.6,1);
    \draw[style=braid] (.6,0) to[out=100,in=-80] (0,1);
  \end{pic} = \begin{pic}
    \draw (.6,0) node[right, xshift=3mm, yshift=1mm] {\normalsize,} to[out=100,in=-80] (0,1) ;
    \draw[style=braid] (0,0) to[out=80,in=-100] (.6,1);
  \end{pic}
  \end{equation} i.e. that $\gamma_{x,y} = \gamma_{y,x}^{-1}$. We may then unambiguously write \[
  \begin{pic}
    \draw (.6,0)  node[right, xshift=3mm, yshift=1mm] {\normalsize;} to[out=100,in=-80] (0,1);
    \draw (0,0) to[out=80,in=-100] (.6,1);
  \end{pic}
\]we call this map the \emph{symmetry}.

\begin{dfn}[symmetric monoidal category]\label{def:symmetric monoidal category}
  A \emph{symmetric monoidal category} is a monoidal category $\cat{C}$,
  together with a natural isomorphism $\gamma_{x,y}: x\otimes y\to y\otimes x$,
  called the \emph{braiding} or \emph{symmetry}, satisfying the coherence laws
  of \Cref{eqn:braid id,eqn:braid coherence,eqn:braid symmetry}.
\end{dfn}

\begin{ex}
  The categories $\scat{Set}$, $\scat{Vect}_\kk$, and $\scat{Cat}$, with the
  monoidal structure defined in \Cref{sec:monoidal examples},
  are all symmetric monoidal.
\end{ex}

\subsection{Monoidal Functors}
\label{sec:monoidal-functors}

Let us work out what a ``monoidal functor'' between monoidal categories should be. Let
$\cat{C}$ and $\cat{D}$ be monoidal categories, and annotate their respective
data with subscripts, so that for instance $\otimes_\cat{C}$ is the monoidal
product of $\cat{C}$. Let $F: \cat{C}\to\cat{D}$ be a functor.

As usual, we do not want to ask that $Fx\otimes_{\cat{D}} Fy =
F(x\otimes_\cat{C} y)$, because categorical axioms tend only to hold up to
natural transformations. A sensible choice is thus to ask for a natural
isomorphism $\phi_{x,y}: Fx\otimes_{\cat{D}} Fy\to F(x\otimes_\cat{C} y)$,
satisfying certain coherence identities. However, even this is often too strong.
For instance, $\texttt{Maybe}$ does not satisfy this definition: while there is
a map
\begin{align*}
  \texttt{Maybe}X\otimes\texttt{Maybe}Y&\to\texttt{Maybe}(X\otimes Y) \\
  (x, y)\mapsto (x, y) \quad (x, \bot&)\mapsto \bot \quad (\bot, y)\mapsto \bot,
\end{align*}
and so $\texttt{Maybe}$ respects the monoidal structure in some weaker sense,
this map is not an isomorphism. Instead, we will often just ask $\phi_{x,y}$ to
be a morphism, which tells us how to ``convert'' monoidal products in $\cat{D}$
into monoidal products in the model of $\cat{D}$\footnote{
  A careful reader may wonder why the morphism goes from $\otimes_\cat{D}$ to
  $\otimes_\cat{C}$, rather than the other way. We do sometimes study the
  latter under the name \emph{colax monoidal functors}, but the former is far
  more common. One way to understand this is that the former direction says that
  product in $\cat{D}$ is in some sense ``more precise'' than product in
  $\cat{C}$, which tends to be why the functor is interesting in the first
  place. 
}. We also need $F$ to be
compatible with the monoidal unit, for which we ask for an morphism $\phi:
I_\cat{D}\to FI_\cat{C}$.

There is a graphical calculus for monoidal functors due
to~\cite{cockett-seely-1999}; we give a presentation
following~\cite{mellies-2006}. The idea is to represent functors as colored
boxes which separate the ``inside world'' of $\cat{C}$ from the ``outside world''
of $\cat{D}$, so that we may depict the morphism $Ff: Fx\to Fy$ as \[
  \begin{pic}
    \node[morphism] (f) at (0,0) {$f$};
    \draw (f.south) to ++(0,-.9) node[left] {$Fx$} node[right, xshift=6mm, yshift=5mm] {\normalsize.};
    \draw[functor=cyan] (-.5,-.8) rectangle (.5, .8);
    \draw (f.north) to ++(0,.9) node[left] {$Fy$};
  \end{pic}
\]

If $F$ is monoidal, we write the morphism $\phi_{x,y}$ as \[
  \begin{pic}
    \draw[functor=cyan] (-.5, -.3) -- (0, -.3) -- (0, .2) -- (.5, .2) -- (.5,
      -.3) -- (1, -.3) -- (1, .7) -- (-.5, .7) -- cycle;
    \draw[rounded corners] (-.25, -.75) node[left] {$Fx$} -- (-.25, .45) --
      (.75, .45) -- ++(0, -1.2) node[right] {$Fy$} node[right, xshift=4mm, yshift=5mm] {\normalsize,};
    \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(x\otimes_\cat{C} y)$};
  \end{pic}
\] the idea being that at first the blue-shaded wires $x$ and $y$ are connected by white
space representing the product $\otimes_{\cat{D}}$, and then it becomes blue space
representing the product $\otimes_\cat{C}$. We often don't write the top part of this
morphism, instead doing manipulation inside $\cat{C}$, which happens in the blue
shading. For instance, coherence with the identity states that
\begin{equation}\label{eqn:monoidal functor id}
  \begin{pic}
    \draw[functor=cyan] (-.6, -.3) -- (0, -.3) -- (0, .2) -- (.3, .2) -- (.3,
      -.3) -- (.9, -.3) -- (.9, 1) -- (-.6, 1) -- cycle;
      \draw (-.3, 1.5) node[left] {$Fx$} -- ++(0, -2.5) node[left] {$Fx$};
    \draw (.6, .45) node[state,scale=.5,rotate=180] {} -- ++(0, -1.) node[state,scale=.5] {};
    \end{pic}\hspace{.5em} = \hspace{.5em}\begin{pic}
      \draw(0,0) to (0,1.5);
      \end{pic}\hspace{.5em} = \hspace{.5em} \begin{pic}
    \draw[functor=cyan] (-.6, -.3) -- (0, -.3) -- (0, .2) -- (.3, .2) -- (.3,
      -.3) -- (.9, -.3) -- (.9, 1) -- (-.6, 1) -- cycle;
      \draw (.6, 1.5) node[right] {$Fx$} -- ++(0, -2.5) node[right] {$Fx$} node[right, xshift=5mm,yshift=7mm]
      {\normalsize.};
    \draw (-.3, .45) node[state,scale=.5,rotate=180] {} -- ++(0, -1.) node[state,scale=.5] {};
  \end{pic}
\end{equation} Similarly, compatibility with the associator asserts that
\begin{equation}\label{eqn:monoidal functor assoc}
  \begin{pic}
    \draw[functor=cyan] (-1.25,-.5) -- (-.75,-.5) -- (-.75, 0) -- (-.25, 0) --
    (-.25, -.5) -- (.25, -.5) -- (.25, .5) -- (.75, .5) -- (.75, -.5) -- (1.25,
    -.5) -- (1.25, 1) -- (-1.25, 1) -- cycle;
    \draw[rounded corners] (-1, -.9) node[left] {$Fx$} -- (-1, .25) --
      (0, .25) -- (0, -.9) node[left] {$Fy$};
    \draw[rounded corners] (-.5, .25) -- (-.5, .75) -- (1, .75) -- (1, -.9)
    node[left] {$Fz$};
    \draw (.25, .75) -- (.25, 1.5) node[left] {$F((x\otimes_\cat{C} y)\otimes_\cat{C} z)$};
    % \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(x\otimes_\cat{C} y)$};
  \end{pic} = 
  \begin{pic}
    \draw[functor=cyan] (1.25,-.5) -- (.75,-.5) -- (.75, 0) -- (.25, 0) --
    (.25, -.5) -- (-.25, -.5) -- (-.25, .5) -- (-.75, .5) -- (-.75, -.5) -- (-1.25,
    -.5) -- (-1.25, 1) -- (1.25, 1) -- cycle;
    \draw[rounded corners] (1, -.9) node[right] {$Fz$} node[right, xshift=5mm,
    yshift=7mm] {\normalsize,} -- (1, .25) --
      (0, .25) -- (0, -.9) node[right] {$Fy$};
    \draw[rounded corners] (.5, .25) -- (.5, .75) -- (-1, .75) -- (-1, -.9)
    node[right] {$Fx$};
    \draw (-.25, .75) -- (-.25, 1.5) node[right] {$F(x\otimes_\cat{C} (y\otimes_\cat{C} z))$};
    % \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(x\otimes_\cat{C} y)$};
  \end{pic}
\end{equation}
while when $\cat{C}$ and $\cat{D}$ are symmetric monoidal, we might also want
compatibility with the symmetry: \begin{equation}\label{eqn:monoidal functor symmetry}
  \begin{pic}
    \draw (.8,0) node[right] {$Fy$} to[out=100,in=-90] (0,1);
    \draw (0,0) node[left] {$Fx$} to[out=80,in=-90] (.8,1);
    \draw[functor=cyan] (-.2, 1) -- (-.2, 2.05) -- (1, 2.05) -- (1, 1) --
    (.6, 1) -- (.6, 1.45) -- (.2, 1.45) -- (.2, 1) -- cycle;
    \draw[rounded corners] (.8,1)  -- (.8,1.7) --
      (0, 1.7) -- (0, 1);
    \draw (.4, 1.7) -- (.4, 2.6) node[left] {$F(y\otimes_\cat{C} x)$};
  \end{pic}=\hspace{.1em}
  \begin{pic}
    \draw (.8,0) node[right] {$Fy$} node[right,xshift=5mm,yshift=7mm] {\normalsize.} to (.8, .4) to[out=90,in=-90] (0,1.4);
    \draw (0,0) node[left] {$Fx$} to (0, .4) to[out=90,in=-90] (.8,1.4);
    \draw[functor=cyan] (-.2, .2) -- (-.2, 2.05) -- (1, 2.05) -- (1, .2) --
    (.6, .2) -- (.6, .65) -- (.2, .65) -- (.2, .2) -- cycle;
    \draw[rounded corners] (.8,1.4)  -- (.8,1.7) --
      (0, 1.7) -- (0, 1.4);
    \draw (.4, 1.7) -- (.4, 2.6) node[right] {$F(y\otimes_\cat{C} x)$};
  \end{pic}
\end{equation}

\begin{dfn}[monoidal functor]\label{def:monoidal functor}
  A functor $F: \cat{C}\to\cat{D}$ between monoidal categories is \emph{lax
  monoidal}, or just \emph{monoidal}, if there is a natural transformation
  $\phi_{x,y}: Fx\otimes_\cat{D} F_y\to F(x\otimes_\cat{C} y)$ and a morphism
  $\phi: I_\cat{D}\to FI_\cat{C}$ satisfying
  \Cref{eqn:monoidal functor id,eqn:monoidal functor assoc}. It is
  further \emph{symmetric} if $\cat{C}$ and $\cat{D}$ are
  symmetric monoidal categories and the data satisfies
  \Cref{eqn:monoidal functor symmetry}.
  Finally, it is \emph{strong monoidal} if $\phi_{x,y}$ and $\phi$ are
  isomorphisms and \emph{strict monoidal} if they are identities. 
\end{dfn}

\begin{ex}Again, there are many familiar monoidal functors.
  \begin{itemize}
    \item $\texttt{Maybe}$ is (lax) symmetric monoidal, but not strong
      monoidal.
    \item \label{ex:monoidal-functors} For any monoidal category $\cat{C}$, $\cat{C}(I, -)$ is monoidal, with
      the coherence \begin{align*}
        \phi_{x,y}: \cat{C}(I, x)\times\cat{C}(I, y)&\to \cat{C}(I, x\otimes y) \\
        (f, g)
         &\mapsto
        \begin{pic}
          \node[state,scale=.75] (f) at (0,0) {$f$};
          \draw (f.north) to ++(0,.6) node[left] {$x$};
          \node[state,scale=.75] (g) at (.7,0) {$g$};
          \draw (g.north) to ++(0,.6) node[right] {$y$};
        \end{pic}
        .
      \end{align*}
      If $\cat{C}$ is symmetric, then so too is $\cat{C}(I, -)$.
    \item The $\kk$-span functor is strong symmetric monoidal. In fact, this is
      one definition of the tensor of vector spaces: \[
        \text{span}_\kk X\otimes \text{span}_\kk Y = \text{span}_\kk(X\times Y).
      \]
    \item The forgetful functor $U: \scat{Vect}_\kk\to\scat{Set}$ is monoidal,
      with $\phi_{X,Y}: U(X)\times U(Y)\to U(X\otimes Y)$ given by the
      universal property of the tensor product of vector spaces, or explicitly
      by the map $(v, w)\mapsto v\otimes w$.
  \end{itemize}
\end{ex}

\subsection{Multicategories}

% cite~\cite{yau-2016}

While monoidal categories are extremely elegant structures, as seen
in~\Cref{ex:set-monoidal} it can be tedious to construct all the
required data. In this section, we give a useful tool for constructing monoidal
categories via a related structure called a \emph{multicategory}, which is just
a category whose morphisms may take multiple inputs.

As usual, it is often easier to understand the algebraic structure
diagramatically than symbolically. A morphism in a multicategory looks like \[
  \begin{pic}
    \multimorphism[0,0][f][$x_1$][$x_n$][$y$\normalsize.]
  \end{pic}
\]
Such morphisms can be composed when the domains and codomains line up, as in \[
  \begin{pic}
    \multimorphism[0,1.2][f_1][][][]
    \multimorphism[4,0][g][][][\normalsize.]
    \multimorphism[0,-1.2][f_n][][][]
    % \draw ($(f_1.east)+(.5,0)$) -- ($(g.north west)+(-.5,0)$);
    \wire[f_1][g][north]
    \wire[f_n][g][south]
    \node[anchor=center,yshift=1mm] at (0,0) {\vdots};
  \end{pic}
\]
This composition is (strictly) associative, which just means that the composite \[
  \begin{pic}
    \multimorphism[0,3.6][f^1_1][][][]
    \multimorphism[4,2.4][g_1][][][]
    \multimorphism[0,1.2][f^1_{m_1}][][][]
    \wire[f^1_1][g_1][north]
    \wire[f^1_{m_1}][g_1][south]

    \multimorphism[0,-1.2][f^n_1][][][]
    \multimorphism[4,-2.4][g_n][][][]
    \multimorphism[0,-3.6][f^n_{m_n}][][][]
    \wire[f^n_1][g_n][north]
    \wire[f^n_{m_n}][g_n][south]

    \multimorphism[10,0][h][][][]
    \wire[g_1][h][north]
    \wire[g_n][h][south]
    % \node[anchor=center,yshift=1mm] at (0,0) {\vdots};
  \end{pic}
\]is well-defined.

We now state the explicit definition.

\begin{dfn}[multicategory]\label{def:multicategory}
  A \emph{multicategory} consists of the following data:
  \begin{itemize}
    \item a collection of objects $\cat{C}$;
    \item for any (possibly empty) finite list of objects $x_1, \dots, x_n\in\cat{C}$ and any
      object $y\in\cat{C}$, a collection of morphisms $\cat{C}(x_1,\dots,x_n;y)$;
    \item for any finite list of morphisms $f_1,\dots,f_n$, and any morphism
      $g$ such that the domain of $g$ has length $n$ and the $i$th object in
      its domain is the codomain of $f_i$, a composite morphism
      $g\circ(f_1,\dots,f_n)$ whose domain is the concatenation of the domains
      of the $f_i$s and whose codomain is the codomain of $g$;
    \item for any object $x\in\cat{C}$, a morphism $1_x\in\cat{C}(x;x)$.
  \end{itemize}
  This data must satisfy the following associativity and unitality axioms:
  \begin{itemize}
    \item for any morphism $(x_1,\dots,x_n)\xto{f} y$, \[
        1_y\circ f = f = f\circ(1_{x_1},\dots,1_{x_n});
      \]
    \item for any morphisms
      $h,g_1,\dots,g_n,f_1^1,\dots,f_1^{m_1},\dots,f_n^1,\dots,f_n^{m_n}$ where
      the composites are defined,
      \begin{align*}
      &h\circ(g_1\circ(f_1^1,\dots,f_1^{m_1}),\dots,g_n\circ(f_n^1,\dots,f_n^{m_n})) \\
      &= (h\circ(g_1,\dots,g_n))\circ(f_1^1,\dots,f_1^{m_1},\dots,f_n^1,\dots,f_n^{m_n}).
      \end{align*}
  \end{itemize}
\end{dfn}

\begin{ntn}
  The \emph{arity} of a morphism in a multicategory is the length of its domain
  list.
\end{ntn}

\begin{ex}
  Any category is a multicategory, with no morphisms of arity other
  than one. Such multicategories are called \emph{unary}.
\end{ex}

\begin{ex}
  Any strict monoidal category has an \emph{underlying multicategory}, where the
  maps $x_1,\dots,x_n\to y$ are exactly the maps $x_1\otimes\dots\otimes x_n\to
  y$.
\end{ex}

We also want to consider a kind of commutativity of domain-forming in
multicategories. The basic idea is that we should be able to permute the domain
of a hom-set and receive a canonically isomorphic hom-set. 

\begin{dfn}
  A \emph{symmetric multicategory} is a multicategory equipped with, for each
  $n$, a right-action of the symmetric group $S^n$ on hom-sets of arity $n$,
  i.e. for $\sigma\in S^n$, a map  \[
    (-\cdot \sigma): \cat{C}(x_1,\dots,x_n; y)\to\cat{C}(x_{\sigma(1)},\dots,x_{\sigma(n)}; y)
  \] which commutes with the group structure of $S^n$, in that \[
    (f\cdot \sigma)\cdot \tau = f\cdot(\sigma\tau),\quad\quad f = f\cdot 1.
  \] This action must respect composition, in that, whenever the types line up, \[
    (g\cdot \sigma)\circ(f_{\sigma(1)}\cdot\tau_{\sigma(1)},\dots,f_{\sigma(n)}\cdot\tau_{\sigma(n)}) =
    (g\circ(f_1,\dots,f_n))\cdot(\sigma\circ(\tau_{\sigma(1)},\dots,\tau_{\sigma(n)}).
  \]
\end{dfn}

This last equality requires some explanation. We have a map $g$ and a
composition-compatible list of maps $f_1,\dots,f_n$. If we permute the inputs to
$g$ by $\sigma$, then we need to permute the $f_i$s in the same way. In the most general
case, we could also have further permutations $\tau_i$ to the inputs of each of the
$f_i$s; we need to permute those by $\sigma$ as well. This gives us the left
hand side.

Of the right hand side, we first take the composite of $g$ and the $f$s, and
then want to use the data of $\sigma$ and the $\tau_i$s to permute the inputs to
this composite morphisms. The point is that it's sufficient to first permute
each bundle of inputs by $\sigma$, and then permute each input to each bundle by
the appropriate $\tau$. In the case where all the maps have arity $2$ and all
the permutations are the transposition $(12)$, this equality is as follows:
\[
  \begin{pic}
    \twomultimorphism[0,.7][f_2][][][]
    \twomultimorphism[2.5,0][g][][][]
    \twomultimorphism[0,-.7][f_1][][][]
    % \draw ($(f_1.east)+(.5,0)$) -- ($(g.north west)+(-.5,0)$);
    \wire[f_1][g][north]
    \wire[f_2][g][south]

    \draw ($(f_2.north west)+(-.3,0)$) to[out=180,in=0] ($(f_2.south west)+(-1,0)$);
    \draw ($(f_2.south west)+(-.3,0)$) to[out=180,in=0] ($(f_2.north west)+(-1,0)$);
    \draw ($(f_1.north west)+(-.3,0)$) to[out=180,in=0] ($(f_1.south west)+(-1,0)$);
    \draw ($(f_1.south west)+(-.3,0)$) to[out=180,in=0] ($(f_1.north west)+(-1,0)$);
  \end{pic}=\quad
  \begin{pic}
    \narrowtwomultimorphism[0,.7][f_1][][][]
    \twomultimorphism[2,0][g][][][\normalsize.]
    \narrowtwomultimorphism[0,-.7][f_2][][][]
    % \draw ($(f_1.east)+(.5,0)$) -- ($(g.north west)+(-.5,0)$);
    \wire[f_1][g][north]
    \wire[f_2][g][south]

    \draw ($([yshift=-2mm]f_1.north west)+(-.3,0)$) to[out=180,in=0] ($(f_2.north
    west)+(-1.5,0)$) to[out=180,in=0] ($(f_2.south west)+(-2.5,0)$);

    \draw ($([yshift=2mm]f_1.south west)+(-.3,0)$) to[out=180,in=0] ($(f_2.south
    west)+(-1.5,0)$) to[out=180,in=0] ($(f_2.north west)+(-2.5,0)$);

    \draw ($([yshift=-2mm]f_2.north west)+(-.3,0)$) to[out=180,in=0] ($(f_1.north
    west)+(-1.5,0)$) to[out=180,in=0] ($(f_1.south west)+(-2.5,0)$);

    \draw ($([yshift=2mm]f_2.south west)+(-.3,0)$) to[out=180,in=0] ($(f_1.south
    west)+(-1.5,0)$) to[out=180,in=0] ($(f_1.north west)+(-2.5,0)$);
    % \draw ($(f_1.south west)+(-.5,0)$) to[out=180,in=0] ($(f_1.north west)+(-1.5,0)$);
    % \draw ($(f_2.north west)+(-.5,0)$) to[out=180,in=0] ($(f_2.south west)+(-1.5,0)$);
    % \draw ($(f_2.south west)+(-.5,0)$) to[out=180,in=0] ($(f_2.north west)+(-1.5,0)$);
  \end{pic}
\]


\section*{Bibliographic Notes}

There are many different ways to visually present string diagrams. In
\Cref{sec:string diagrams}, we have
followed the style of~\cite{broadbent-karvonen-2022} very closely. We program
our diagrams in part using the Ti\textit{k}Z code
of~\cite{broadbent-karvonen-2022}, and code due to Zajj Daugherty.
