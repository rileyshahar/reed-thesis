i theory of cryptography should define at least four things: computation,
protocols, adversarial behavior, and security. A major advantage of categorical
models of cryptography is that they conveniently separate these issues. In
particular, we have some underlying category of computations, while we represent
categories of protocols with certain constructions on categories; as such, our
notions of interaction and security are completely independent of the underlying
model of computation.

There have been several attempts to use category theory for
cryptography~\cite{hines-2020,pavlovic-2012,pavlovic-2014,stay-vicary-2013,bkm-2019,bmr-2019},
but all on the level of individual protocols; except
for~\cite{broadbent-karvonen-2022}, none of them handle composition. The area of
categorical quantum mechanics is especially active
\cite{abramsky-coecke-2004,coecke-perdrix-2012,heunen-vicary-2014,coecke-kissinger-2017,chitambar-gour-2019},
in which categorical structures are used to give semantics about quantum
protocols; most of the tools we develop in~\Cref{sec:protocols}
originated in this line of work.

This section is primarily an exposition of the model of categorical cryptography
due to \citeauthor{broadbent-karvonen-2022}~\cite{broadbent-karvonen-2022}. We
will be clear where we believe our contributions to be original, but even there
are hugely indebted to their work. As usual, any mistakes are our own.

\section{Computation}
\label{sec:computation}

The categorical theory of computation is well-developed, going back at least to
the work of Jim Lambek and several contemporaries around the
1970s~\cite{lambeck-1974,lambeck-1980,lawvere-1969,seely-1984}. The essential
idea generalizes~\Cref{ex:functional programming}: objects are types
and morphisms are typed computations. The most disciplined approach is to
consider the categorical structure needed to model certain forms of computation, so that
for instance models of simply typed computation are \emph{bicartesian closed
categories}~\cite{lambeck-1974}, of linear computation are \emph{star-autonomous
categories}~\cite{seely-1989}, of quantum computation are \emph{compact-closed
categories}~\cite{abramsky-coecke-2004}, and of probabilistic computation are \emph{Markov
categories}~\cite{fritz-2020}. We will not review this approach here. Instead,
our focus will be on constructing specific categorical models of forms of
computations of interest to cryptographers.

\subsection{Deterministic Computation}

We would like a category of deterministic computations to have computable
functions as morphisms. However, the natural choice, taking sets as objects and
computable functions as morphisms, is actually not yet precise. The first issue
is that there are several distinct notions of computability on uncountable sets.
Each such notion forms a category, but formal definitions are outside our scope,
as cryptographers tend not to care about uncountable sets anyway\footnote{These
issues are studied in the field of \emph{computable analysis}; see for instance
the PhD thesis of Andre Bauer~\cite{bauer-2000}.}.

We can resolve this issue simply, by limiting ourselves to finite sets, in which
case every function is computable (simply by a lookup table):

\begin{dfn}[category of finite sets]
  The \emph{category of finite sets}, $\scat{FinSet}$, has finite sets as
  objects and functions as morphisms.
\end{dfn}

However, we often want to work with larger input spaces. The natural guess is to
take countable sets and computable functions. The issue here is one of encoding:
there is a canonical notion of computability on the set of finite binary
strings, but elements of arbitrary sets do not generally have canonical
encodings as binary strings. We could solve this issue by limiting
ourselves to working only with binary strings:
\begin{dfn}[category of computable binary functions]
  The \emph{category of computable binary functions} \scat{BinComp} has sets of binary strings
  $A\subseteq\bin^*$ as objects and computable functions as morphisms.
\end{dfn}

In practice, however, we like to think of computations as working over arbitrary
sets, which in particular may have more algebraic structure than sets of binary
strings. Our strategy, following~\cite{pavlovic-2014}, will be to work over sets
with fixed binary encodings.
\begin{dfn}[binary-encoded set]
  A \emph{binary-encoded set} is a set $X$ together with an injection
  $\denote{-}_X: X\to\bin^*$, called the \emph{encoding}.
\end{dfn}

Note that every binary-encoded set is finite or countable; as such, we avoid the
issues with uncountable sets mentioned above.

\begin{ntn}
  When the context is clear, we will generally drop the subscript of
  $\denote{-}$. We write $\denote{X}$ for the image of $\denote{-}_X$, i.e.
  $\denote{X} = \{s\in\bin^*: s = \denote{x}\text{ for some }x\in X\}$.
\end{ntn}

Given a function $f: X\to Y$ of binary-encoded sets, we can define a function
  \begin{align*}
    \denote{f} \colon \denote{X} &\to \denote{Y}\\
    \denote{x} &\mapsto \denote{f(x)}.
  \end{align*}
This is well-defined exactly because $\denote{-}_X$ is injective.

\begin{dfn}[category of computable functions]
  A function $f: X\to Y$ of binary-encoded sets is \emph{computable} if
  $\denote{f}$ is computable. The \emph{category of computable functions},
  \scat{Comp}, has binary-encoded sets as objects and computable functions as
  morphisms.
\end{dfn}

It needs to be shown that this is a category. First, the identities
$1_X$ are computable, as $\denote{1_X} = 1_{\denote{X}}$ is computable. Second,
the composite of computable functions is computable, as the composition of
computable binary functions is computable, and composition is preserved by
$\denote{-}$. As this argument indicates, there is a functor $\denote{-}:
\scat{Comp}\to\scat{BinComp}$; in fact this functor is an \emph{equivalence of
categories}. Nevertheless, the expanded perspective provided by $\scat{Comp}$ will be
convenient.

Finally, we now define a symmetric monoidal structure on \scat{Comp}.
In particular, for two binary-encoded sets $X$ and $Y$, we would like to define
the product $X\otimes Y$ as the set $X\times Y$, but it is unclear what
$\denote{-}_{X\times Y}$ should be. We first fix an injective pairing map
$\<-,-\>: \bin^*\times\bin^*\to \bin$ which is efficiently computable\footnote{%
  One such map is computed as follows: given inputs $(m,n)$, start by encoding the
  length of $m$ in $2\log\log m$ bits: first write a bit of the length, then
  write a $1$ if the length continues and a $0$ if it doesn't. Now knowing the
  length of $m$, we can append the binary representation of $m$ and then $n$,
  which takes $O(\log m + \log n) = O(\log (mn))$ bits. Since $\log\log m =
  O(\log m)$, in total this algorithm takes $O(\log(mn))$ bits, and just writes
  across the tape, hence is computable in linear time.
}. We can then define $\denote{(x, y)} = \<\denote{x}, \denote{y}\>$; it is a
standard check that this defines a symmetric monoidal structure inherited from
$\scat{Set}$\footnote{
  Here is a more abstract way to see this. A suitable pairing function $\<-,-\>$
  turns $\{0,1\}$ into an internal commutative monoid in $\scat{Set}$. In other
  work, we show that the category of subobjects of any internal monoid is a
  monoidal category~\cite{shahar-zdancewic-2024}. The construction here is
  approximately an application of that general theorem.
}.

\subsection{Probabilistic Computation}

Again, there is some subtlety with probabilistic computation. Even in the case
of finite sets, not every stochastic function is computable by algorithms with
access to fair coin flips\footnote{
  We believe this is a slight conceptual problem with the strategy
  of~\cite[Section 6]{broadbent-karvonen-2022}, which models unbounded
  probabilistic computation in the category of finite sets and stochastic
  functions: this category is too powerful to reasonably model computation. This
  does not pose a technical issue in their specific example.
}. However, there is again a standard notion of computable stochastic function
of binary strings, so we can proceed much as before, defining:
\begin{dfn}[category of computable stochastic functions]
  The \emph{category of computable stochastic functions}, \scat{BinCompStoch},
  has sets of binary strings as objects and computable stochastic functions as
  morphisms.

  A stochastic function $f:X\to Y $ between binary-encoded sets is
  \emph{computable} if $\denote{f}$ is computable. The \emph{category of
  computable stochastic functions} \scat{CompStoch} has binary-encoded sets as
  objects and computable stochastic functions as morphisms.
\end{dfn}

Again, it needs to be shown that this is a category. The identities are
computable (and stochastic, since every deterministic function is stochastic),
and composition commutes with $\denote{-}$, so the composite of computable
functions is computable. Furthermore, this category is symmetric monoidal, with
pairing of encodings as in \scat{Comp}.

We give a more abstract characterization of this category. There
are only countably many computable probability distributions on $\bin^*$, since
there are only countably many Turing machines. Fix a choice $\varphi$ of
bijection witnessing this fact. Note further that any probability distribution
$P$ on a binary-encoded set $X$ induces a probability distribution
$\denote{P}$ on $\bin^*$ by \[
  \Pr_{s\from \denote{P}}[s = s_0] = \Pr_{x\from P}[\denote{x} = s_0].
\]
There is now a monad $G_c: \scat{Comp}\to\scat{Comp}$, which we call the
\emph{computable Giry monad}, which takes any binary-encoded set $X$ to the set
of computable probability distributions on $X$, i.e. those such that
$\denote{P}$ is a computable probability distribution on $\bin^*$, with encoding
given by $\denote{P}_{G_c X} = \varphi(\denote{P}_X)$. Given $f: X\to Y$ and
$P\in G_c X$, we define the probability distribution $G_c f(P)$ on $Y$ by
\[
  \Pr_{y\from G_c f(P)}[y = y_0] = \Pr_{x\from P}[f(x) = y_0].
\]
The unit of $G_c$ is the function $X\to G_c X$ taking $x$ to the point
distribution at x. The multiplication is the function $\mu_X: G_c G_c X\to G_c X$
acting by summation: given a probability distribution $Q$ on $G_c X$, we define
a distribution $\mu_X (Q)$ on $X$ by \begin{equation*}\label{eqn:giry-sum}
  \Pr_{x\from \mu_X(Q)}[x = x_0] = \sum_{P_0\in G_c X} \Pr_{P\from Q}[P =
  P_0]\Pr_{x\from P}[x = x_0],
\end{equation*}which converges because $Q$ is a probability distribution. The proofs of
functorality and the monad laws as exactly as for the ordinary Giry
monad~\cite{giry-1982}, so we do not give them here. Now \scat{CompStoch} is in
fact (isomorphic to) the Kleisi category of $G_c$.

\subsection{Efficient and Effectful Computation}

Suppose that we are given some wide subcategory \scat{EffBin} of \scat{BinComp},
for instance that of poly-time computable maps. We can define the category
\scat{EffComp} of efficient computations as the wide subcategory of \scat{Comp}
consisting of morphisms $f$ whose encodings $\denote{f}$ are in $\scat{EffBin}$:
this is the \emph{preimage} of $\scat{EffBin}$ under the functor $\denote{-}$.

\begin{dfn}
  The category \scat{P} of poly-time computable maps is the wide subcategory
  of $\scat{Comp}$ consisting of those morphisms $f$ such that $\denote{f}$ is
  poly-time computable.
\end{dfn}

Similarly, suppose that we are give some wide subcategory of
\scat{BinCompStoch}, for instance that of poly-time computable stochastic maps.
We can similarly define the category \scat{EffCompStoch}.

\begin{dfn}
  The category \scat{PPT} of poly-time computable stochastic maps is the wide is
  the wide subcategory of $\scat{CompStoch}$ consisting of those morphisms $f$
  such that $\denote{f}$ is probabilistic poly-time-computable.
\end{dfn}

In general, we can perform this construction for any complexity class $C$ which
is closed under composition.

Even more generally, let \scat{Bin} be the category of sets of binary strings and
(maybe uncomputable) set-functions between them. Let \scat{Enc} be the category
of binary-encoded sets and (maybe uncomputable) set-functions between them. Then
$\denote{-}$ is an equivalence of categories $\scat{Enc}\simeq \scat{Bin}$.

Now let \scat{EffBin} be any subcategory of \scat{Bin}. Then the \emph{category
of efficient computations} \scat{Eff} is the subcategory of \scat{Enc}
consisting of morphisms $f$ such that $\denote{f}$ is in \scat{EffBin}, i.e. the
preimage of \scat{EffBin} under $\denote{-}$. Finally, let $T$ be any monad on
\scat{Enc} which restricts to a monad on \scat{Eff}. Then the \emph{category of
efficient $T$-computations} is the Kleisi category of the restriction of $T$ to
\scat{Eff}. When $T$ is symmetric lax monoidal, this category is symmetric
monoidal.

\begin{ex}
  Each example in the previous three sections is a special case of this
  construction.
  \begin{itemize}
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the identity
      monad, we recover \scat{Comp}.
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the
      computable Giry monad, we recover \scat{CompStoch}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the identity monad, we recover \scat{P}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the \emph{poly-time Giry monad}, which sends a set $X$ to the set of
      poly-time computable probability distributions on $X$, we recover
      \scat{PPT}.
  \end{itemize}
\end{ex}

The point is that for any notion of efficient computation, and any notion of
computational effect (since effects are generally
monadic~\cite{wadler-thiemann-2003}), as long as the effect can be efficiently
represented, we can use the machinery of binary-encoded sets to define a
category of efficient computations carrying the given effect.

\subsection{Quantum Computation}

While an complete introduction to quantum computation is outside our scope, we
can sketch a categorical perspective; a standard introduction
is~\cite{nielsen-chuang-2010}. The \emph{category of quantum computations}
\scat{FinHilb} is the category of finite-dimensional Hilbert spaces over $\CC$ and
linear maps. Since nontrivial complex Hilbert spaces have
uncountably many vectors, we cannot directly model this category using the
machinery of the previous section, as there is no way to encode a complex
Hilbert space as an object of \scat{Bin}. If we had developed a more general
theory relying on a notion of computability over uncountable sets, then we could
now unify these perspectives; indeed, there have been several attempts to
monadically embed quantum computation into classical
calculi~\cite{altenrich-green-2009,abramsky-2017}. As we have chosen not to
develop such a general theory, in this section we will treat Hilbert spaces as
our primitive object.

A \emph{quantum computation} is a sequence of unitary transformations and
\emph{measurements}. There are several ways to provide categorical semantics to
quantum measurement; we follow~\cite{heunen-vicary-2014}.

Let $I$ be the one-dimensional Hilbert space. Note that the maps $I\to I$
correspond to choices of scalars $\lambda\in\CC$; as such, we say that a
\emph{scalar} is a map $I\to I$. Given a Hilbert space $V$, a \emph{state} is a
map $I\to V$, so that a state is determined by a choice of vector in $V$. If
$I\xto{a} V$ and $I\xto{b} V$ are states, then the projection of $a$ onto $b$
has amplitude \[
  I\xto{a}V\xto{b^\dag} I,
\]where $(-)^\dag$ denotes the adjoint; the corresponding element of $\CC$ is
the inner product $\<b,a\>$. Now the \emph{Born rule} of quantum mechanics
asserts that the probability of measuring the outcome $b$ from the state $a$ is
$|\<b, a\>|^2$. Categorically, if $I\xto{a,b} V$ are states, then the
\emph{probability of measuring $b$ from the state $a$} is the scalar \[
    I\xto{a}V\xto{b^\dag} I\xto{b} V\xto{a^\dag} I.
  \]

This is just a brief sketch of a very rich theory; see especially the work of
Bob Coecke such
as~\cite{abramsky-coecke-2004,coecke-perdrix-2012,coecke-kissinger-2017}, or the
book by Heunen and Vicary~\cite{heunen-vicary-2014}. The key point is that any
fully categorical treatment of cryptography should obtain quantum cryptography as
a special case.

\section{Protocols}
\label{sec:protocols}

The categorical semantics of interactive computation, and in particular of
protocols, originates from the study of quantum cryptography, especially of
so-called \emph{resource theories}~\cite{coecke-2016}. The idea is to start with
some underlying SMC $\cat{C}$ of computations---fixed throughout this
section---and to construct a category of ``protocols built from computations in
$\cat{C}$.'' Exactly which such construction we choose depends on what we want
our protocols to look like.

In all these categories, the basic idea is that we will think of objects as
resources and morphisms as protocols, which convert some resources into others.
For instance, in the category $\ncomb{\cat{C}}$, morphisms will be ``protocols with
holes''---when instantiated with specific implementations of the resources they
are waiting for, they provide some new resource.

\subsection{Products}

While the product category is used implicitly in the definition of monoidal
categories, it is worth exploring it explicitly. Given two categories $\cat{C}$
and $\cat{D}$, the \emph{product category} $\cat{C}\times\cat{D}$ has:
\begin{itemize}
  \item as objects, pairs $(X,Y)$ of objects in $\cat{C}$ and $\cat{D}$;
  \item as morphisms $(X,Y)\to (X',Y')$, pairs $(f,g)$ of morphisms so that $f:
    X\to X'$ and $g: Y\to Y'$;
  \item composition and identities defined componentwise.
\end{itemize}

When $\cat{C}$ and $\cat{D}$ are categories of computations, we think of
$\cat{C}\times\cat{D}$ as a category of non-interfering parallel computations: a
computation in $\cat{C}\times\cat{D}$ is a computation in $\cat{C}$ and a
computation in $\cat{D}$, but they cannot interact.

\subsection{States}

In the symmetric monoidal category \scat{Set}, the morphisms $\{*\}\to X$
are in natural correspondence with the elements of $X$, by the bijection \[
  (*\mapsto x) \mapsto x.
\]
Similarly, in the symmetric monoidal category $\scat{Vect}_\kk$, the morphisms
$\kk\to V$ are in natural correspondence with vectors in $V$, since such maps
are determined by their action on the vector $1\in\kk$. This pattern holds more
generally, motivating the following definition.

\begin{dfn}[state]
  A \emph{state} or \emph{generalized element} of $\cat{C}$ is a morphism $I\to
  X$ for some object $X$.
\end{dfn}

As we know, it is easy to recognize states string-diagramatically: they are
downward-pointing triangles.

\begin{dfn}[resource theory of states]
  The \emph{resource theory of states} $\state{\cat{C}}$ is the category whose objects
  are states in $\cat{C}$ and whose morphisms $(I\xto{s}X)\to (I\xto{t}Y)$ are
  maps $X\xto{f} Y$ such that $fs = t$. Composition is as in $\cat{C}$.
\end{dfn}

When $\cat{C}$ is interpreted a category of types of resources and conversions
between them, we can think of $\state{\cat{C}}$ states as a category
of specific resources and of conversions between them, forgetting the type
information.

The resource theory of states has a canonical symmetric monoidal structure
induced by that of $\cat{C}$: the monoidal product of states $I\xto{s} X$ and
$I\xto{t} Y$ is just the state $I \to X\otimes Y$ given by\footnote{
  It may worry the careful reader that there are two seemingly distinct, albeit
  coherently naturally isomorphic, morphisms this diagram could represent: \[
    I\xto{\lambda_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y\quad\text{and}\quad 
    I\xto{\rho_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y.
  \]
  Fortunately, it is a non-obvious but standard result of Kelly that $\lambda_I
  = \rho_I$ in any SMC~\cite{kelly-1964}, so these morphisms agree.
}
\[
        \begin{pic}
          \node[state,scale=.75] (f) at (0,0) {$s$};
          \draw (f.north) to ++(0,.6) node[left] {$X$};
          \node[state,scale=.75] (g) at (.7,0) {$t$};
          \draw (g.north) to ++(0,.6) node[right] {$Y$};
        \end{pic},
\]while the monoidal product of morphisms is just their product in $X$. The unit is
the state $1_I$, while the associator and unitor are inherited from $\cat{C}$.

It will be useful to be a little more general. Let $F: \cat{D}\to\cat{C}$ be a
lax monoidal functor. Then an \emph{$F$-state} is a pair of $X\in\cat{D}$ and a
map $I\to FX$ in $\cat{C}$. The \emph{resource theory of $F$-states} $\state{F}$
is the category whose objects are $F$-states and whose morphisms $(I\xto{s}
FX)\to (I\xto{t} FY)$ are maps $X\xto{f}Y$ in $\cat{D}$ such that $(Ff)s =
t$. Note what then $\cat{C} = \cat{D}$ and $F = 1_\cat{C}$, we recover
  $\state{\cat{C}}$.

Since $F$ is lax monoidal, there is again general recipe for taking the monoidal
product in this category: given $I\xto{s} FX$ and $I\xto{t} FY$, the product of $s$ and
$t$ is the state \[
  \begin{pic}
    \draw[functor=cyan] (-.5, -.3) -- (0, -.3) -- (0, .2) -- (.5, .2) -- (.5,
      -.3) -- (1, -.3) -- (1, .7) -- (-.5, .7) -- cycle;
    \draw[rounded corners] (-.25, -.75) node[rounded corners=0, state, scale=.75] {$s$} -- (-.25, .45) --
      (.75, .45) -- ++(0, -1.2) node[rounded corners=0, state, scale=.75] {$t$} node[right, xshift=4mm, yshift=5mm] {\normalsize.};
    \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(X\otimes_\cat{D} Y)$};
  \end{pic}
\]

With a little more machinery: $\state{F}$ is the \emph{category of elements}
of the functor $\cat{D}\xto{F}\cat{C}\xto{C(I, -)}\scat{Set}$. In general, the
category of elements of a functor $F: \cat{C}\to\scat{Set}$ has as objects pairs
$(c, x)$ where $c\in Fx$, and as morphisms $(c, x)\to (c', x')$, maps $f: c\to
c'$ such that $Ff(x) = x'$. The category of elements of any lax monoidal functor
has a canonical monoidal structure on it induced by that of the codomain; this
is the monoidal structure with which we endow $\state{F}$. Observe the
similarity of the monoidal product in $\state{F}$ with the coherence map for the
functor $C(I, -)$ from \Cref{ex:monoidal-functors}. 

Following~\cite{broadbent-karvonen-2022}, we are especially interested in the category
$\state{\cat{C}^2\xto{\otimes}\cat{C}}$. Objects in this category are morphisms
$I\to X\otimes Y$ in $\cat{C}$, which we can think of as \emph{joint states}.
When $\cat{C} = \scat{Set}$, every joint state is \emph{independent}, in that it
splits into the product of two morphisms $I\to X$ and $I\to Y$, but in more
complicated categories like \scat{PPT} or \scat{Hilb} this may fail, representing a
kind of \emph{entanglement}. In this way, we can express the idea that two
parties $A$ and $B$ have a shared uniform random key by the map $I\to X\otimes
X$ in \scat{PPT} that sends $*$ to a uniform random choice of pairs $(k, k)$ for
$k\in X$. This map does not split into a pair of stochastic maps $I\to X$ and $I\to X$.

Morphisms $(I\xto{s} X\otimes Y)\to(I\xto{t}X'\otimes Y')$ in this category are
maps $(f,g)$ in $\cat{C}^2$ satisfying $(f\otimes g)s = t$. The maps $f$ and $g$
prescribe the computations undertaken by the respective parties in order to
transform the joint state $s$ into the joint state $t$. Note that there is a
kind of locality to morphisms in this category, since they are morphisms in the
product category; all of the interaction between the two parties is encoded in
the initial joint state. This separation is actually desirable: it will make it
easier for us to reason about the security of protocols. However, it means we
need a way to describe objects which represent more complicated forms of
interaction; we will do so in the next two sections.

It is worth remarking that more generally, we can model computations on
$n$-party states via the category
\[
  \state{\cat{C}^N\xto{\otimes^{N-1}}\cat{C}},
\] where the $i$th copy of $\cat{C}$ represents computations taken by the $i$th
party in the computation\footnote{There is a choice of associativity to be made, but any
choice yields a coherently isomorphic category, so we will not worry about it
here. A standard assumption---justified by the \emph{strictification theorem for
monoidal categories}, which says that every monoidal category is equivalent to
strict one---is that the underlying category $\cat{C}$ is strict.}.

Finally, there is a forgetful functor $\Pi: \state{\cat{D}\xto{F}\cat{C}}\to
\cat{D}$, which sends a state $I\xto FX$ to the object $X$ and a map to its
underlying map in $\cat{D}$. This functor is monoidal, since the monoidal
structure on $\state{\cat{D}\xto{F}\cat{C}}$ is induced by that of $\cat{D}$.
This functor composes with $F$ to get a forgetful functor with codomain
$\cat{C}$. We will use these functors to help organize information about the
relationship between these categories.

\begin{prop}\label{thm:cat-elements-reflects-isos}
  Let $f: (x, s)\to (y, t)$ be an isomorphism in $\st{\cat{C}\xto{F}\cat{D}}$. Then
  the map $f$ in $\cat{C}$ is an isomorphism in $\cat{C}$.
\end{prop}

\begin{proof}
  The result follows from construction of the forgetful functor
  and the fact that by~\Cref{thm:functors-preserve-iso},
  functors preserve isomorphism.
\end{proof}

\subsection{Flat Process Conversions}

Recall that we can think of morphisms in $X\xto{f} Y$ in $\cat{C}$ as processes
converting $X$ to $Y$. Before arriving at the more general strategy
of~\cite{broadbent-karvonen-2022}, we first treat a simpler case. We will
construct a category $\onecomb{\cat{C}}$ of \emph{flat process conversions}, whose
objects are ``type signatures'' of processes and whose morphisms are recipes for
converting between processes with the appropriate signatures.

By type signature, we mean a pair of objects $(X, Y)$ in $\cat{C}$. The idea is
that the resource $(X, Y)$ should be ``inhabited'' by the morphisms $X\to Y$ in
$\cat{C}$. To make this work out, whatever notion of morphism in $\onecomb{\cat{C}}$
we end up with, it should be the case that $\onecomb{\cat{C}}(I, (X, Y)) \cong
\cat{C}(X, Y)$, i.e. that the morphisms $I\to (X, Y)$ in $\onecomb{\cat{C}}$ should
be in (natural) correspondence with the morphisms $X\to Y$ in $\cat{C}$.

To make this work out, a morphism $(X, Y)\to (X', Y')$ in $\onecomb{\cat{C}}$
consists of the following structure, called a \emph{1-comb}: \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[midway, left] {$X$};
    \draw (xi2.south west) -- (f.north) node[midway, left] {$Y$};
  \end{pic}
\]

Explicitly, a 1-comb consists of an object $Z$ and two morphisms $\xi_1: X'\to
X\otimes Z$ and $\xi_2: Y\otimes Z\to Y'$. The point is that, if we ``plug in''
a morphism $X\to Y$ for the hole, we obtain a morphism $X'\to Y'$; $Z$
represents some auxiliary data that isn't needed by the plugged-in morphism.
We often call $Z$ the \emph{residual} of the comb. It is a theorem
of~\cite{coecke-2016} that in an SMC, any morphism $X'\to Y'$ obtainable as a
string diagram which uses exactly one occurrence of a morphism $f: X\to Y$ may
be obtained as a 1-comb with $f$ filled in the hole.

Composition of 1-combs is defined by ``nesting'': given 1-combs
$(Z, \xi_1, \xi_2): (X, Y)\to (X', Y')$ and $(Z', \xi_1', \xi_2'): (X', Y')\to
(X'', Y'')$, we have a composite 1-comb $(X, Y)\to (X'', Y'')$ defined by:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{10mm}
    \node[morphism] (xi1') at (0,0) {$\xi_1'$};
    \node[morphism] (xi2') at (0,3.5) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[left] {$X''$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2'.north) to ++(0,.5) node[left] {$Y''$};
    \draw ([xshift=2.5pt]xi1'.north east) to ([xshift=2.5pt]xi2'.south east);
    \node[morphism,scale=.6] (xi1) at ($(xi1'.north west)!.2!(xi2'.south west)$)
    {\normalsize$\xi_1$};
    \node[morphism,scale=.6] (xi2) at ($(xi1'.north west)!.8!(xi2'.south west)$)
    {\normalsize$\xi_2$};
    \draw (xi1'.north west) -- (xi1.south);
    \draw (xi2'.south west) -- (xi2.north);
    \draw (xi1.north east) to (xi2.south east);

    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism,scale=.75] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
This does indeed form a 1-comb: explicitly, the composite 1-comb is the
tuple \[
  ((Z\otimes Z'), (\xi_1\otimes 1_{Z'})\circ \xi_1', (1_{Z}\otimes \xi_2')\circ \xi_2).
\]

Meanwhile, the monoidal product of 1-combs is as follows:
\begin{equation}\label{eqn:product-1-comb}
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,4) {$\xi_2$};
    \node[dashedmorphism] (f) at ($(xi1.north)!.5!(xi2.south)$) {};

    \draw (xi1.south) to ++(0,-.5);
    \draw (xi2.north) to ++(0,.5);
    \draw (xi1.north west) -- (f.south west);
    \draw (xi2.south west) -- (f.north west);
    % \draw (0,0) to[out=80,in=-100] (.6,1);

    \node[morphism] (xi1') at (2,0) {$\xi_1'$};
    \node[morphism] (xi2') at (2,4) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[right, xshift=2em, yshift=1.5em] {\normalsize.};
    \draw (xi2'.north) to ++(0,.5);

    \draw
      let
        \p1=(xi1'.north west),
        \p2=(f.south),
        \p3=(f.north)
      in
      (xi1.north east) to[out=90,in=-90]
      (\x1,\y2) --
      (\x1,\y3) to[out=90,in=-90]
      (xi2.south east);
        
    % (xi1.north east) to[out=90,in=-90] ($(xi1'.north west)!.5!(xi2'.south west)$) to[out=90, in=-90] (xi2.south east);
    \draw (xi1'.north west) to[out=90,in=-90] (f.south east);
    \draw (f.north east) to[out=90,in=-90] (xi2'.south west);
    \draw (xi1'.north east) to (xi2'.south east);
  \end{pic}
\end{equation}Again, this forms a 1-comb.

We now return to the assertion from the beginning of the section: since a map $I\to
I$ carries no data, a 1-comb $I\to (X, Y)$ looks like \[
  \begin{pic}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,1) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X$} node[right, xshift=1em,
    yshift=1.5em]
    {\normalsize;};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y$};
    \draw (xi1.north) -- (xi2.south);
  \end{pic}
\]these are morphisms $X\to Y$, but not bijectively so. To resolve this, we take
equivalence classes of 1-combs, where two 1-combs are equivalent if they
yield the same morphism when any morphism $W\otimes X\to W\otimes Y$ is plugged
into their hole\footnote{This is an extensional notion of equality of
  combs. With significantly more machinery, it is also possible to define combs
intensionally, via so-called \emph{coend optics}~\cite{riley-2018,hefford-2023}: a 1-comb
$(X, Y)\to (X', Y')$ is precisely an element of the set $\int^{M\in \cat{C}}
\cat{C}(X', X\otimes M)\times\cat{C}(Y\otimes M, Y')$.}
Finally, we can formally define the category.

\begin{dfn}[category of flat process conversions]
  The \emph{category of flat process conversions} $\onecomb{\cat{C}}$ has as
  objects pairs $(X, Y)$ of objects in $\cat{C}$ and as morphisms equivalence
  classes of 1-combs in $\cat{C}$.
\end{dfn}

\begin{ex}
  The construction $\state{\onecomb{\cat{C}}}$ is the \emph{category of
  parallel-combinable processes} of~\cite{coecke-2016}.
\end{ex}

Now suppose that $F: \cat{C}\to \cat{D}$ is a strong monoidal functor; recall that this
means there is a natural isomorphism
$\phi_{X,Y}: FX\otimes_\cat{D} FY\to F(X\otimes_\cat{C} Y)$. Now there
is an induced functor $\onecomb{F}:\,
\onecomb{\cat{C}}\to\,\onecomb{\cat{D}}$ which acts on 1-combs by
\[
  \begin{pic}
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$X'$};
    \draw (xi2.north) to ++(0,.75) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}\quad\mapsto\quad\begin{pic}
    \draw[functor=cyan] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=cyan] (-.75,3) -- (.75,3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$FX'$} node[right, xshift=2em,
    yshift=1.5em] {\normalsize.};
    \draw (xi2.north) to ++(0,.75) node[left] {$FY'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
Symbolically, the action of $\onecomb{F}$ is \[
  (Z, \xi_1, \xi_2)\mapsto (FZ, \phi^{-1}_{X,Z}F\xi_1, (F\xi_2)\phi_{Y,Z}).
\] We have that $\onecomb{F}$ preserves
identities and composition because $F$ does. Furthermore, this construction
turns 1-comb into an endofunctor on the category of SMCs and strong monoidal
functors.

Cryptographically, we are primarily interested in the category \[
  \state{\onecomb{\cat{C}^2}\xto{\onecomb{\otimes}}\onecomb{\cat{C}}}.
\]

Objects in this category are maps $I\to (X\otimes Y, X'\otimes Y')$ in
$\onecomb{\cat{C}}$, hence maps $X\otimes Y\to X'\otimes Y'$ in $\cat{C}$.
Morphisms $(X\otimes Y\xto{f} X'\otimes Y')\to(A\otimes B\xto{g} A'\otimes B')$
are 1-combs $(X\otimes Y, X'\otimes Y')\to (A\otimes B, A'\otimes B')$, which,
when the hole is ``filled in'' with $f$, yield the morphism $g$. The idea is
that $f$ represents some shared cryptographic resources which the two parties
already have access to; the one-comb is a protocol the parties can use to
transform it into the resource $g$.

We emphasize that these $1$-combs ``live in $\cat{C}^2$: the morphisms $\xi_1$
and $\xi_2$ must be in the image of $\otimes$. As before, this means that they
satisfy a kind of disjointness: they are really two separate computations
running in parallel but independently. All of the interaction between the two
parties is encapsulated in the resource $f$, which is shared between them. As
such, it is a general rule that \emph{protocols cannot create extra
  interactivity on their own; they need input resources enabling interaction}.

Finally, we note that to model $n$-party computation we can work in the category \[
  \state{\onecomb{\cat{C}^n}\xto{\onecomb{\otimes^{n-1}}}\onecomb{\cat{C}}}.
\]

As an example, let $\cat{C} = \scat{Set}$, and let $f$ be the map $X\times *\to
*\times X$ given by $(x, *)\mapsto (*, x)$. Then $f$ is a \emph{one-shot channel}
from the first party to the second party. However, we have no way to represent
protocols which use multiple input resources: our combs only have one hole. We
fix this by working with \emph{n-combs}.

\subsection{Linear Process Conversions}
\label{sec:libear-process-conversions}

The extension from 1-combs to the n-combs of~\cite{broadbent-karvonen-2022} is
conceptually straightforward, but technically somewhat messy. An n-comb is just
a stack of 1-combs; we can combine the top of one comb with the bottom of the
next, so we may as well write\footnote{
  As with 1-combs, there is a more abstract definition of n-combs using coend
  optics: an n-comb $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')$ is an
  element of the set \[
    \int^{M_1,\dots,M_n\in\cat{C}}\cat{C}(X', X_1\otimes
    M_1)\times\prod_{i=1}^{n-1} \cat{C}(Y_i\otimes M_i, X_{i+1}\otimes M_{i+1})
    \times \cat{C}(Y_n\otimes M_n, Y').
  \]
}
\[
  \begin{pic}
    \comb[0,0][0,2][$\xi_1'$][$\xi_2'$]
    \comb[0,3][0,5][$\xi_3'$][$\xi_4'$]

    \node at (0,6.5) {\normalsize$\vdots$};

    \comb[0,8][0,10][$\xi_{2n-1}'$][$\xi_{2n}'$]
  \end{pic}\quad\quad\quad\text{as}\quad\quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xi3) at (0,4) {$\xi_3$};
    \node[morphism] (xin) at (0,7) {$\xi_n$};
    \node[morphism] (xin1) at (0,9) {$\xi_{n+1}$};

    \node at (0,5.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi3.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi3.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xi2.north east) to ([xshift=2.5pt]xi3.south east);
    \node[dashedmorphism] (g) at ($(xi2.north west)!.5!(xi3.south west)$)
    {\phantom{$f$}};
    \draw (xi2.north west) -- (g.south);
    \draw (xi3.south west) -- (g.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]
Again by a theorem of~\cite{coecke-2016}, any circuit which is obtainable as a
string diagram using exactly one occurance of each of a list of $n$ morphisms
can also be obtained as the result of plugging those morphisms in to an
appropriate n-comb.

Generalizing the case of 1-combs, the objects in the category of n-combs should
be finite lists of pairs of objects: a resource of type $[(X_1, Y_1), \ldots,
(X_n, Y_n)]$ is a list of maps $X_i\to Y_i$ in $\cat{C}$. We can proceed
directly to defining the category, but we find it easier to first define a
symmetric multicategory of n-combs. The advantage is that this requires us only
to define morphisms with one pair in the
codomain---what~\cite{broadbent-karvonen-2022} call the ``basic
morphisms''---and then construct a full SMC via a general procedure.

Objects in this multicategory are pairs of objects in $\cat{C}$. Morphisms
\[[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')\] consist of a permutation $\sigma$
and an n-comb
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xin) at (0,5) {$\xi_n$};
    \node[morphism] (xin1) at (0,7) {$\xi_{n+1}$};

    \node at (0,3.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[left, midway] {$X_{\sigma(1)}$};
    \draw (xi2.south west) -- (f.north) node[left, midway] {$Y_{\sigma(1)}$};

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south) node[left, midway] {$X_{\sigma(n)}$};
    \draw (xin1.south west) -- (h.north) node[left, midway] {$Y_{\sigma(n)}$};

    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$};
    \draw (xin1.north) to ++(0,.5) node[left] {$Y'$};
    \node at (1, .5) {\normalsize.};
  \end{pic}
\] The idea is that $\sigma$ encodes the order in which the protocol uses the
input resources; we do not have to use them in the order specified by the domain
list. Composition of general combs is as with 1-combs: given an n-comb and n
$m_k$-combs such that the types line up, we nest each of the combs into the
outer n-comb. This indeed gives us a symmetric multicategory.

We can now use the following general construction to obtain the category of
n-combs:

\begin{dfn}\label{def:associated-monoidal-category}
  Let $\cat{C}$ be a (symmetric) multicategory. Then there is an associated
  (symmetric) monoidal category $\cat{C}^\otimes$ defined as follows:
  \begin{itemize}
    \item an object in $\cat{C}^\otimes$ is a finite list of objects in
      $\cat{C}$, written $x_1\otimes\dots\otimes x_n$;
    \item a morphism $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes \dots\otimes
      y_m$ consists of a \emph{partition function}
      $\alpha_f: \{1,\dots,n\}\to\{1,\dots,m\}$ and for each $i\in\{1,\dots,m\}$, a morphism \[
        x_{k_1}, \dots, x_{k_l}\xto{f_i} y_i,
      \] called the \emph{$y_i$ component}, where the $k_j$s range over
      $\alpha_f^{-1}(i)$;
    \item the composite morphism $x_1\otimes\dots\otimes
      x_n\xto{f}y_1\otimes\dots\otimes y_m\xto{g}z_1\otimes\dots\otimes z_p$ is
      given by the partition function $\alpha_{gf} = \alpha_g\alpha_f$ and for
      each $z_i$, the component \[
        g_i\circ(f_{\sigma_i(1)},\dots,f_{\sigma_i(k)})
      \]in $\cat{C}$, where $\sigma_i$ is from $g$;
    \item the identity on $x_1\otimes\dots\otimes x_n$ is given by the identity
      partition and the identities $1_{x_i}$ from $\cat{C}$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n$ and
      $y_1\otimes\dots\otimes y_m$ is given by the concatenation
      $x_1\otimes\dots\otimes x_n\otimes y_1\otimes \dots\otimes y_m$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes\dots\otimes y_m$
      and $z_1\otimes\dots\otimes z_p\xto{g} w_1\otimes\dots\otimes w_q$ is given
      by lifting the partitions to the disjoint union, so the $y_i$
      component is just $f_i$ while the $w_i$ component is just $g_i$.
  \end{itemize}
\end{dfn}

The idea is that each object in $x_1\otimes\dots\otimes x_n\in\cat{C}^\otimes$
represents the presence of the ``resources'' represented by the objects
$x_1,\dots,x_n\in\cat{C}$. A morphism must consume precisely one ``copy'' of
each resource in that list and produce one copy of each resource in its
codomain. The partition $\alpha$ is an allocation of input resources to output
resources: $\alpha^{-1}(i)$ is exactly the input resources used to produce the
resource $y_i$.

We can be explicit about what this construction looks like in the case of
n-combs.

\begin{dfn}
  Objects in the category $\ncomb{\cat{C}}$ are finite lists of pairs of objects
  in $\cat{C}$. A morphism $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to [(X'_1, Y'_1),
  \dots, (X'_m, Y'_m)]$ is a list of $m$ combs, one for each pair of objects in
  the codomain, and each of which has holes typed by the pairs in the domain,
  such that each pair in the domain is used in \emph{exactly one} n-comb and
  \emph{exactly once} in that n-comb. Composition is by nesting, while the
  monoidal product is by concatenation of lists.
\end{dfn}

\begin{ex}
  The category $\state{\ncomb{\cat{C}}}$ is the \emph{category of universally
  combinable processes} of~\cite{coecke-2016}.
\end{ex}

Furthermore, n-comb is functorial in the same way as 1-comb. Given a strong
monoidal functor $F: \cat{C}\to\cat{D}$, we can define a functor $\ncomb{F}:
\ncomb{\cat{C}}\to\ncomb{\cat{D}}$ by acting on each n-comb over $\cat{C}$ by \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
  \end{pic}
  \quad\quad
  \mapsto
  \quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \draw[functor=cyan] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=cyan] (-.75,3.3) -- (-.15, 3.3) -- (-.15, 2.9) -- (.15, 2.9) --
    (.15, 3.3) -- (.75,3.3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;

    \draw[functor=cyan] (-.75,8.5) -- (.75,8.5) -- (.75, 7.2) -- (.15, 7.2) --
    (.15, 7.6) -- (-.15, 7.6) -- (-.15, 7.2) -- (-.75, 7.2) -- cycle;
    \draw[functor=cyan] (-.75,4.7) -- (-.15, 4.7) -- (-.15, 5.1) -- (.15, 5.1) --
    (.15, 4.7) -- (.75,4.7) -- (.75, 6.3) -- (.15, 6.3) --
    (.15, 5.9) -- (-.15, 5.9) -- (-.15, 6.3) -- (-.75, 6.3) -- cycle;

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]

Cryptographically, still following~\cite{broadbent-karvonen-2022} we are interested in
the category \[
  \prot{N}{\cat{C}} := \state{\ncomb{\cat{C}^N}\xto{\ncomb{\otimes^{N-1}}}\ncomb{\cat{C}}},
\]
which is a category of $N$-party protocols with computations from $\cat{C}$.
Objects in this category are finite lists of maps \[
  X^i_1\otimes\dots\otimes X^i_N\xto{f_i} Y^i_1\otimes\dots\otimes Y^i_N
\] in $\cat{C}$, which represent shared access to the resources $\{f_i\}$,
themselves processes for transforming joint states in $\cat{C}$. Morphisms are
lists of $M$ combs, so that each map $f_i$ in the domain list is allocated to
exactly one comb, and so that plugging in all the $f_i$s into the appropriate
combs yields exactly the list of maps in the codomain.

Here is a convenient way to think about the situation, to our knowledge original
to us. A map in $\ncomb{\cat{C}}$ is a ``schema for a protocol''. We can look
its fiber\footnote{
  The \emph{fiber} $F^{-1}f$ of a functor $F: \cat{C}\to\cat{D}$ over a morphism
  $f\in\cat{D}$ is collection of morphisms $g\in\cat{C}$ such that $Fg = f$.
} under the functor \[
  \ncomb{\otimes^{N-1}}\Pi: \prot{N}{\cat{C}}\to\ncomb{\cat{C}}
\] to determine what the schema does when instantiated with a specific kind of
resource. In some cases, as in the next section, we only care about the maps in
$\prot{n}{\cat{C}}$ with some specific domain and codomain, and are interested
in verifying that there is an element in the fiber with that correct type: this
is a \emph{correctness property} of a protocol. However, there are more
complicated situations where we want to verify that the same protocol behaves in
one way given an input of some type, and in another way given another input; in
this case the expanded perspective provided by the forgetful functor can be
useful for organizing the data.

\subsection{The One-Time Pad}
\label{sec:otp}

As a first example, we work out in full detail the categorical description of
the one-time pad due to~\cite{broadbent-karvonen-2022}. For now, let $\cat{C} =
\scat{CompStoch}$ and $N = 3$; we label the three parties $A$, $B$, and $E$. We
pick a message space $M\in\cat{C}$; we could just say $M = \bin^*$, but instead
let us figure out what ``local'' structure, by which we mean structure in
$\cat{C}$ which is hence usable by each of the parties on their own, $M$ needs
to have.

First, we should be able to copy and delete messages from $M$; they're just
classical information. We represent this with a pair of maps \[
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$M$};
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$M$};
    \draw (mu) to ++(0, -.7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \hspace{1em}
  \quad\quad
  \begin{pic}
    \node[dot, fill=white] (eta) at (0,0) {};
    \draw (eta) to ++(0, -.7) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]called the \emph{copy} and \emph{deletion} maps. Copying is associative
(category theorists call this \emph{coassociativity}, because it is opposite to the
direction of normal associativity):
\begin{equation}\label{eqn:coassociative}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to[out=0, in=-90] ++(.7, .7) to ++(0, .5) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[left] {};
    \draw (a) to ++(0, -.7) node[left] {};
  \end{pic}
  =
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to[out=180, in=-90] ++(-.7, .7) to ++(0, .5) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[right] {};
    \draw (a) to ++(0,-.7) node[left] {};
  \end{pic}
\end{equation}and commutative (\emph{cocommutativity}): 
\begin{equation}\label{eqn:cocommutativity}
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
    \draw (mu) to ++(0, -.7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) to[out=90, in=-90] ++(1, 1);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) to[out=90, in=-90] ++(-1, 1);
    \draw (mu) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize;};
  \end{pic}
\end{equation}
deletion is the inverse of copying (\emph{counitality})\footnote{We do not
need to axiomatize both sides of this equality when we have commutativity.}:
\begin{equation}\label{eqn:counital}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to ++(0, -.7) node[left] {};
    \draw (a) to[out=180, in=-90] ++(-.5, .5) to ++(0, .4) node[left] {};
  \end{pic}
  \hspace{.4em}
  =
  \begin{pic}
    \draw(0, 0) node[left] {} to (0, 1.5) node[left]{};
  \end{pic}
  \hspace{.6em}
  =
  \hspace{.5em}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (a) to[out=0, in=-90] ++(.5, .5) to ++(0, .4);
  \end{pic}
\end{equation}
These three equations give $M$ the structure of a \emph{cocommutative
comonoid} in $\cat{C}$.

We often want to work over categories in which \emph{every} object has such copy
and delete maps. We say that an SMC $\cat{C}$ \emph{supplies cocommutative
comonoids} if every object in $\cat{C}$ is a cocommutative comonoid in such a
way that the comonoidal structure on any object $X\otimes Y$ is induced from
that on $X$ and $Y$ by the monoidal product. We are now very close to the
definition of a \emph{Markov category}, which is a natural categorical
axiomatization of stochastic computation~\cite{fritz-2020}.

Recall from~\Cref{ex:otp} the one-time pad
works over an arbitrary group $G$. As such, we separately need that $M$ looks
like a group in $\cat{C}$: it should have multiplication, unit, and inverse
maps \[
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[left] {$M$};
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right] {$M$}
      node[right, xshift=4mm, yshift=1mm] {\normalsize,};
    \draw (mu) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
    \draw (eta) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {};
    \draw (eta) to ++(0, .5) node[left] {$M$};
    \draw (eta) to ++(0, -.5) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]which are associative and unital in the sense of~\Cref{def:monoid object}
and satisfy the additional \emph{inverse law}:
\begin{equation}\label{eqn:inverse}
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=0, in=-90] (inv) to[out=90, in=0] (mult);
    \draw (copy) to[out=180, in=-90] (-.5,.5) to[out=90, in=180] (mult);
    \draw (copy) to ++(0, -.75);
    \draw (mult) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (del) at (0,0) {};
    \node[dot, fill=black] (id) at (0,1) {};
    \draw (del) to ++(0, -.75);
    \draw (id) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (-.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=180, in=-90] (inv) to[out=90, in=180] (mult);
    \draw (copy) to[out=0, in=-90] (.5,.5) to[out=90, in=0] (mult);
    \draw (copy) to ++(0, -.75) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (mult) to ++(0, .75);
  \end{pic}
\end{equation}
Notice that this law relies on the existence of the copy and delete maps;
indeed, it is not possible to define a group without some way to talk about
copying.

We need one more compatibility law, which says essentially that multiplication
is deterministic: performing the same multiplication twice is the same as
performing it once and then copying the result:
\begin{equation}\label{eqn:mult-deterministic}
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.5, 0) {};
    \node[dot, fill=white] (copy2) at (.5, 0) {};
    \node[dot, fill=black] (mult1) at (-.5, .8) {};
    \node[dot, fill=black] (mult2) at (.5, .8) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-10] (mult2);
    \draw (copy1) to[out=10, in=190] (mult2);
    \draw (copy2) to[out=170, in=-10] (mult1);
    \draw (copy1) to ++(0, -.7);
    \draw (copy2) to ++(0, -.7);
    \draw (mult1) to ++(0, .7);
    \draw (mult2) to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \node[dot, fill=white] (copy) at (0,.8) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2);
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right, xshift=4mm, yshift=1mm] {\normalsize.};
    \draw (mu) to ++(0, .7);
    \draw (mu) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
  \end{pic}
\end{equation}

Finally, for the one-time pad we need some way to model randomness; in
\scat{CompStoch} this is the map $I\xto{\$} M$ which draws a uniform random
value from $M$. Categorically, rather than the specific construction of the map,
we care about its properties\footnote{
  The laws \eqref{eqn:coassociative} to
  \eqref{eqn:mult-deterministic} give $M$ the structure of a
  \emph{Hopf object} in $\cat{C}$. It turns out that these objects are
  well-known, and in particular have important applications in quantum
  computation~\cite{de-felice-2017}; for instance, a Hopf object in
  $\scat{Vect}_\kk$ is just an ordinary Hopf algebra. This is a major advantage
  of the categorical machinery: we discover unexpected connections between
  different kinds of computation and mathematics.

  Somewhat surprisingly, elements of Hopf algebras satisfying
  \eqref{eqn:random-invariance} and \eqref{eqn:random-non-side-effecting} 
  have been well studied under the name
  \emph{integrals}~\cite{sweedler-1969,lomp-2004,sullivan-1971}. As such, the
  one-time pad can be instantiated over any Hopf algebra $H$ with an integral,
  by replacing the uniform random choice of key with the map $\kk\to H$ which
  sends $1$ to the chosen integral. This translation is purely syntactic;
  everything we will say about the one-time pad applies to this construction as
  well. We can now start doing cryptography inside a Hopf algebra, or using the
theory of Hopf algebras to say things about cryptography.}: it is invariant
under
multiplication, in the sense
that
\begin{equation}\label{eqn:random-invariance}
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}\quad=\quad
  \begin{pic}
    \draw (0,0) node[state, scale=.75] {\normalsize\$} to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) node[state, scale=.75] {\normalsize\$} node[right, xshift=3mm, yshift=1mm] {\normalsize,};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}
\end{equation}
and it is independent, in the sense that \begin{equation}\label{eqn:random-non-side-effecting}
  \begin{pic}
    \draw (0, 0) node[state, scale=.75] (rand) {\normalsize\$} to ++(0, .7) node[dot, fill=white] {};
  \end{pic}\quad\text{equals the empty diagram.}
\end{equation} We interpret \eqref{eqn:random-invariance} as
saying that the product of any group element with a uniform random value is
uniform random, while \eqref{eqn:random-non-side-effecting} says that
creating and then deleting a uniform random value does nothing.

All this is just the local structure. To implement the one-time pad, we need
two shared resources. First, $A$ and $B$ should have a shared random key drawn
from $M$. In $\scat{CompStoch}$, this is the map $I\to M\otimes M\otimes I$
which draws uniformly at random from the set $\{(k, k, *): k\in M\}$.
Diagramatically, we can build this map as \[
  \begin{pic}
    \node[state, scale=.75] (rand) at (0, 0) {\normalsize\$} node[right, xshift=8mm, yshift=1mm] {\normalsize,};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]where we now label the wires with the party in possession of the data, so that
for instance a wire labeled $A$ has type $M\otimes I\otimes I$, while
the two parallel wires labeled $A$ and $B$ have type $M\otimes
M\otimes I$. This is a map in $\cat{C}$ which cannot be written in $\cat{C}^3$,
because it does not factor into a product of three separate maps in $\cat{C}$.

We also need a way for $A$ to send the encoded message to $B$ and $E$. In
\scat{CompStoch}, this is the map $M\otimes I\otimes I\to I\otimes M\otimes M$
given by $(c, *, *)\mapsto (*, c, c)$. Again, this can be represented using the
structure defined above, as the map \[
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$} node[right, xshift=5mm,
    yshift=1mm] {\normalsize.};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]It is a good exercise in string diagram comprehension to spell out this map
symbolically. Assuming we chose to left-associate the functor $\otimes^2$ in the
definition of $\prot{3}{\cat{C}}$, one way to write it is as the map \[
  (M\otimes I)\otimes I\xto{\rho_{M\otimes I}} M\otimes I
  \xto{\gamma_{M,I}} I\otimes M\xto{1_I\otimes
  \text{copy}} I\otimes (M\otimes M)\xto{\alpha^{-1}_{I,M,M}} (I\otimes
    M)\otimes M.
\]The magic of the coherence theorem is that, once we agree on a choice of
associativity, any way of writing this map is the same, and so we can work with
the far simpler diagrammatic notation.

From all this, we learn that the domain of the one-time pad should be the object
\begin{equation}\label{eqn:otp-domain}
  \begin{pic}
    \node[state] (rand) at (0, 0) {\normalsize\$};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
  \otimes
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\end{equation} of $\prot{3}{\cat{C}}$. The goal of the one-time pad is to produce a channel
from $A$ to $B$, so the codomain should be the object \begin{equation}\label{eqn:otp-codomain}
  \begin{pic}
    \draw (0, 0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm] {\normalsize.} to ++(0, 1) node[left] {$B$};
  \end{pic}
\end{equation}
The reader may now object that the one-time pad does not give the eavesdropped
no information, as they learn that a message was sent. However, we are not yet
attempting to deal with adversarial behavior, so any protocol can simply have
Eve forget that information. We will discuss this issue at length in
\Cref{sec:security}.

For a second, let us not worry about preserving states, and just think in the
category $\ncomb{\cat{C}}$. Recall that the objects in this category are finite
lists of pairs of objects in $\cat{C}$. The domain of the one-time pad should be \[
  [(I\otimes I\otimes I, M\otimes M\otimes I), (M\otimes I\otimes I,
  I\otimes M\otimes M)],
\] while the codomain should be \[
  [(M\otimes I\otimes I, I\otimes M\otimes I)].
\]
A morphism between these should be a 2-comb which takes morphisms of the domain
types and produces a morphism of the codomain type. In other words, given two
``black box'' maps \[
  \begin{pic}
    \node[dashedstate] (rand) at (0, 0) {};
    \draw (rand.north west) to ++(0, .5) node[left] {$A$};
    \draw (rand.north east) to ++(0, .5) node[right] {$B$};
  \end{pic}\quad\text{and}\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .5) node[left] {$E$};
    \draw (send.north east) to ++(0, .5) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
  \end{pic},
\]the 2-comb must produce a map \[
  \begin{pic}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.south) to ++(0, -.5) node[left] {$A$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.};
    \draw (send.north) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]
The easiest such 2-comb to write, \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (send.north east) to ++(0, .7) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to ++(0, .3) node[dot, fill=white] {};
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} to ++(0, .3) node[dot, fill=white] {};
  \end{pic},
\]
represents simply sending the message unencrypted, without use of the key. Note
that the theory does require us to explicitly forget the key, as n-combs must consume
all their input resources. We will alleviate this requirement soon.

Now the schema for the one-time pad is the 2-comb \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    % \node[morphism] (send) at (0, 0) {};
    % \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    % \draw (send.north east) to ++(0, .7) node[right] {$B$};
    % \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \node[dot, fill=black] (mult) at (.5, 1) {};
    \node[dashedmorphism] (copy) at (.5, 2) {};
    \draw (copy.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (mult) to (copy.south) node[yshift=-3mm, left] {$A$};
    \draw (-.3, -1) node[left] {$A$} to (-.3, .2) to [out=90, in=180] (mult);
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to[out=90, in=0] (mult);
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} node[right, yshift=-3mm,
    xshift=5mm] {\normalsize.} to ++(0, .7) node[dot,
    fill=black] {} to ++(0, .4) node[right] {$B$} to ++(0, 1.1) to[in=0,out=90] ++(-.5, .5) node[dot, fill=black] (f) {};
    \draw (copy.north east) to ++(0, .2) node[right] {$B$} to[out=90,in=180] (f);
    \draw (f) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]

This is a morphism in $\ncomb{\cat{C}}$. To check that this protocol is correct,
we need to check that it sends the state \eqref{eqn:otp-domain} to
the state \eqref{eqn:otp-codomain}, i.e. that it is a morphism with
the right type in $\prot{3}{\cat{C}}$. Substituting the actual resources in for
their generic counterparts, we get the protocol \[
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist) node[left, xshift=-3mm] {$A$};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=3mm] {$B$} node[right, xshift=8mm,
    yshift=-2mm] {\normalsize.} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) node[above right, xshift=-.5mm] {$B$} to[out=90, in=0] (bm);
    \draw (copy) node[above right, yshift=1mm] {$B$} to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) node[left] {$E$} to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic}
\]
Now we compute, using counitality, associativity, the inverse law, unitality,
and the independence of random choice:
\begin{align*}
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist) node[left, xshift=-3mm] {$A$};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=3mm] {$B$} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) node[above right, xshift=-.5mm] {$B$} to[out=90, in=0] (bm);
    \draw (copy) node[above right, yshift=1mm] {$B$} to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) node[left] {$E$} to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6) node[left] {$B$};
    \end{pic}\quad&
  \xequals{\eqref{eqn:counital}}\quad\begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to ++(0, .3) to[out=90, in=180] (bm);
    \draw (am) to[out=0, in=180] (keydist);
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) to[out=90, in=0] (bm);
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic}\,\\
  &\xequals{\eqref{eqn:monoid associative}}\quad\begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
      node[dot, fill=black] {} to[out=90, in=0] ++(-.5, .5) node[dot, fill=black] (bm) {};
      \draw (keydist) to[out=180, in=-90] ++(-.5, .5) to[out=90, in=180] (bm);
      \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
      \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
      \draw (am) to ++(0, .5) node[left] {$B$};
    \end{pic}\\
  &\xequals{\eqref{eqn:inverse}}\quad
    \begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
      \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
      \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
      \draw (am) to ++(0, .5) node[left] {$B$};
    \end{pic}\,\\
  &\xequals{\eqref{eqn:monoid unital}}\quad
  \begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw ($(keydist) + (-.5, -1.2)$) node[left] {$A$} to ++(0, 1.5) node[left] {$B$};
    % \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
    %   \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
    %   \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
    %   \draw (am) to ++(0, .5) node[left] {$B$};
  \end{pic}\,\\
  &\xequals{\eqref{eqn:random-non-side-effecting}}\quad
  \begin{pic}
    \draw (0,0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm]
    {\normalsize.} to ++(0, 1.5) node[left] {$B$};
    % \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
    %   \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
    %   \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
    %   \draw (am) to ++(0, .5) node[left] {$B$};
  \end{pic}
\end{align*}
This computation proves that the one-time pad is a morphism
$\eqref{eqn:otp-domain}\to\eqref{eqn:otp-codomain}$
in $\prot{3}{\cat{C}}$; this is the categorical statement of the correctness of
the one-time pad.

% Notice that this computation is very similar to the proof of the correctness of
% the one-time pad (\Cref{ex:otp}). 

We reiterate that the entire preceding discussion relies only on the existence
of an object satisfying the axioms \eqref{eqn:coassociative} to
\eqref{eqn:random-non-side-effecting}. The one-time pad can be
correctly implemented in any category over any object with this structure.

Of course, this entire discussion assumes that Eve does as the protocol
instructs and simply deletes the message they read. If they do not, we need
another layer of analysis, dealing with adversarial behavior. That will be the
subject of \Cref{sec:security}.

\subsection{Extensions to the Framework}

\subsubsection{Reusable Resources}
In the title of
\Cref{sec:libear-process-conversions},
we called $\ncomb{\cat{C}}$ a category of \emph{linear} process conversions.
This is because each input resource is used exactly once in the list of n-combs.
While it is often valuable to have this restriction enforced by the syntax,
there are cases where we want to model reusable resources. As suggested
by~\cite{broadbent-karvonen-2022}, we can straightforwardly modify the
construction to account for this by making two changes.

First, recall that in the definition of an n-comb at the beginning of
\Cref{sec:libear-process-conversions},
the permutation $\sigma$ determines the order in which the input resources are
used. For an $n$-comb with $m$ input resources, we can replace this permutation
with a function $n\to m$ which assigns to each comb the type of the resource
which will fill it. In this way, we can use each resource as many times
as we want, including not at all.

However, this is not enough, as in the category $\ncomb{\cat{C}}$ morphisms are
lists of n-combs, and the current definition allocates each input resource to
exactly one of these combs. One advantage of our choice to use the intermediate
step of a multicategory is that we can make the required change directly to the
construction in \Cref{def:associated-monoidal-category}. When
defining morphisms in this category, we used a partition function $\alpha$ to
assign input resources to outputs resources. By allowing this function to be a
relation, we can allow each input resource to be assigned to multiple output
resources. When $\cat{C}$ is a symmetric multicategory, we call this category
$\cat{C}^{\otimes!}$. Combining these two modifications yields the category
$\ncombb{\cat{C}}$ of~\cite{broadbent-karvonen-2022}.

We suspect that their choice of notation $!$
is not accidental: in many ways, this category behaves like the exponential
modality $!$ of linear logic. In linear logic~\cite{girard-1987}, hypotheses
must be used once and only once. The $!$ modality allows a hypothesis to be used
any number of times; this allows controlled intuitionistic reasoning with linear
frameworks, hence allowing linear logics to be both as expressive as intuitionistic
logic, and to have fine-grained control over resource usage. In the case of
n-combs, however, we currently have two separate categories $\ncomb{\cat{C}}$
and $\ncombb{\cat{C}}$, so if we want to model cryptosystems that have some
multi-use resources and some single-use resources, we need some way to relate
them. We give a solution in \Cref{def:ncomba}, but first we
digress to discuss the categorical semantics of linear logic, which motivate our
construction. This explanation uses some categorical terminology we have not
introduced, but the reader may safely skip directly to the definition.

Any symmetric monoidal category $\cat{L}$ forms a model of the
multiplicative-intuitionistic fragment of linear logic~\cite{mellies-2009}. In such
settings, $!$ can be modeled by a lax monoidal comonad $\denote{!}$ together
with natural transformations $\denote{!}x\to I$, and
$\denote{!}x\to\denote{!}x\otimes\denote{!}x$. This data is subject to a
coherence axiom given in \cite[Equation 72]{mellies-2009}.

The modern perspective, motivated by~\cite{benton-1995}, is to focus on
resolutions of this comonad, i.e. monoidal adjunctions \[
  \begin{tikzcd}
    \cat{I}\ar[rr, bend left, "F"] & \bot & \cat{L}\ar[ll, bend left, "G"]
  \end{tikzcd}
\]such that $FG = \denote{!}$, and in particular on resolutions such that the
monoidal structure on $\cat{I}$ is cartesian, hence a model of conjunctive
intuitionistic logic\footnote{
  Normally we consider such situations with significantly more structure than just
  the multiplicatives, but the situation is the same even in this case.
}. It turns out that any monoidal adjunction between categories with this
structure gives the necessary structure on the comonad $GF$; as a consequence,
such adjunctions are called \emph{linear-non-linear}. In this way, $F$ is an
embedding of intuitionistic terms as linear terms, while $G$ forgets the
linearity of a term. A standard example of this structure is the free-forgetful
adjunction between \scat{Set} and
$\scat{Vect}_\kk$~\cite{valiron-zdancewic-2014}. Linear-non-linear adjunctions
have been widely used for designing resource-aware programming
languages~\cite{maf-2005,krishnaswami-2015,paykin-2018,lmz-2019}.

All this machinery suggests that, to give a system which allows simultaneous
reasoning about both single- and multi-use resources, we should look for
such an adjunction. There is indeed a forgetful functor $G: \ncomb{\cat{C}}\to
\ncombb{\cat{C}}$, which we may think of as forgetting the linearity of an
n-comb. Furthermore, the category $\ncombb{\cat{C}}$ is cartesian monoidal,
meaning that the concatenation of two lists is a cartesian product; the
projections simply do not use the extra resource, while the universal property is
witnessed by concatenating lists of n-combs. As such, $\ncombb{\cat{C}}$ is a
model of conjunctive intuitionistic logic; it represents an intuitionistic,
rather than linear, calculus of resources.

However, the functor $G$ seems unlikely to be a right adjoint\footnote{
  I would like, but do not have, an explicit construction of a limit which $G$
  does not preserve; the issue is that it seems hard for $\ncomb{\cat{C}}$ to
  have very many limits in the first place.
}. The issue is that combs between the same two objects $\ncombb{\cat{C}}$ may
use different numbers of resources, and so ought to be sent to different objects
in $\ncomb{\cat{C}}$, but this is impossible for any functor. To resolve this,
we need a notion of intuitionistic resource internal to $\ncomb{\cat{C}}$. A solution
may perhaps be along the lines of the $\infty$-combs of~\cite{roman-2020}, which
are used there to model stream-like data, but these have slightly
differently-structured domains and codomains than n-combs, so the translation is
not obvious.

A more direct solution is to extend $\ncomb{\cat{C}}$ with objects $!(A, B)$,
which represent reusable resources of type $A\to B$ and are used to build
n-combs as in $\ncombb{\cat{C}}$.

\begin{dfn}\label{def:ncomba}
Objects in the category
$\ncomba{\cat{C}}$ are finite multisets\footnote{
  We use multisets instead of lists to simplify the monoidal structure; since
  all our categories and multicategories are symmetric, the distinction is not
  important.
} of pairs $(A, B)$ and/or $!(A, B)$ of objects in $\cat{C}$, called
\emph{linear} and \emph{reusable} resources respectively. Given four
finite disjoint index sets $I,J,K,$ and $L$, we now describe morphisms
 \[
   \{!(A_i, B_i), (C_j, B_j): i\in I, j\in J\}\to \{!(X_k, Y_k), (Z_l, W_l):
   k\in K, l\in L\}.
\] To construct such a morphism, we first give a relation $\alpha: K\sqcup L\to I\sqcup J$ such
that:
\begin{enumerate}
  \item each $j\in J$ $\alpha$-relates to exactly one element;
  \item each $k\in K$ $\alpha$-relates only to elements in $I$.
\end{enumerate}
Next, for each $k\in K$, we give morphism from $\ncombb{\cat{C}}$, whose domain
is the multiset $\{(A_i, B_i): i\in \alpha(k)\}$ and whose codomain is $(X_k,
Y_k)$. Finally, for each $l\in L$, we first give for some $n$ a function
$\sigma: n\to \alpha(l)$, such that for each $j\in J\cap\alpha(l)$,
$\sigma^{-1}(j)$ is a singleton. We then give an n-comb which uses the resources in
$\alpha(j)$ according to the order assigned to them by $\sigma$.
\end{dfn}
The definition is justified as follows. The first condition on $\alpha$ ensures
that each linear resource must be used in exactly one comb, while the second
ensures that we can only build reusable resources out of reusable resources.
We build reusable resources as in $\ncombb{\cat{C}}$, which was constructed
specifically for that purpose. To build linear resources, we can use
reusable resources as many times as we want, but must use linear resources
exactly once, hence the condition on $\sigma$.


% situation for combs building linear resources is slightly more complicated: we
% should be able to use intuitionistic resources to build them multiple times,
% while we should have to use linear resources exactly once. For each $l\in L$,
% the comb consists of a function $\sigma: n\to |\alpha(l)|$, such that for each
% $j\in J\cap\alpha(l)$, $\sigma^{-1}(j)$ is a singleton. Now we build an $n$-comb
% using the given resources in the order prescribed by $\sigma$.


Another semantic digression: this category is strict symmetric monoidal with the
union of multisets as the product and the empty set as the identity.
Furthermore, there is a linear-non-linear adjunction \[
  \begin{tikzcd}
    \ncombb{\cat{C}}\ar[rr, bend left, "F"] & \bot &
    \ncomba{\cat{C}}\punctuation{,}\ar[ll, bend left, "G"]
  \end{tikzcd}
\]
where $G$ forgets the difference between linear and reusable resources,
and $F$ sends all resources to reusable ones. To show this is an
adjunction, observe that all the restrictions on the construction of the combs
are on the use of linear resources in the domain. As such, when all the
resources in the domain are reusable, a morphism in $\ncomba{\cat{C}}$ is
exactly a morphism in $\ncombb{\cat{C}}$; thus the identities give a natural
isomorphism between adjoint hom-sets.

This may seem like abstract nonsense, but the point is that the theory guided us
in constructing a category which models protocols relying on both linear and
multi-use resources; this is likely of independent interest to other uses of
n-combs. We conjecture that this style of construction extends to graded linear
logic (in which resources can have a bounded number possible
uses)~\cite{girard-1992}, affine logic (in which resources must be used at most
once)~\cite{troelstra-1992}, relevance logic (in which resources must be used at
least once)~\cite{dunn-1983}, ordered logic (in which resources must be used in
a specific order)~\cite{lambek-1958}, and to other such substructural resource
logics. The general paradigm of adjoint logic~\cite{pruiksma-2018} provides
categorical semantics for embedding many of these logics in each other; giving
``comb-like'' constructions of such categorical structures would allow reasoning
about resource-bounded protocols with fairly sophisticated resource-usage
constraints.

As a final notational point, we modify $\prot{N}{\cat{C}}$ as
$\protb{N}{\cat{C}}$ and $\prota{N}{\cat{C}}$ by replacing all the invocations
of n-comb with n-comb$!$ and n-comb$^*$, respectively. In particular, these
constructions are both functorial in the same way as n-comb.

% To explicitly construct the 
% define $\denote{!} = FG$, which promotes all the resources in the domain to be
% reusable. Then the map $\denote{!}x\to I$ is the empty comb, and the map
% $\denote{!}x\to \denote{!}x\otimes \denote{!}x$ is the comb which uses each
% input resource twice to produce the output resoures.
%
%
%
% For instance, suppose
% $\cat{C}$ has two objects, $a$ and $b$, and the following morphisms:
% \begin{itemize}
%   \item for each natural number $n$, a morphism $n: a\to a$;
%   \item one morphism $f: a\to b$;
%   \item one morphism $g: b\to a$;
%   \item two morphisms $h,1_b: b\to b$.
% \end{itemize}
% Composition of morphisms $a\to a$ is by addition, while $h\circ h = 1_b$, $. Impose a strict symmetric
% monoidal structure on this category by \begin{mathpar}
%   a\otimes a = a, \and a\otimes b = b\otimes a = a, \and b\otimes b = b,
%   \and n\otimes m = n+m, \and n\otimes f = f\otimes n = n, \and n\otimes g = g\otimes n =
%   g, \and g\otimes f = f\otimes g = 0, \and 1_b\otimes 1_b = 1_b, \and 1_b\otimes f
%   = f\otimes 1_b = 1_b\otimes g = g\otimes 1_b = 0$.
% \end{mathpar}
% Then the pair $(*, *)$ is 
% $(0, 0)$ is terminal in $\ncomb{\cat{C}}$.

\subsubsection{Shading Diagrams}
While \cite{broadbent-karvonen-2022} choose to label the wires with the
identities of the parties in possession of that data, we worry that this
approach does not easily scale to protocols where multiple objects are relevant.
We now give an alternative approach using the shaded boxes of
\Cref{sec:monoidal-functors}. In addition
to being less cluttered, this approach has a fairly pleasant abstract
justification, though we emphasize that it is merely a syntactic distinction.

We begin by noting that, in addition to the monoidal product \[
  \cat{C}^N\xto{\otimes^{N-1}}\cat{C},
\]there are also strong monoidal projection functors \[
  \cat{C}^N\xto{\pi_i}\cat{C}.
\]
Instead of labelling each wire with the party, we can shade the wires according
to the projection functors that they live in the image of. For instance, if Alice
is blue, Bob is green, and Eve is red, then the one-time pad can be depicted
as \[
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1);
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist);
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=8mm,
    yshift=-2mm] {\normalsize.} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) to[out=90, in=0] (bm);
    \draw (copy) to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6);
    \draw[functor=cyan] (-.7, .2) -- (.5, .2) -- (.5, -.6) to[out=180, in=90]
    (-.3, -1.8) -- (-.7, -1.8) node[left, opacity=1] {$A$} -- cycle;
    \draw[functor=green] (1.1,-.6) to[out=0, in=-90] (1.5, 0) node[right, opacity=1] {$B$} to[out=90, in=0]
    (.8, 2) to [out=180, in=90] (.2, .9) -- cycle;
    \draw[functor=red] (-.3, .9) -- (-.7, .9) -- (-.7, 1.6) node[left, opacity=1] {$E$} -- (-.3, 1.6) --
    cycle;
  \end{pic}
\]%

We like the visual clarity provided by this approach; it emphasizes the flow of
information and control between the parties in the protocol. As mentioned, it
also has a nice justification in terms of the functorial boxes studied
previously; unifying analogous notations is always valuable. However, we see two
potential issues. First, as usual with color in diagrams, there are
accessibility concerns; while we attempt to ameliorate these by labelling the
regions and using an accessible colorscheme due to~\cite{tol-2021}, such
measures can only go so far. Second, this approach is hard to scale to settings
with many parties, as there are only so many visually distinct colors. As such,
we think that both approaches have their place.

\subsubsection{Parties With Differing Capabilities}

It is quite common in cryptography to consider settings where different parties
have different capabilities. For instance, we may want to analyze classical
protocols which are secure against quantum attackers or zero-knowledge proofs
with polynomial verifiers and unbounded provers. While the attack models
of~\cite{broadbent-karvonen-2022}, to be studied in
\Cref{sec:attack-models}, allow treating
adversaries with different capabilities from the honest parties, the paper does
not directly address honest parties with different capabilities. This can be
done within their framework using the categories we constructed
in~\Cref{sec:computation}.

As an example, we construct the category of protocols with one unbounded but
deterministic party and one PPT party. Recall that unbounded deterministic
computation is modeled in the category \scat{Comp}, while PPT computation is
modeled in the category \scat{PPT}. Both of these include as subcategories into
$\cat{C} = \scat{CompStoch}$; call these inclusion functors $i$ and $j$. As such, we can
construct the category \[
  \state{\ncomb{\scat{Comp}\times\scat{PPT}}\xto{\ncomb{i\times
    j}}\ncomb{\cat{C}^2}\xto{\ncomb{\otimes}}\ncomb{\cat{C}}}.
\]

In general, assuming there is a clear ambient category $\cat{C}$ of
into which all the relevant categories include, we write \[
  \prot{N}{\cat{C}_1,\dots,\cat{C}_N} := \state{\ncomb{\prod_{i=1}^N
  \cat{C}_i}\into\ncomb{\cat{C}^N}\xto{\ncomb{\otimes^{N-1}}}\ncomb{\cat{C}}}.
\]
We define $\protb{N}{\cat{C}_1,\dots,\cat{C}_N}$ and
$\prota{N}{\cat{C}_1,\dots,\cat{C}_N}$ similarly.

\subsubsection{Joint Input}

While the objects in the category $\prot{N}{\cat{C}}$ are morphisms representing
joint computations in $\cat{C}$, the domains and codomains of these computations
are $N$-fold monoidal products of objects in $\cat{C}$, and so cannot themselves be
entangled. However, it is extremely common in cryptography to want to represent
joint or otherwise correlated input. For instance, if $\cat{C} =
\scat{Set}$, we may only care about inputs from a subset $\{(x, x)\}\subseteq
X\times X$. In the framework as described, it is impossible to restrict inputs
in such a way that does not decompose into a product.

There are various ad-hoc low-tech solutions to this problem, such as giving
the parties an oracle which rejects bad inputs, but we can also modify the
construction of our categories to allow for this kind of entangled input to
resources. Our goal will be to define a \emph{category of refinements on joint
states} which will allow us to refine the domains of our resources.

What is the categorical notion of subset? Every subset $A\subseteq X$ comes with
an \emph{inclusion function} $i: A\into X$, which is always an injection. As
usual, the categorical approach is to forefront the role of the morphism, in
this case the injection. It turns out there is a categorical generalization of
injections which makes no reference to objects having elements: a morphism $f:
x\to y$ is a \emph{monomorphism} if for all objects $z$ and maps $g, h: z\to x$,
if $fg = fh$, then $g = h$. In the category of sets, monomorphisms are exactly
injections. Given two monomorphisms $i: y\into x$ and $j: z\into x$, we say that
$i\leq j$ if there is a (necessarily unique) morphism $k: y\into z$ such that \[
  \begin{tikzcd}
    y\ar[hook, r, "i"]\ar[hook, dr, "k"'] & x\\
    & z\ar[hook, u, "j"']
  \end{tikzcd}
\]commutes. A \emph{subobject} of $x$ is an equivalence class of monomorphisms
into $x$ under the relation $i\sim j$ if $i\leq j$ and $j\leq i$.

To make a category of subobjects, we need a way to talk about morphisms between
subobjects of different objects. It turns out that in many categories there is a
way to talk about images of subobjects under morphisms, though we have not given
the background to go into detail here\footnote{For the categorically inclined:
  we have in mind a factorization system whose right class is the monomorphisms.
The direct image of a subobject $i: z\into x$ under a map $f: x\to y$ is the
monic part of the factorization of $fi$.}. We write $f_*i$ for the image of $i$
under the morphism $f$; in all our examples, this is the familiar image of a
subset.

Now we define the category $\pred{\cat{C}}$ of predicates on objects in
$\cat{C}$. Objects in this category are pairs $(x, i)$ where $x\in\cat{C}$ and
$i$ is a subobject of $x$. Morphisms $(x, i)\to (y, j)$ are maps $f: x\to y$ in
$\cat{C}$ such that $f_*i\leq j$, i.e. so that the image of $i$ under $f$ is
contained in $j$. Composition and identities are as in $\cat{C}$.

More generally, as with state we define $\pred{\cat{C}\xto{F}\cat{D}}$ for any
functor. Objects are pairs $(x, i)$ where $x\in\cat{C}$ and $i$ is a subobject
of $Fx$, while morphisms are maps $f: x\to y$ in $\cat{C}$ such that
$(Ff)_*i\leq j$.

If $F$ is strong monoidal and $\otimes_{\cat{D}}$ preserves monomorphisms (as it does in all
our categories of interest), then this category is also monoidal, with the
structure induced by the respective monoidal structures: \[
  (x, i)\otimes (y, j) = (x\otimes_{\cat{C}} y, (i\otimes_{\cat{D}} j)\phi^{-1}_{x,y}).
\]

Given a (strong monoidal) functor $F: \cat{C}\to\cat{D}$, there is a (strong
monoidal) functor $\pred{F}\to\pred{\cat{D}}$, which due to the notational
ambiguity\footnote{ Observe that pred is not functorial. Given a functor $F:
  \cat{C}\to\cat{D}$, the natural thing is to define a functor
  $\pred{\cat{C}}\to\pred{\cat{D}}$ which sends $(x, i)$ to $(Fx, Fi)$, but $Fi$
is not necessarily a monomorphism. } we call $\overline{F}$. This functor sends
a predicate $(x, i)$ to the predicate $(Fx, i)$, and a map $f$ to the map $Ff$.

Given an SMC $\cat{C}$, consider the category \[
  \oprot{N}{\cat{C}} := \state{\ncomb{\pred{\otimes^{N-1}}}\xto{\ncomb{\overline{\otimes^{N-1}}}}\ncomb{\pred{\cat{C}}}}.
\]
Basic objects in this category consists of a subobject $i$ of $X_1\otimes \dots\otimes
X_N$, a subobject $j$ of $Y_1\otimes \dots\otimes Y_N$, and a morphism
$f: X_1\otimes\dots\otimes X_N\to Y_1\otimes\dots\otimes Y_N$ in $\cat{C}$ such
that $f_*i\leq j$. The domain and codomain of this map are refinements of a
product state, which specify the allowable input and output states; the map must
send allowable inputs to allowable outputs. Objects in this category are finite
lists of basic objects. Morphisms are lists of n-combs in $\cat{C}^N$ whose
domains and codomains may be augmented with predicates, and whose maps must
respect those predicates. We define $\overline{\operatorname{prot}}!$ and
$\overline{\operatorname{prot}}^*$ similarly.

We expect that most readers are somewhat overwhelmed by the
proliferation of constructions on categories; this is quite understandable.
However, once this initial conceptual barrier is overcome, this proliferation of
constructions is actually very helpful; they allow us to fine-tune our base
category for any specific use-case.

\subsection{Interactive Proof}
\label{sec:interactive proof}

We now give an original representation of interactive proofs within the
framework. Recall from \Cref{sec:zkp}
that an \emph{interactive proof} for a
language $\cL$ consists of a prover and a verifier, both given an input $x$,
such that the verifier accepts if $x\in\cL$ and does not if $x\not\in\cL$, even
if the prover is behaving maliciously. While we do not yet know how to model
malicious behavior, we are already able to model the honest case. Fix a universe
of strings $A$ and a decidable\footnote{
  Note that $\cL$ needs to be decidable so that its characteristic function is
  in $\scat{CompStoch}$, which allows us to represent it as a resource. This
  restriction can technically be relaxed if we choose a bigger ambient category
  of computations, even while still requiring our prover to be computable.
} language $\cL$. This can be made significantly more
general, but for simplicity we will work over the category $\scat{CompStoch}$,
and let the verifier be bounded in $\scat{PPT}$. We will work in the category
$\oprota{2}{\scat{CompStoch}, \scat{PPT}}$.

We need to know what the input and output resources of an interactive proof
should be. Certainly we need a two-way channel between the prover and verifier.
Since our proofs are interactive, this needs to be multi-use, so it should be
the resource \[
  !\begin{pic}
    \draw (0,0) node[left] {$P$} -- ++(0, 1) node[left] {$V$};
  \end{pic}\quad\otimes\quad !\begin{pic}
  \draw (0,0) node[left] {$V$} node[right, xshift=3mm, yshift=1mm] {\normalsize.} -- ++(0, 1) node[left] {$P$};
  \end{pic}
\]

As output, the protocol should give a resource such that, on an input $(x, x):
x\in A$, the verifier outputs $\ind_\cL(x)$. Thanks to our work in the
previous section, we know how to encode this: the input to this resource should
be the subset $\{(x, x)\}\subseteq A\otimes A$. To describe this input
constraint pictorially, we want a box \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (i) at (0,0) {\textsc{Input}};
    \draw (i.north west) to ++(0, .3) node[left] {$A$};
    \draw (i.north east) to ++(0, .3) node[right] {$A$};
    \draw (i.south) to ++(0, -.3) node[left] {$A$};
  \end{pic}
\]such that doing some separate computations on each of the outputs, and then swapping
the results, is the same as doing the same computations on the other side, i.e.
for all $f: A\to X$ and $g: A\to Y$,
\begin{equation}\label{eqn:ip shared input}
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (i) at (0,0) {\textsc{Input}};
    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=-1mm] i.north west) to ++(0, .5) node[morphism] (f) {$f$};
    \draw ([xshift=1mm] i.north east) to ++(0, .5) node[morphism] (g) {$g$};
    \draw (i.south) to ++(0, -.3) node[left] {$A$};
    \draw (f.north) to[out=90, in=-90] ($(g.north)+(0, .8)$) node[right] {$X$};
    \draw (g.north) to[out=90, in=-90] ($(f.north)+(0, .8)$) node[left] {$Y$};
  \end{pic}\quad=\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (i) at (0,0) {\textsc{Input}};
    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=-1mm] i.north west) to ++(0, .5) node[morphism] (g) {$g$};
    \draw ([xshift=1mm] i.north east) to ++(0, .5) node[morphism] (f) {$f$};
    \draw (i.south) to ++(0, -.3) node[left] {$A$} node[right, xshift=5mm, yshift=3mm] {\normalsize.};
    \draw (g.north) to ++(0, .4) node[left] {$Y$};
    \draw (f.north) to ++(0, .4) node[right] {$X$};
  \end{pic}
\end{equation}

 Given such correlated inputs, our interactive proof should output a value of
$*\otimes \{0, 1\}$; the prover has no output, while the verifier outputs either
to accept or reject. In other words, the n-comb should have codomain
$(\textsc{Input}, 1_{*\otimes \{0, 1\}})$; these are both monomorphisms into
products, hence objects in $\pred{\otimes}$. The actual resource we want to
produce is the map \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (i) at (-.5,-1.3) {\textsc{Input}};
    \setlength\minimummorphismwidth{0mm}
    \draw[functor=cyan] (-1.3, -.6) -- (-.7, -.6) -- (-.7, .2) -- (-1.3, .2) node[left, opacity=1] {$P$} -- cycle;
    \draw[functor=green] (-.5, -.6) -- (.65, -.6) node[right, opacity=1]
    {$V$\normalsize,} -- (.65, .8) -- (-.5, .8) -- cycle;
    \draw (i.north west) to[out=90, in=-90] (-1, -.2) node[dot, fill=white] {};
    \node[morphism] (c) at (0,0) {$\ind_\cL$};
    \draw (c.south) to[out=-90, in=90] (i.north east);
    \draw (c) to ++(0, .6) node[right, xshift=-1mm] (b) {$\{0, 1\}$};
    \draw (i.south) to ++(0, -.3) node[left] {$A$};
  \end{pic}
\]where the prover is blue and the verifier is green. The point is that a
correct interactive proof should amount to the prover doing nothing with its
input, while the verifier outputs the characteristic function of the language
under proof.

We emphasize that this definition has no security properties; it does not even
guarantee completeness. For instance,
directly from \eqref{eqn:ip shared input} we can see that
\[
  \begin{pic}
    \draw[functor=cyan] (-1.5, -.6) -- (-.5, -.6) -- (-.5, .5) -- (-1.5, .5) node[left, opacity=1] {$P$} -- cycle;
    \draw[functor=green] (-.3, -.6) -- (.3, -.6) node[right, opacity=1]
    {$V$\normalsize,} -- (.3, .2) -- (-.3, .2) -- cycle;
    \draw[functor=green] (-.4, 1.2) -- (-.4, 1.8) node[left, midway, opacity=1]
    {$V$} -- (.8, 1.8) -- (.8, 1.2) -- cycle;
    \node[morphism] (i) at (-1, 0) {$\ind_\cL$};

    \draw (i.north) to[out=90, in=-90] (0, 1.5) node[right] {$\{0, 1\}$};

    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (in) at (-.5,-1.3) {\textsc{Input}};
    \draw (i.south) to[out=-90, in=90] (in.north west);
    \draw (in.north east) to[out=90, in=-90] (0, -.2) node[dot, fill=white] {};
    \draw (in.south) to ++(0, -.3) node[left] {$A$};
  \end{pic}
\]
the protocol where the prover just sends the answer to the verifier, is correct.

The reader may wonder which type the channels carry; this is a good question,
and we have actually been imprecise about it. If we wanted to model any specific
interactive proof, we could simply let it carry the type of messages that that
proof needs to communicate. For instance, in the previous protocol, we just need
a single-use channel which carries a message of type $\{0, 1\}$.
However, to reason about the existence or non-existence of interactive proofs,
we would need a way to model more general channels which can carry any data; we
do not currently have a way to do so\footnote{
  Since all our computations are binary-encoded, one option is to let this be a
  channel over the object $\bin^*$, but this requires forgetting type information
  that may be useful. With more categorical machinery, we could instead make this
  a \emph{polymorphic} channel. Again, we would need to adapt the standard
  categorical semantics of the polymorphic lambda calculus~\cite{seely-1987} to
  the comb framework. As the type theories involved get increasingly
  sophisticated, so too do the categorical requirements: we would need to give a
  kind of indexed cartesian closed category called a \emph{hyperdoctrine}
  satisfying a fairly intricate equational theory.
}.

\section{Security}
\label{sec:security}

We set aside all these proliferating functors and return to a familiar setting.
Consider a string $\cat{C}\xto{F}\cat{D}\xto{G}\cat{E}$ of symmetric monoidal
functors, which as in the previous section we interpret as including a class of
free or local processes into a broader class of processes. We are interested in
the category $\state{GF}$; we want to know when a morphism in this category is
secure. All of the constructions in the previous section fit this paradigm.

The main issue with defining security in the categorical setting is modelling
adversarial behavior. Recall from~\Cref{sec:uc}
that Universal Composability avoids
dealing with this issue by having the behavior of corrupted parties baked into
protocols via backdoor tapes. As this issue relies on a fairly low-level
understanding of the machine model, it is hard to adapt to the categorical
setting. Furthermore, cryptographic approaches to computation in some sense
fundamentally rely on the computations respecting some kind of type
system---this is how we interpret the objects in the category.

For expository purposes, in this section we will quite closely follow the
technical approach of~\cite{broadbent-karvonen-2022}. However, the machinery
they develop can be made significantly more general. We will see an example of
this in \Cref{sec:2-cat}

\subsection{Attack Models}
\label{sec:attack-models}

The primary tool of~\cite{broadbent-karvonen-2022} is the notion of \emph{attack
model}, which constrains the possible behavior of the adversary. The definition
is chosen specifically so that we can prove a composition theorem.

\begin{dfn}
  An \emph{attack model} $\AA$ on a symmetric monoidal category $\cat{C}$
  consists of, for each morphism $f$ in $\cat{C}$, a collection of morphisms
  $\AA f$ such that:
  \begin{enumerate}
    \item \label{item:am-id} $f\in \AA f$;
    \item \label{item:am-seq-comp} if $f'\in\AA f$ and $g'\in\AA g$ so that $f$ and $g$ compose and $f'$
      and $g'$ compose, then $g'f'\in\AA (gf)$;
    \item \label{item:am-con-comp} if $f'\in\AA f$ and $g'\in\AA g$, then $f'\otimes g'\in\AA (f\otimes
      g)$;
    \item \label{item:am-seq-fact} if $h\in\AA (gf)$, then there is some $g'\in\AA g$ and $f'\in\AA f$ such
      that $h = g'f'$ \emph{up to structure isomorphism}\footnote{
        The requirement that this equation only holds up to coherence
        isomorphism is new to us; this is a small technical error
        in~\cite{broadbent-karvonen-2022}. The issue is that, if the domain $x$
        of $h$ does not factor into a monoidal product, then it is impossible to
        find such a horizontal factorization of $h$. Our suggested fix
        functionally allows the domain of this factorization to be $x\otimes I$.

        As an example of the issue, even the maximal attack model defined
        in~\Cref{ex:trivial-attacks} does not satisfy the original
        version of the axiom. Consider the free strict symmetric monoidal
        category on one generator $x$ and let $f = g = 1_x.$ Then $1_I$ is an
        attack on $f\otimes g$, but it is impossible to factor $1_I$ as the
        unrepaired axiom requires.
      };
    \item \label{item:am-con-fact} if $h\in\AA (f\otimes g)$, then there is some $h'\in\AA 1_{\cod
      f\otimes\cod g}$, $f'\in\AA f$, and $g'\in\AA g$ such that $h = h'\circ
      (f'\otimes g')$.
  \end{enumerate}
\end{dfn}

The definition is motivated as follows. The collection $\AA f$ represents all
the possible actions that the adversary could force to occur, if the protocol
specifies that the morphism $f$ is supposed to occur. The first condition says
that any adversary is allowed to act as an honest party. The second and third
say that, if the adversary has a pair of attacks on two separate computations,
then they can compose those attacks to get an attack on the composite
computation. These all seem very natural in any threat model.

The fourth axiom says that any attack on a sequential composite protocol $gf$
factors into attacks on each of its subprotocols. This point is somewhat
subtler; it seems at first that this should rule out attacks where the adversary
against the first protocol forwards its view to the adversary against the second,
hence allowing the adversary against the second to do something it cannot do on
its own. Such attacks are extremely common, and so certainly need to be
included. However, the point of the definition is that the morphisms in $\AA f$
do not have to have the same domain as $f$. As such, the composite attack can
model the forwarded view by representing the adversary on the second protocol
with an attack whose codomain includes that extra input.

The fifth axiom says something similar, but about attacks on parallel processes.
The complication here is that the two separate attacks may need some way to
combine their data at the end; this is represented by an extra attack on the
identity, which is semantically identified with the do-nothing computation; such
attacks thus generally consist of adversaries manipulating their own state.

\begin{ex}\label{ex:trivial-attacks}
  On any symmetric monoidal $\cat{C}$, the \emph{honest}\footnote{Called
  \emph{minimal} in~\cite{broadbent-karvonen-2022}.} attack model is given
  by $\AA f = \{f\}$, while the \emph{maximal} attack model is given by $\AA f =
  \sqcup_{x,y\in\cat{C}}\cat{C}(x, y)$, i.e. in the maximal attack model any
  morphism is an attack on any morphism. In particular, attacks in the maximal
  attack model factor via identities: if $h'\in\AA (f\otimes g)$, then up to
  structure isomorphism $h' = h'\otimes 1_I$.
\end{ex}

\begin{dfn}
  Let $\cat{C}_1,\dots,\cat{C_N}$ be symmetric monoidal categories with attack
  models $\AA_1,\dots,\AA_N$. Then the \emph{product attack model}
  $\prod_{i=1}^N \AA_i$ on $\prod_{i=1}^N \cat{C}_i$ is given by \[
    (\prod_{i=1}^N \AA_i)(f_1,\dots, f_N) = \prod_{i=1}^N \AA_i f_i.
  \]
\end{dfn}

We can use the previous two results to modify malicious behavior in $N$-party
computation. For instance, by placing the maximal attack model on some subset of
the categories and the honest attack model on the others, the product attack
model represents some parties acting independently, but maliciously, while the
others act honestly. If we want the adversaries to be able to communicate, then
we can consider the functor \[
  \cat{C}^N\xto{1_\cat{C}^{N-k}\times\otimes^{k-2}}\cat{C}^{N-k}\times\cat{C}\xto{\otimes^{N-k}}\cat{C},
\]and place the maximal attack model on the final copy of $\cat{C}$ in the
middle step. This means that the $k$ parties on the right can behave
arbitrarily, including coordinating securely amongst themselves, while the other
parties behave honestly.

It is also possible to extend attack models to the various constructions of
\Cref{sec:protocols}.
In~\cite{broadbent-karvonen-2022}, they place an attack model on
$\ncomb{\cat{C}}$ representing a single malicious party; we give a slight
generalization which allows extending arbitrary attack models to this setting.
Recall that a comb $[(X_1, Y_1), \dots, (X_n, Y_n)[\to (X', Y')$ in
$\ncomb{\cat{C}}$ is formally a permutation $\sigma$ and a list $[\xi_1, \dots,
\xi_{n+1}]$ of morphisms in $\cat{C}$ with appropriate types. Any attack model
defined on such combs extends to an attack model on all morphisms, since
morphisms are just lists of combs.

\begin{dfn}\label{def:n-comb-attack}
  Let $\cat{C}$ be a symmetric monoidal category and $\AA$ an attack model. Then
  there is an induced attack model on $\ncomb{\cat{C}}$ defined as follows: an
  attack on the comb $(\sigma, [\xi_1, \dots, \xi_{n+1}])$ is a pair
  $(\sigma, [a_1, \dots, a_{n+1}])$ such that $a_i\in\AA \xi_i$ for all
  $i$; note that the permutations $\sigma$ must agree.
\end{dfn}

\begin{prop}
  \Cref{def:n-comb-attack} defines an attack model on
  $\ncomb{\cat{C}}$.
\end{prop}

\begin{proof}
  Each morphism is an attack on itself by the same property for $\AA$. Since the
  attack model on monoidal products is defined as the concatenation of attacks
  on the components, the attack model is compatible with and factors with
  respect to the monoidal product.

  Recall that the (sequential) composition of combs is defined by nesting.
  Because the attacks are defined locally, fixing the permutation and specifying
  attack morphisms for each piece of the comb, we can consider each piece of the
  comb on its own. When not working ``at the ends'' of one of the inner combs,
  there is no local composition happening, so the result follows immediately.
  The difficultly is at this boundary, where the situation looks like \[
  \begin{pic}
    \setlength\minimummorphismwidth{10mm}
    \node[morphism] (xi1') at (0,0) {$\xi$};
    \draw ([xshift=2.5pt]xi1'.north east) to ++(0, 1.15) node[right] {$z'$};
    \node[morphism,scale=.6] (xi1) at ($(xi1'.north west)+(0, .5)$)
    {\normalsize$g$};
    \draw (xi1.north) to ++(0, .5);
    \draw (xi1'.north west) -- (xi1.south);
    \draw ([xshift=2.5pt]xi1'.south east) to ++(0, -1.15) node[right, xshift=2em,
    yshift=1.5em] {\normalsize.} node[right] {$z$};
    \node[morphism,scale=.6] (xin) at ($(xi1'.south west)+(0, -.5)$)
    {\normalsize$f$};
    \draw (xi1'.south west) -- (xin.north);
    \draw (xin.south) to ++(0, -.5);
  \end{pic}
\]
Given attacks on $f$, $\xi$, and $g$, we see directly by the compatibility
properties of $\AA$ that these yield an attack on this composite.
Given an attack on this composite, i.e. a morphism \[
  a\in\AA((g\otimes 1_{z'})\xi(f\otimes 1_z)),
\] factor $a$ into attacks as guaranteed by the definition of $\AA$. Combining
these factorizations yields the desired factorization of the global attack.
\end{proof}

\subsection{The Security Definition}

Recall that objects in $\state{GF}$ are
pairs $(x, s)$, where $s\in\cat{E}(I, GFx)$, while morphisms $f: (x, s)\to (y,
t)$ are maps $f: x\to y$ in $\cat{C}$ such that $fs = t$.

\begin{dfn}\label{def:sec-condition}
  Let $\cat{C}\xto{F}\cat{D}\xto{G}\cat{E}$ be a string of
  symmetric monoidal functors so that $F$ is strong monoidal. Let $f: (x,
  s)\to (y, t)$ be a map in $\state{GF}$ and let $a$ be a map in $\cat{D}$ with
  $\dom a = Fx$. Then $f$ is \emph{secure against the attack $a$} if
  there is an attack $a'\in\AA (1_{Fy})$ such that $\dom a' = Fx$, $\cod a =
  \cod a'$, and the following diagram commutes in $\cat{E}$:\[
    \begin{tikzcd}
      I\ar[r, "s"]\ar[d, "t"'] & GFx\ar[d, "Ga"]\\
      GFy\ar[r, "Ga'"'] & G\cod a\punctuation{.}
    \end{tikzcd}
  \]
\end{dfn}

\begin{dfn}
  Let $\cat{C}\xto{F}\cat{D}\xto{G}\cat{E}$ be a string of
  symmetric monoidal functors so that $F$ is strong monoidal. Let $\AA$ be an
  attack model on $\cat{D}$. A map $f: (x, s)\to (y, t)$ in $\state{GF}$ is
  $\AA$-\emph{secure} if it is secure against all attacks in $\AA Ff$.
\end{dfn}

The idea is that, for every attack $a$ on the real protocol, there should be an
attack $a'$ on the ideal protocol which produces the same final state. The
restriction on the domains says that the adversaries must start from the same
state as in the actual protocol. This notion is fundamentally not black-box: the
ideal adversary $a'$ is introduced after, and so may depend on, the real
adversary $a$. Moreover, because of the untyped nature of adversaries in this
paradigm, it seems quite difficult to encode black-box simulation within the
model.

The definition immediately seems somewhat relaxed in comparison to the well-known
approach of UC: the ideal adversary is required to produce the same state only
at the end of the protocol, rather than constantly simulating the real adversary
to the environment throughout the protocol execution. As we will see, this is
already enough to prove a composition theorem; however, it is unclear to the
author whether this is enough to entail all the security properties we want in
the most general settings.

We now aim to prove the following composition theorem\footnote{
  Note that~\cite{broadbent-karvonen-2022} prove this theorem under the
  assumption that $\cat{D} = \cat{E}$ and $\cat{G} = 1_\cat{D}$, but allow more
  flexibility in the definition of the category of states, such that the
  theorems are equivalence. We choose the presentation here because it
  generalizes more directly, and reflects all of the examples studied so far.
  The proof given here is substantively identical to theirs, except that our
  security condition is based on commutativity in $\cat{E}$ rather than
  $\scat{Set}$.

  To see the equivalence between the theorems, to go from theirs to ours take
  $\cat{E} = \scat{Set}$ and $G = R$ (and use the fact that $*$ represents
  $1_\scat{Set}$), while to go from ours to theirs take $R = \hom(I, -)G$.
}.

\begin{thm}\label{ccc:composition}
  Let $\cat{C}\xto{F}\cat{D}\xto{G}\cat{E}$ be a string of symmetric monoidal
  functors so that $F$ is strong monoidal. Let $\AA$ be an attack model on
  $\cat{D}$. Then the class of $\AA$-secure maps forms a wide symmetric monoidal
  subcategory of $\state{GF}$.
\end{thm}

As parallel composition theorems go, this is a fairly weak result. In
particular, it does not give us any security guarantee when composing with any
processes which are not secure, and it requires that we can construct our
composition operation as a monoidal product: it is not clear that this can
capture the same generality as the universal composition operation. We will have
more to say about this in \Cref{sec:evaluation}.

To demonstrate the claim, we need to show that this class is closed under
composition and monoidal product, that it contains all the identities, and that
it contains the coherence isomorphisms. We will show the latter two claims
first, since they will be used for the others. It suffices to show the following
more general lemma.

\begin{lemma}
  All isomorphisms in $\state{GF}$ are $\AA$-secure.
\end{lemma}

\begin{proof}
  Let $f: (x, s)\to (y, t)$ be an isomorphism, and recall
  from~\Cref{thm:cat-elements-reflects-isos} that the underlying
  map $f$ in $\cat{C}$ is also an isomorphism. Let $a\in\AA (Ff)$ be an attack such
  that $\dom a = Fx$. Then since $Ff^{-1}\in\AA Ff^{-1}$, by compatibility
  with composition we have \[aFf^{-1}\in \AA F(ff^{-1}) = \AA 1_{Fy}.\] Now
  since $(GFf)s = t$ by definition of the category of states, \[
    \begin{tikzcd}
      & I\ar[dl, "s"']\ar[rd, "t"] \\
      GFx && GFy\ar[ll, "GFf^{-1}"]
    \end{tikzcd}
    % (Ga)s = (Ga)(GFf^{-1})(GFf)s = G(a(Ff^{-1}))t.
  \] commutes in $\cat{E}$. Pasting $Ga$ onto the bottom-left of this diagram yields the
  commutative diagram
  \[
    \begin{tikzcd}
      I\ar[rr, "s"]\ar[d, "t"'] && GFx\ar[d, "Ga"]\\
      GFy\ar[r, "GFf^{-1}"'] & GFx\ar[r, "Ga"'] & G\cod a\punctuation{,}
    \end{tikzcd}
  \]which is the desired result.
\end{proof}

Next, we show that the class of secure maps is closed under composition.

\begin{lemma}
  Let $f: (x, s)\to (y, t)$ and $g: (y, t)\to (z, u)$ be $\AA$-secure maps.
  Then $gf$ is $\AA$-secure.
\end{lemma}

\begin{proof}
  Let $a\in\AA F(gf)$ be an attack such that $\dom a = Fx$. Let
  $a_f\in\AA Ff$ and $a_g\in\AA Fg$ be attacks such that $a_ga_f = a$, as is
  guaranteed by~\Cref{item:am-seq-fact} in the definition of an attack
  model. Since $f$ is $\AA$-secure, there is an attack
  $a_f'\in\AA 1_{Fy}$ with $\dom a_f' = Fx$ and $\cod a_f'
  = \cod a_f$ such that the following diagram commutes in $\cat{E}$: \[
    \begin{tikzcd}
      I\ar[r, "s"]\ar[d, "t"'] & GFx\ar[d, "Ga_f"]\\
      GFy\ar[r, "Ga_f'"'] & G\cod a_f\punctuation{.}
    \end{tikzcd}
  \]
  Now since $a'_f\in\AA 1_{Fy}$ and $a_g\in\AA Fg$, since attacks are
  compatible with composition we have that $a_ga_f'\in\AA Fg$, so there is
  $a_g'\in \AA 1_{Fz}$ such that the following diagram commutes: \[
    \begin{tikzcd}
      I\ar[rr, "t"]\ar[dd, "u"'] && GFy\ar[d, "Ga_f'"]\\
                                && G\cod a_f\ar[d, "Ga_g"] \\
      GFz\ar[rr, "Ga_g'"'] && G\cod a_g\punctuation{.}
    \end{tikzcd}
  \] By pasting the previous two diagrams along the edge $I\xto{t}
  GFy\xto{Ga'_f} G\cod a_f$, we finally see that \[
    \begin{tikzcd}
      I\ar[rr, "s"]\ar[dd, "u"'] && GFx\ar[d, "Ga_f"]\\
                                && G\cod a_f\ar[d, "Ga_g"] \\
      GFz\ar[rr, "Ga_g'"'] && G\cod a_g
    \end{tikzcd}
  \]commutes; this is the desired result.
\end{proof}

The pattern of this argument has cryptographic meaning. The attack $a'_f$ on
$1_{Fy}$ is the ideal adversary for the attack against the real protocol $f$.
The composite adversary $a_ga'_f$ is first the ideal adversary for $f$ and then
the real adversary for $g$. By this point in the proof, the point is that the
attack on $g$ can do no better than using the output state of the attack on
$f$, hence can be simulated by a simulator $a'_g$ against this composite.

Finally, we prove that the class of secure maps is closed under monoidal
product.

\begin{lemma}\label{thm:closed-under-monoidal}
  Let $f: (x, s)\to (y, t)$ and $g: (z, u)\to (w, v)$ be $\AA$-secure maps.
  Then $f\otimes g$ is $\AA$-secure.
\end{lemma}

\begin{proof}
  Let $\psi_{x,y}: Fx\otimes_{\cat{D}} Fy\to F(x\otimes_{\cat{C}} y)$ and
  $\phi_{x,y}: Gx\otimes_{\cat{E}}\to G(x\otimes_{\cat{D}} y)$ be the structure
  maps of $F$ and $G$, respectively, so that $\psi$ is an isomorphism since $F$
  is strong monoidal.

  We first prove the claim when $\cat{C} = \cat{D}$ and $F = 1_\cat{D}$.
  Let $a\in \AA (f\otimes g)$ be an attack such that $\dom a = x\otimes z$.
  Let $a_f\in\AA f$, $a_g\in \AA g$, and $a_1\in \AA 1_{y\otimes w}$ be
  attacks such that $a = a_1(a_f\otimes a_g)$, as guaranteed
  by~\Cref{item:am-con-fact} in the definition of an attack model. Since
  $f$ and $g$ are $\AA$-secure, there are attacks $a_f'\in\AA 1_y$ and
  $a_g'\in\AA 1_w$ such that \[
    \begin{tikzcd}
      I\ar[r, "s"]\ar[d, "t"'] & Gx\ar[d, "Ga_f"]\\
      Gy\ar[r, "Ga_f'"'] & G\cod a_f
    \end{tikzcd}
    \quad\text{and}\quad
    \begin{tikzcd}
      I\ar[r, "u"]\ar[d, "v"'] & Gz\ar[d, "Ga_g"]\\
      Gw\ar[r, "Ga_g'"'] & G\cod a_g
    \end{tikzcd}
  \] commute.
  Let $o = \cod a_f$ and $p = \cod a_g$. Letting $\phi$ be the structure
  map which witnesses monoidality of $G$, we claim that \[
    \begin{tikzcd}
      I\ar[r, "s\otimes_{\cat{E}} u"]\ar[d, "t\otimes_{\cat{E}} v"'] &
        Gx\otimes_{\cat{E}} Gz\ar[d, "Ga_f\otimes_{\cat{E}} Ga_g"']\ar[r, "\phi_{x, z}"] &
        G(x\otimes_{\cat{D}} z)\ar[d, "G(a_f\otimes_{\cat{D}} a_g)"']\ar[dr, "Ga"]
      \\
      Gy\otimes_{\cat{E}} Gw\ar[r, "Ga_f'\otimes_{\cat{E}} Ga_g'"']\ar[dr, "\phi_{y, w}"'] &
        Go\otimes_{\cat{E}} Gp\ar[r, "\phi_{o,p}"'] &
        G(o\otimes_{\cat{D}} p)\ar[r, "Ga_1"'] &
        G\cod a
      \\ &
      G(y\otimes_{\cat{D}} w)\ar[ur, "G(a'_f\otimes_{\cat{D}} a'_g)"']
    \end{tikzcd}
  \] commutes. Indeed, the top-left square is the product of the two previous diagrams,
  the middle square is naturality of $\phi$, the right triangle is the definition
  of $a_f$, $a_g$, and $a_1$, and the bottom square is naturality of $\phi$ again.

  Now notice that the top path along this diagram is exactly the definition of
  the product $s\otimes u$ in $\state{G}$, while the left path is the definition
  of $t\otimes v$. As such, the top-right path is the top-right path of the
  square we need to commute to show security of $f\otimes g$. It just suffices
  to show that $a_1\circ (a'_f\otimes_{\cat{D}} a'_g)$ is an attack on the ideal
  model to complete the proof, but this follows because of the composition
  properties of attack models.

  Now we prove the claim for arbitrary $F$. Notice that a map $f: (x, s)\to
  (y, t)$ is secure in $\state{GF}$ if and only if $Ff: (Fx, s)\to (Fy, t)$ is
  secure in $\state{F}$: the commutative squares witnessing security are
  exactly the same. Since $f$ and $g$ are secure, now $Ff$ and $Fg$ are secure,
  so by the previous special case $Ff\otimes_\cat{D} Fg$ is secure. Furthermore,
  $\psi$ is an isomorphism, so secure. Finally, since
  \[
    F(f\otimes_\cat{C} g) = \psi_{y,w}(Ff\otimes_\cat{D} Fg)\psi^{-1}_{x,z}
  \] is the composite of secure maps, it is secure, and so $f\otimes_\cat{C} g$
  is secure.
  %
  % Let $a\in \AA F(f\otimes g)$ be an attack such that $\dom a = F(x\otimes z)$.
  % Let $a_f\in\AA Ff$, $a_g\in \AA Fg$, and $a_1\in \AA 1_{F(y\otimes w)}$ be
  % attacks such that $a = a_1(a_f\otimes a_g)$, as guaranteed
  % by~\Cref{item:am-con-fact} in the definition of an attack model. Since
  % $f$ and $g$ are $\AA$-secure, there are attacks $a_f'\in\AA 1_{Fy}$ and
  % $a_g'\in\AA 1_{Fw}$ such that \[
  %   \begin{tikzcd}
  %     I\ar[r, "s"]\ar[d, "t"'] & GFx\ar[d, "Ga_f"]\\
  %     GFy\ar[r, "Ga_f'"'] & G\cod a_f
  %   \end{tikzcd}
  %   \quad\text{and}\quad
  %   \begin{tikzcd}
  %     I\ar[r, "u"]\ar[d, "v"'] & GFz\ar[d, "Ga_g"]\\
  %     GFw\ar[r, "Ga_g'"'] & G\cod a_g
  %   \end{tikzcd}
  % \] commute.
  % Let $o = \cod a_f$ and $p = \cod a_g$. Letting $\phi$ be the structure
  % map which witnesses monoidality of $G$, we claim that \[
  %   \begin{tikzcd}
  %     I\ar[r, "s\otimes_{\cat{E}} u"]\ar[d, "t\otimes_{\cat{E}} v"'] &
  %       GFx\otimes_{\cat{E}} GFz\ar[d, "Ga_f\otimes_{\cat{E}} Ga_g"']\ar[r, "\phi_{Fx, Fz}"] &
  %       G(Fx\otimes_{\cat{D}} Fz)\ar[d, "G(a_f\otimes_{\cat{D}} a_g)"']\ar[dr, "Ga"]
  %     \\
  %     GFy\otimes_{\cat{E}} GFw\ar[r, "Ga_f'\otimes_{\cat{E}} Ga_g'"']\ar[dr, "\phi_{Fy, Fw}"'] &
  %       Go\otimes_{\cat{E}} Gp\ar[r, "\phi_{o,p}"'] &
  %       G(o\otimes_{\cat{D}} p)\ar[r, "Ga_1"'] &
  %       G\cod a
  %     \\ &
  %     G(Fy\otimes_{\cat{D}} Fw)\ar[ur, "G(a'_f\otimes_{\cat{D}} a'_g)"']
 %   \end{tikzcd}
  % \] commutes. Indeed, the top-left square is the tensor of the two previous diagrams,
  % the middle square is naturality of $\phi$, the right triangle is the definition
  % of $a_f$, $a_g$, and $a_1$, and the bottom shape is naturality of $\phi$ again.
\end{proof}

Putting it all together:

\begin{proof}[Proof of~\Cref{ccc:composition}]
  We have shown that the class of secure maps is closed under composition and
  monoidal product, and contains all the identities and coherence isomorphisms.
  This is the desired result.
\end{proof}

In universal composability, there is a theorem which says that a protocol is
UC-secure if and only if it is UC-secure against the ``trivial
adversary''\footnote{Called the ``dummy adversary'' in the literature.}, which
just forwards all its messages to the environment~\cite[Claim 11]{canetti-2020}.
There is a similar notion in the categorical model, which
\cite{broadbent-karvonen-2022} call an \emph{initial class of attacks}.

\begin{dfn}
  Let $\cat{C}$ be a symmetric monoidal category with attack model $\AA$. Let
  $f: x\to y$ be a morphism in $\cat{C}$. A sub-collection $X$ of $\AA f$ is \emph{initial} if for any
  $a\in\AA f$ with $\dom a = x$, there exists some $a_x\in X$ and $a_1\in\AA
  1_y$ such that $a = a_1a_x$.
\end{dfn}

\begin{ex}
  When $\AA$ is the maximal attack model, any map $f: x\to y$ has an initial
  attack given by just $1_x$. This corresponds to the trivial adversary in UC.
\end{ex}

\begin{thm}
  Let $\cat{C}\xto{F} \cat{D}\xto{G}\cat{E}$ be a string of monoidal functors so
  that $F$ is strong monoidal. Let $f: (x, s)\to (y, t)$ be a morphism in
  $\state{GF}$. Let $\AA$ be an attack model on $\cat{D}$ and let $X$ be an
  initial sub-collection of $\AA f$. Then $f$ is $\AA$-secure if and only if it
  is secure against all attacks in $X$.
\end{thm}

\begin{proof}
  The forwards direction is immediate because $X\subseteq \AA f$. For the
  backwards direction, let $a\in \AA Ff$ be an attack such that $\dom a = Fx$.
  By the definition of an initial subcollection, let $a = a_1a_x$ with $a_x\in
  X$ and $a_1\in \AA 1_{Fy}$. Since $f$ is secure against $a_x$, there is an
  $a_x'\in \AA 1_{Fy}$ witnessing the security condition. Now $a_1a_x'\in\AA
  1_{Fy}$, and further \[
    \begin{tikzcd}
      I\ar[r, "s"]\ar[d, "t"'] & GFx\ar[d, "Ga_x"']\ar[dr, "Ga"]\\
      GFy\ar[r, "Ga_x'"'] & G\cod a_x\ar[r, "Ga_1"'] & G\cod a \\
    \end{tikzcd}
  \] commutes: the square by the security condition for $a_x$, and the triangle
  by definition of $a_x$ and $a_1$. This is the desired result.
\end{proof}

Finally, the following lemma is a helpful computational tool.

\begin{prop}
  Let $\cat{C}_1,\dots,\cat{C}_N$ be symmetric monoidal categories with attack
  models $\AA_1,\dots,\AA_N$. Let $f_1,\dots,f_N$ be morphisms in the respective
  categories and let $X_1,\dots,X_N$ be initial subcollections of $\AA_i f$.
  Then $\prod_{i=1}^N X_i$ is an initial subcollection of $\prod_{i=1}^N \AA_i f_i$.
\end{prop}

\begin{proof}
  Given an attack $(a_1,\dots,a_N)\in\prod_{i=1}^N \AA_i f_i$ with $\dom a_i =
  \dom f_i$, factor it componentwise, and assemble the resulting attacks into an
  attack in $\prod_{i=1}^N X_i$.
\end{proof}

% \begin{prop}
%   Let $\cat{C}$ be a symmetric monoidal category with attack model $\AA$.
%   Suppose that for every morphism $f\in\cat{C}$, there is an initial
%   subcollection $X_f\subseteq\AA f$. Given a comb $(\sigma, [\xi_1, \dots,
%   \xi_{n+1}])$, define a class $X$ of combs in $\ncomb{\cat{C}}$ consisting of
%   exactly those combs $(\sigma, [x_1, \dots, x_{n+1}])$ such that
%   $x_i\in X_{\xi_i}$. This is an initial subcollection of attacks on the given
%   comb, and furthermore this result extends to lists of combs.
% \end{prop}
%
% \begin{proof}
%   We need to show that any attack factors in the desired way. Given an attack
%   $(\sigma, [a^1, \dots, a^{n+1}])$ on the comb, factor each $a_i$ into $a_x^i$
%   and $a_1^i$ as guaranteed by the definition of an initial subcollection.
%   Assemble these attacks into a comb $(\sigma, [a_x^1, \dots, a_x^{n+1}])$,
%   which is in $X$, and a comb $(\sigma, [a_1^1, \dots, a_1^{n+1}])$, which is an
%   attack on the identity comb.
% \end{proof}

\subsection{The One-Time Pad}

Still following~\cite{broadbent-karvonen-2022}, we now show security of the
one-time pad. We equip $\cat{C}^3$ with the product attack model, where $A$ and
$B$ have the honest attack model, and $E$ has the maximal attack model. This
induces an attack model on $\ncomb{\cat{C}^3}$
by~\Cref{def:n-comb-attack}.

First, note that the eavesdropper has an initial attack given by computing the
identity. To prove security, we need to give an attack on the ideal protocol \[
  \begin{pic}
    \draw (0,0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm]
    {\normalsize.} to ++(0, 1.5) node[left] {$B$};
    % \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
    %   \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
    %   \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
    %   \draw (am) to ++(0, .5) node[left] {$B$};
  \end{pic}
\] Such an attack can have $E$ compute any map on their own, without any
interaction with $A$ and $B$, while $A$ and $B$ must compute exactly this
resource. We will choose the map \[
  \begin{pic}
    \draw (0,0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm]
    {\normalsize.} to ++(0, 1.5) node[left] {$B$};
    \draw (-1,.5) node[state, scale=.75] {\normalsize\$} to ++(0, .8) node[left]
    {$E$};
  \end{pic}
\]
\begingroup
  \allowdisplaybreaks
Now we just compute: \begin{align*}
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist) node[left, xshift=-3mm] {$A$};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=3mm] {$B$} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) node[above right, xshift=-.5mm] {$B$} to[out=90, in=0] (bm);
    \draw (copy) node[above right, yshift=1mm] {$B$} to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) node[left] {$E$} to ++(0, .2);
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic}\quad&\xequals{\eqref{eqn:mult-deterministic}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,0) {};
    \node[dot, fill=white] (copy2) at (.3,0) {};
    \node[dot, fill=black] (mult1) at (-.3, .6) {};
    \node[dot, fill=black] (mult2) at (.3, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-10] (mult2);
    \draw (copy1) to (mult2);
    \draw (copy2) to (mult1);
    \draw (copy1) -- ++(0, -1.5) node[left] {$A$};
    \draw (copy2) to[out=-90, in=180] (keydist);
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) to[out=90, in=0] (bm);
    \draw (mult2) to[out=90, in=180] (bm);
    \draw (mult1) to ++(0, .5) node[left] {$E$};
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic} \\
  &\xequals{\eqref{eqn:coassociative}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[dot, fill=white] (copy2) at (.3,-.7) {};
    \node[dot, fill=black] (mult1) at (-.3, .45) {};
    \node[dot, fill=black] (mult2) at (.3, .45) {};
    \node[dot, fill=white] (keydist) at (.8, -.2) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-90] (keydist);
    \draw (copy1) to (mult2);
    \draw (copy2) to (mult1);
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (copy2) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
    to ++(0, .15) node[dot, fill=black] {} to++(0, .15) to[out=90, in=0] (bm);
    \draw (keydist) to[out=180, in=-90] ++(-.5, .5) to (mult2);
    \draw (mult2) to[out=90, in=180] (bm);
    \draw (mult1) to ++(0, .5) node[left] {$E$};
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic} \\
  &\xequals{\eqref{eqn:monoid associative}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[dot, fill=white] (copy2) at (.3,-.7) {};
    \node[dot, fill=black] (mult1) at (-.3, 1.3) {};
    \node[dot, fill=black] (mult2) at (.3, 1.3) {};
    \node[dot, fill=white] (keydist) at (.8, -.2) {};
    \node[dot, fill=black] (bm) at (.8, .8) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-90] (keydist);
    \draw (copy1) to (mult2);
    \draw (copy2) to (mult1);
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (copy2) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
     node[dot, fill=black] {} to[out=90, in=0] (bm);
     \draw (keydist) to[out=180, in=-90] ++(-.5, .5) to[out=90, in=180] (bm);
    \draw (mult2) to[out=0, in=90] (bm);
    \draw (mult1) to ++(0, .5) node[left] {$E$};
    \draw (mult2) to ++(0, .5) node[left] {$B$};
  \end{pic} \\
  &\xequals{\eqref{eqn:inverse}} \quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[dot, fill=white] (copy2) at (.3,-.7) {};
    \node[dot, fill=black] (mult1) at (-.3, 1.3) {};
    \node[dot, fill=black] (mult2) at (.3, 1.3) {};
    \node[dot, fill=white] (keydist) at (.8, -.2) {};
    \node[dot, fill=black] (bm) at (.8, .8) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-90] (keydist);
    \draw (copy1) to (mult2);
    \draw (copy2) to (mult1);
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (copy2) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult2) to[out=0, in=90] (bm);
    \draw (mult1) to ++(0, .5) node[left] {$E$};
    \draw (mult2) to ++(0, .5) node[left] {$B$};
  \end{pic} \\
  &\xequals{\eqref{eqn:counital}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[dot, fill=black] (mult1) at (-.3, 1.3) {};
    \node[dot, fill=black] (mult2) at (.8, .2) {};
    \node[dot, fill=black] (bm) at (1.4, -.4) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy1) to[out=10, in=190] (mult2);
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (mult1) to[out=-10, in=90] ++(.5, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult2) to[out=0, in=90] (bm);
    \draw (mult1) to ++(0, .5) node[left] {$E$};
    \draw (mult2) to ++(0, .5) node[right] {$B$};
  \end{pic} \\
  &\xequals{\eqref{eqn:monoid unital}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[dot, fill=black] (mult1) at (-.3, 1.3) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy1) to[out=10, in=-90] (.8, .2) to ++(0, .5) node[right] {$B$};
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (mult1) to[out=-10, in=90] ++(.5, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult1) to ++(0, .5) node[left] {$E$};
  \end{pic} \\
  &\xequals{\eqref{eqn:random-invariance}}\quad
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.3,-.7) {};
    \node[state, scale=.75] (rand) at (-.3, .5) {\normalsize\$};
    \draw (copy1) to[out=170, in=-90] ++(-.5, .5) node[dot, fill=white] {};
    \draw (copy1) to[out=10, in=-90] (.8, .2) to ++(0, .5) node[right] {$B$};
    \draw (copy1) -- ++(0, -1) node[left] {$A$};
    \draw (rand) to ++(0, .5) node[left] {$E$};
  \end{pic} \\
  &\xequals{\eqref{eqn:counital}}\quad
  \begin{pic}
    \draw (0,0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm]
    {\normalsize.} to ++(0, 1.5) node[left] {$B$};
    \draw (-1,.5) node[state, scale=.75] {\normalsize\$} to ++(0, .8) node[left]
    {$E$};
  \end{pic}
\end{align*}
\endgroup

This is the entire proof.

\subsection{A 2-Categorical Generalization}
\label{sec:2-cat}

In many situations in cryptography, we want to consider not
equality of protocols, but rather some weaker notion of indistinguishability or
even an asymmetric reducibility relation. There is a natural categorical model
of such settings, in the form of \emph{2-categories}, in which there are not
only morphisms between objects, but also 2-morphisms between morphisms, which we
think of as encoding reductions. We now present an original generalization of
the above theory to this setting.

\begin{dfn}
  A (strict) \emph{2-category} $\cat{C}$ consists of:
  \begin{itemize}
    \item A collection of \emph{0-cells};
    \item For each pair of 0-cells $x,y$, a category $\cat{C}(x, y)$, whose
      objects are called \emph{1-cells} and whose morphisms are called
      \emph{2-cells};
    \item For each triple of 0-cells $x,y,z$, a functor $\circ_{x,y,z}: \cat{C}(y, z)\times \cat{C}(x, y)\to \cat{C}(x, z)$;
    \item For each 0-cell $x$, an identity 1-cell $1_x\in\cat{C}(x, x)$.
  \end{itemize}
  The functor $\circ$ must be unital and associative; see for instance~\cite{kelly-1981}.
\end{dfn}

Let us ``unroll'' what this definition says. We have 1-cells between 0-cells,
and 2-cells between 1-cells. There is one way to compose 1-cells, via the
functor $\circ$, but two ways to compose 2-cells: within their own hom-category,
via its internal composition, or with those from other hom-categories, via
$\circ$. The situation is identical to the vertical and horizontal composition
of natural transformations, and thus this is the fundamental example:

\begin{ex}
  The category of categories $\scat{Cat}$ is a 2-category, where the 0-cells are
  categories, the 1-cells are functors, and the 2-cells are natural
  transformations.
\end{ex}

\begin{ex} There are many more examples of 2-categories.
  \begin{itemize}
    \item Any ordinary category is a 2-category with no non-identity 2-cells.
    \item Suppose that $\cat{C}$ is a category endowed with equivalence
      relations $\sim$ on each of its hom-sets, such as $\scat{PPT}$ with
      computational indistinguishability of outputs, such that if $f\sim g$ and
      $h\sim k$, and the composites exist, then $hf\sim kg$. Then $\cat{C}$
      forms a 2-category with a unique 2-cell between morphisms if and only if
      they $\sim$-relate. The horizontal composition is by the compatibility law
      and the vertical composition is by transitivity.
    \item Let $L$ be a functional programming language endowed with rewrite rules,
      such as $\alpha\beta\eta$ reductions in the lambda calculus, which are
      strongly normalizing\footnote{Logicians know this assumption as
      \emph{cut elimination}.}. Then the associated category $\cL$ is a 2-category
      with reductions as 2-cells~\cite{seely-1987b}. Such 2-categories have been
      previously used for operational semantics~\cite{baez-2019}.
  \end{itemize}
\end{ex}

The value of the generalization is in the last two examples: if our
computations are enriched with a notion of reduction, such as the existence of a
simulator which may produce the output of one morphism given the output of
another, then a 2-categorical approach takes advantage of that extra structure.

We have phrased the preceding sections in such a way as to make the
generalization as painless as possible. We let $\cat{E}$ be a monoidal
2-category (meaning one endowed with a 2-functor $\otimes$ satisfying certain
axioms), and modify \Cref{def:sec-condition} to ask for the
existence of a 2-cell\footnote{
  It may seem that the 2-cell should go the other direction, but we choose this
  direction as representing the ability to convert the output of the ideal
  adversary into the output of the real adversary. The definitions have
  equivalent expressive power by taking the dual of all the hom-categories.
} \[
  \begin{tikzcd}
    I\ar[r, "s"]\ar[d, "t"'] & GFx\ar[d, "Ga"]\\
    GFy\ar[r, "Ga'"']\ar[ur, shorten <>=10pt, Rightarrow] & G\cod a\punctuation{.}
  \end{tikzcd}
\]
In all the proofs, we paste such squares in the same orientation, so they go
through as is. The only issue is in the proof
of~\Cref{thm:closed-under-monoidal}, where we need that the tensor of two
2-cells still yields a 2-cell, but this is exactly what we mean by
2-functorality of $\otimes$.

Notice that, in this treatment, we only give $\cat{E}$ a 2-categorical
structure. It is possible to ask that the other categories and functors are
their 2-categorical equivalents, but this turns out to be a lot of extra work
for little-to-no extra expressive power, because we only end up using the 2-cell
structure on $\cat{E}$. A further generalization is possible to
\emph{bicategories}, in which case this extra structure ends up being necessary
to make the proofs work, but we have preferred the strict approach here for its
easy relation to the 1-categorical case.

\section{Conclusion}
\subsection{Evaluation}
\label{sec:evaluation}

We conclude this chapter by returning once more to the questions
from~\Cref{sec:composition-issues}. 

In~\Cref{q:composed-protocols}, we asked which kinds of protocols can be
composed. An major advantage of this kind of axiomatic algebraic approach is
that it can model a very general class of computations; we have, for instance,
discussed how probabilistic, quantum, and other effectful forms of computation
can all be represented as symmetric monoidal categories. The literature on
resource theories and on categorical representations of quantum protocols is in
particular quite extensive. However, while we suspect that virtually any
individual protocol can be represented via a suitable categorical construction,
there are open questions about whether the system as a whole can be cohesively
reasoned about; for instance, we saw in~\Cref{sec:interactive proof}
that it is difficult to represent polymorphic channels using the current tools
in the literature. Representing this kind of more complicated resources likely
requires increasingly sophisticated categorical constructions, removing some of
the comparative complexity advantages of the framework.

In~\Cref{q:composition-meaning}, we asked how we compose protocols. The
composition operation must satisfy the axioms of a symmetric monoidal category,
which have been widely used for modelling computational composition.
In~\Cref{q:allowed-composition}, we asked about the scope of this
composition definition; here we see some potential limitations. It is not clear
that the flexibility of the universal composition operation from UC can be
matched by monoidal composition. Issues like asynchronous network conditions,
adversarial schedulers, and dynamic subroutine calling are all covered by
of UC, but are typically handled by more sophisticated categorical machinery out
of the scope of the composition theorem.

In~\Cref{q:preserved-security}, we asked what notion of security the
composition theorem preserves. A major advantage of the categorical machinery is
that protocols ``come with'' types, so that we know the ideal functionality for
a protocol immediately by construction: it is the identity on the codomain. The
security definition says that the ideal adversary can be used to simulate the
real adversary, represented by the presence of a certain 2-cell. These 2-cells
potentially allow modelling situations like the environment from UC, where two
protocols are required to be indistinguishable throughout their execution; we
leave this for future work.

In~\Cref{q:adversarial-model}, we asked about the model of adversarial
behavior. The categorical framework is based around the notion of an
\emph{attack model}, which seems to be fairly general. However, the author is
uncertain about the correctness of~\Cref{item:am-con-fact} of the
definition. In particular, it may be that the two attacks need to commmunicate
with each other \emph{during the run of the protocol}, rather than combining
their states together at the end. This is not \emph{a priori} impossible with
this definition, but it seems to require a more sophisticated monoidal structure
along the lines of the product of 1-combs in
\eqref{eqn:product-1-comb}, rather than the concatenations we
have constructed here.

In~\Cref{q:compose-with}, we asked which protocols the composition
theorem lets us compose with. Crucially, the composition theorem requires that
\emph{all} protocols being composed are secure. This is a much weaker result
than that of UC, which guarantees that simulatability properties still hold even
if a secure sub-protocol is substituted for an ideal functionality in an
insecure larger protocol.

Finally, in~\Cref{q:count-compositions}, we asked how many times we can
compose. The composition theorem works only a constant number of times, and it
is unclear how to extend it to polynomially-many compositions; this is related
to the lack of a dynamic composition operation discussed earlier.

In the end, we think that the categorical model is more expressive
computationally, thanks to axiomatizing the properties a computational model
ought to have, but less expressive cryptographically, lacking the flexibility of
the universal composition operation and the breadth of the UC general
composition theorem. It is possible that this could be resolved with more
sophisticated underlying categorical structure, but this would remove the
comparative complexity advantage of the categorical model. However, the
categorical framework does admit elegant diagrammatic descriptions of protocols
and security proofs, which are likely very valuable for describing complex
cryptographic protocols.

% \begin{questions}
%   \item What kinds of protocols are being composed? Our security definitions do not
%     capture security of arbitrary interactive processes, so either we will
%     need a substantially more general definition or we will need to limit
%     our composition theorem to a specific class of
%     protocols.\label{q:composed-protocols}
%   \item What does it mean to compose these protocols? It is not immediately
%     clear how to compose arbitary interactive
%     algorithms.\label{q:composition-meaning}
%   \item What kind of composition is allowed? In particular, we can
%     consider \emph{sequential composition}, in which only one protocol is
%     ``running'' simultaneously, or \emph{parallel composition}, in which many
%     protocols may be running simultaneously. To formally state a parallel
%     composition theorem, we need to either specify a \emph{scheduling model} and
%     deal with low-level issues like atomicity, or find some way to abstract over
%     these details.\label{q:allowed-composition}
%   \item What kind of security is being preserved? Given a security definition
%     for the component protocols, we need some say to derive the security
%     definition for the composite protocol.\label{q:preserved-security}
%   \item What kinds of adversaries does the theorem handle? Composition theorems
%     may look very different for security against uniform and non-uniform
%     adversaries, for instance---these subtle issues can lead to very different
%     results.\label{q:adversarial-model}
%   \item What protocols are we allowed to compose with? We could be allowed to
%     compose with arbitrary protocols, which might not even be secure, or only
%     with other protocols we already know are secure.\label{q:compose-with}
%   \item How many times we can compose---for instance, must it be constant in the
%     security parameter?\label{q:count-compositions}
% \end{questions}

\subsection{Paths Not Taken}

% \section{Paths Not Taken}

% - along the lines of the pi calculus
% - functorality of attack models
% - internalization of owf/indistinguishability/etc
