A theory of cryptography should define at least four things: computation,
protocols, adversarial behavior, and security. A major advantage of categorical
models of cryptography is that they conveniently separate these issues. In
particular, we have some underlying category of computations, while we represent
categories of protocols with certain constructions on categories; as such, our
notions of interaction and security are completely independent of the underlying
model of computation.

[todo: lots more intro,
cite \cite{broadbent-karvonen-2022};
categorical crypto theories~\cite{hines-2020,pavlovic-2012,pavlovic-2014,stay-vicary-2013},
caterogies for specific crypto protocols~\cite{bkm-2019, bmr-2019}; categorical
qm
\cite{abramsky-coecke-2004,coecke-perdrix-2012,heunen-vicary-2014,coecke-kissinger-2017,chitambar-gour-2019}]

\section{Computation}
\label{sec:computation}

The categorical theory of computation is well-developed, going back at least to
the work of Jim Lambek and several contemporaries around the
1970s~\cite{lambeck-1974,lambeck-1980,lawvere-1969,seely-1984}. The essential
idea generalizes~\Cref{ex:functional programming}: objects are types
and morphisms are typed computations. The most disciplined approach is to
consider the categorical structure needed to model certain forms of computation, so that
for instance models of simply typed computation are \emph{bicartesian closed
categories}~\cite{lambeck-1974}, of linear computation are \emph{star-autonomous
categories}~\cite{seely-1989}, of quantum computation are \emph{compact-closed
categories}~\cite{abramsky-coecke-2004}, and of probabilistic computation are \emph{Markov
categories}~\cite{fritz-2020}. We will not review this approach here. Instead,
our focus will be on constructing specific categorical models of forms of
computations of interest to cryptographers.

\subsection{Deterministic Computation}

We would like a category of deterministic computations to have computable
functions as morphisms. However, the natural choice, taking sets as objects and
computable functions as morphisms, is actually not yet precise. The first issue
is that there are several distinct notions of computability on uncountable sets.
Each such notion forms a category, but formal definitions are outside our scope,
as cryptographers tend not to care about uncountable sets anyway\footnote{These
issues are studied in the field of \emph{computable analysis}; see for instance
the PhD thesis of Andre Bauer~\cite{bauer-2000}.}.

We can resolve this issue simply, by limiting ourselves to finite sets, in which
case every function is computable (simply by a lookup table):

\begin{dfn}[category of finite sets]
  The \emph{category of finite sets}, $\scat{FinSet}$, has finite sets as
  objects and functions as morphisms.
\end{dfn}

However, we often want to work with larger input spaces. The natural guess is to
take countable sets and computable functions. The issue here is one of encoding:
there is a canonical notion of computability on the set of finite binary
strings, but elements of arbitrary sets do not generally have canonical
encodings as binary strings. We could solve this issue by limiting
ourselves to working only with binary strings:
\begin{dfn}[category of computable binary functions]
  The \emph{category of computable binary functions} \scat{BinComp} has sets of binary strings
  $A\subseteq\bin^*$ as objects and computable functions as morphisms.
\end{dfn}

In practice, however, we like to think of computations as working over arbitrary
sets, which in particular may have more algebraic structure than sets of binary
strings. Our strategy, following~\cite{pavlovic-2014}, will be to work over sets
with fixed binary encodings.
\begin{dfn}[binary-encoded set]
  A \emph{binary-encoded set} is a set $X$ together with an injection
  $\denote{-}_X: X\to\bin^*$, called the \emph{encoding}.
\end{dfn}

Note that every binary-encoded set is finite or countable; as such, we avoid the
issues with uncountable sets mentioned above.

\begin{ntn}
  When the context is clear, we will generally drop the subscript of
  $\denote{-}$. We write $\denote{X}$ for the image of $\denote{-}_X$, i.e.
  $\denote{X} = \{s\in\bin^*: s = \denote{x}\text{ for some }x\in X\}$.
\end{ntn}

Given a function $f: X\to Y$ of binary-encoded sets, we can define a function
  \begin{align*}
    \denote{f} \colon \denote{X} &\to \denote{Y}\\
    \denote{x} &\mapsto \denote{f(x)}.
  \end{align*}
This is well-defined exactly because $\denote{-}_X$ is injective.

\begin{dfn}[category of computable functions]
  A function $f: X\to Y$ of binary-encoded sets is \emph{computable} if
  $\denote{f}$ is computable. The \emph{category of computable functions},
  \scat{Comp}, has binary-encoded sets as objects and computable functions as
  morphisms.
\end{dfn}

It needs to be shown that this is a category. First, the identities
$1_X$ are computable, as $\denote{1_X} = 1_{\denote{X}}$ is computable. Second,
the composite of computable functions is computable, as the composition of
computable binary functions is computable, and composition is preserved by
$\denote{-}$. As this argument indicates, there is a functor $\denote{-}:
\scat{Comp}\to\scat{BinComp}$; in fact this functor is an \emph{equivalence of
categories}. Nevertheless, the expanded perspective provided by $\scat{Comp}$ will be
convenient.

% [TODO: SMC structure]

Finally, we now define a symmetric monoidal structure on \scat{Comp}.
In particular, for two binary-encoded sets $X$ and $Y$, we would like to define
the product $X\otimes Y$ as the set $X\times Y$, but it is unclear what
$\denote{-}_{X\times Y}$ should be. We first fix an injective pairing map
$\<-,-\>: \bin^*\times\bin^*\to \bin$ which is efficiently computable\footnote{%
  One such map is computed as follows: given inputs $(m,n)$, start by encoding the
  length of $m$ in $2\log\log m$ bits: first write a bit of the length, then
  write a $1$ if the length continues and a $0$ if it doesn't. Now knowing the
  length of $m$, we can append the binary representation of $m$ and then $n$,
  which takes $O(\log m + \log n) = O(\log (mn))$ bits. Since $\log\log m =
  O(\log m)$, in total this algorithm takes $O(\log(mn))$ bits, and just writes
  across the tape, hence is computable in linear time.
}. We can then define $\denote{(x, y)} = \<\denote{x}, \denote{y}\>$; it is a
standard check that this defines a symmetric monoidal structure inherited from
$\scat{Set}$\footnote{
  Here is a more abstract way to see this. A suitable pairing function $\<-,-\>$
  turns $\{0,1\}$ into an internal commutative monoid in $\scat{Set}$. In other
  work, we show that the category of subobjects of any internal monoid is a
  monoidal category~\cite{shahar-zdancewic-2024}. The construction here is
  approximately an application of that general theorem.
}.

\subsection{Probabilistic Computation}

Again, there is some subtelty with probabilistic computation. Even in the case
of finite sets, not every stochastic function is computable by algorithms with
access to fair coin flips\footnote{
  We believe this is a slight conceptual problem with the strategy
  of~\cite[Section 6]{broadbent-karvonen-2022}, which models unbounded
  probabilistic computation in the category of finite sets and stochastic
  functions: this category is too powerful to reasonably model computation. This
  does not pose a technical issue in their specific example.
}. However, there is again a standard notion of computable stochastic function
of binary strings, so we can proceed much as before, defining:
\begin{dfn}[category of computable stochastic functions]
  The category \scat{BinCompStoch} has sets of binary strings as objects and
  computable stochastic functions as morphisms.

  A stochastic function $f:X\to Y $ between binary-encoded sets is
  \emph{computable} if $\denote{f}$ is computable. The \emph{category of
  computable stochastic functions} \scat{CompStoch} has binary-encoded sets as
  objects and computable stochastic functions as morphisms.
\end{dfn}

Again, it needs to be shown that this is a category. The identities are
computable (and stochastic, since every determinstic function is stochastic),
and composition commutes with $\denote{-}$, so the composite of computable
functions is computable. Furthermore, this category is symmetric monoidal, with
pairing of encodings as in \scat{Comp}.

We give a more abstract characterization of this category. There
are only countably many computable probability distributions on $\bin^*$, since
there are only countably many Turing machines. Fix a choice $\varphi$ of
bijection witnessing this fact. Note further that any probability distribution
$P$ on a binary-encoded set $X$ induces a probability distribution
$\denote{P}$ on $\bin^*$ by \[
  \Pr_{s\from \denote{P}}[s = s_0] = \Pr_{x\from P}[\denote{x} = s_0].
\]
There is now a monad $G_c: \scat{Comp}\to\scat{Comp}$, which we call the
\emph{computable Giry monad}, which takes any binary-encoded set $X$ to the set
of computable probability distributions on $X$, i.e. those such that
$\denote{P}$ is a computable probability distribution on $\bin^*$, with encoding
given by $\denote{P}_{G_c X} = \varphi(\denote{P}_X)$. Given $f: X\to Y$ and
$P\in G_c X$, we define the probability distribution $G_c f(P)$ on $Y$ by
\[
  \Pr_{y\from G_c f(P)}[y = y_0] = \Pr_{x\from P}[f(x) = y_0].
\]
The unit of $G_c$ is the function $X\to G_c X$ taking $x$ to the point
distribution at x. The multiplication is the function $\mu_X: G_c G_c X\to G_c X$
acting by summation: given a probability distribution $Q$ on $G_c X$, we define
a distribution $\mu_X (Q)$ on $X$ by \begin{equation*}\label{eqn:giry-sum}
  \Pr_{x\from \mu_X(Q)}[x = x_0] = \sum_{P_0\in G_c X} \Pr_{P\from Q}[P =
  P_0]\Pr_{x\from P}[x = x_0],
\end{equation*}which converges because $Q$ is a probability distribution. The proofs of
functorality and the monad laws as exactly as for the ordinary Giry
monad~\cite{giry-1982}, so we do not give them here. Now \scat{CompStoch} is in
fact (isomorphic to) the Kleisi category of $G_c$.

\subsection{Efficient and Effectful Computation}

Suppose that we are given some wide subcategory \scat{EffBin} of \scat{BinComp},
for instance that of poly-time computable maps. We can define the category
\scat{EffComp} of efficient computations as the wide subcategory of \scat{Comp}
consisting of morphisms $f$ whose encodings $\denote{f}$ are in $\scat{EffBin}$:
this is the \emph{preimage} of $\scat{EffBin}$ under the functor $\denote{-}$.

\begin{dfn}
  The category \scat{P} of poly-time computable maps is the wide subcategory
  of $\scat{Comp}$ consisting of those morphisms $f$ such that $\denote{f}$ is
  poly-time computable.
\end{dfn}

Similarly, suppose that we are give some wide subcategory of
\scat{BinCompStoch}, for instance that of poly-time computable stochastic maps.
We can similarly define the cateogry \scat{EffCompStoch}.

\begin{dfn}
  The category \scat{PPT} of poly-time computable stochastic maps is the wide is
  the wide subcategory of $\scat{CompStoch}$ consisting of those morphisms $f$
  such that $\denote{f}$ is probabilistic poly-time-computable.
\end{dfn}

In general, we can perform this construction for any complexity class $C$ which
is closed under composition.

Even more generally, let \scat{Bin} be the category of sets of binary strings and
(maybe uncomputable) set-functions between them. Let \scat{Enc} be the category
of binary-encoded sets and (maybe uncomputable) set-functions between them. Then
$\denote{-}$ is an equivalence of categories $\scat{Enc}\simeq \scat{Bin}$.

Now let \scat{EffBin} be any subcategory of \scat{Bin}. Then the \emph{category
of efficient computations} \scat{Eff} is the subcategory of \scat{Enc}
consisting of morphisms $f$ such that $\denote{f}$ is in \scat{EffBin}, i.e. the
preimage of \scat{EffBin} under $\denote{-}$. Finally, let $T$ be any monad on
\scat{Enc} which restricts to a monad on \scat{Eff}. Then the \emph{category of
efficient $T$-computations} is the Kleisi category of the restriction of $T$ to
\scat{Eff}. When $T$ is symmetric lax monoidal, this category is symmetric
monoidal.

\begin{ex}
  Each example in the previous three sections is a special case of this
  construction.
  \begin{itemize}
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the identity
      monad, we recover \scat{Comp}.
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the
      computable Giry monad, we recover \scat{CompStoch}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the identity monad, we recover \scat{P}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the \emph{poly-time Giry monad}, which sends a set $X$ to the set of
      poly-time computable probability distributions on $X$, we recover
      \scat{PPT}.
  \end{itemize}
\end{ex}

The point is that for any notion of efficient computation, and any notion of
computational effect (since effects are generally
monadic~\cite{wadler-thiemann-2003}), as long as the effect can be efficiently
represented, we can use the machinery of binary-encoded sets to define a
category of efficient computations carrying the given effect.

\subsection{Quantum Computation}

While an complete introduction to quantum computation is outside our scope, we
can sketch a categorical perspective; a standard introduction
is~\cite{nielsen-chuang-2010}. The \emph{category of quantum computations}
\scat{FinHilb} is the category of finite-dimensional Hilbert spaces over $\CC$ and
linear maps. Since nontrivial complex Hilbert spaces have
uncountably many vectors, we cannot directly model this category using the
machinery of the previous section, as there is no way to encode a complex
Hilbert space as an object of \scat{Bin}. If we had developed a more general
theory relying on a notion of computability over uncountable sets, then we could
now unify these perspectives; indeed, there have been several attempts to
monadically embed quantum computation into classical
calculi~\cite{altenrich-green-2009,abramsky-2017}. As we have chosen not to
develop such a general theory, in this section we will treat Hilbert spaces as
our primitive object.

A \emph{quantum computation} is a sequence of unitary transformations and
\emph{measurements}. There are several ways to provide categorical semantics to
quantum measurement; we follow~\cite{heunen-vicary-2014}.

Let $I$ be the one-dimensional Hilbert space. Note that the maps $I\to I$
correspond to choices of scalars $\lambda\in\CC$; as such, we say that a
\emph{scalar} is a map $I\to I$. Given a Hilbert space $V$, a \emph{state} is a
map $I\to V$, so that a state is determined by a choice of vector in $V$. If
$I\xto{a} V$ and $I\xto{b} V$ are states, then the projection of $a$ onto $b$
has amplitude \[
  I\xto{a}V\xto{b^\dag} I,
\]where $(-)^\dag$ denotes the adjoint; the corresponding element of $\CC$ is
the inner product $\<b,a\>$. Now the \emph{Born rule} of quantum mechanics
asserts that the probability of measuring the outcome $b$ from the state $a$ is
$|\<b, a\>|^2$. Categorically, if $I\xto{a,b} V$ are states, then the
\emph{probability of measuring $b$ from the state $a$} is the scalar \[
    I\xto{a}V\xto{b^\dag} I\xto{b} V\xto{a^\dag} I.
  \]

This is just a brief sketch of a very rich theory; see especially the work of
Bob Coecke such
as~\cite{abramsky-coecke-2004,coecke-perdrix-2012,coecke-kissinger-2017}, or the
book by Heunen and Vicary~\cite{heunen-vicary-2014}. The key point is that any
fully categorical treatment of cryptography should obtain quantum cryptography as
a special case.

\section{Protocols}

The categorical semantics of interactive computation---in particular, of
protocols---originates from the study of quantum cryptography, especially of
so-called \emph{resource theories}~\cite{coecke-2016}. The idea is to start with
some underlying SMC $\cat{C}$ of computations---fixed throughout this
section---and to construct a category of ``protocols built from computations in
$\cat{C}$.'' Exactly which such construction we choose depends on what we want
our protocols to look like.

In all these categories, the basic idea is that we will think of objects as
resources and morphisms as protocols, which convert some resources into others.
For instance, in the category $\ncomb{\cat{C}}$, morphisms will be ``protocols with
holes''---when instantiated with specific implementations of the resources they
are waiting for, they provide some new resource.

\subsection{Products}

While the product category is used implicitly in the definition of monoidal
categories, it is worth exploring it explicitly. Given two categories $\cat{C}$
and $\cat{D}$, the \emph{product category} $\cat{C}\times\cat{D}$ has:
\begin{itemize}
  \item as objects, pairs $(X,Y)$ of objects in $\cat{C}$ and $\cat{D}$;
  \item as morphisms $(X,Y)\to (X',Y')$, pairs $(f,g)$ of morphisms so that $f:
    X\to X'$ and $g: Y\to Y'$;
  \item composition and identities defined componentwise.
\end{itemize}

When $\cat{C}$ and $\cat{D}$ are categories of computations, we think of
$\cat{C}\times\cat{D}$ as a category of non-interfering parallel computations: a
computation in $\cat{C}\times\cat{D}$ is a computation in $\cat{C}$ and a
computation in $\cat{D}$, but they cannot interact.

\subsection{States}

In the symmetric monoidal category \scat{Set}, the morphisms $\{*\}\to X$
are in natural correspondence with the elements of $X$, by the bijection \[
  (*\mapsto x) \mapsto x.
\]
Similarly, in the symmetric monoidal category $\scat{Vect}_\kk$, the morphisms
$\kk\to V$ are in natural correspondence with vectors in $V$, since such maps
are determined by their action on the vector $1\in\kk$. This pattern holds more
generally, motivating the following definition.

\begin{dfn}[state]
  A \emph{state} or \emph{generalized element} of $\cat{C}$ is a morphism $I\to
  X$ for some object $X$.
\end{dfn}

As we know, it is easy to recognize states string-diagramatically: they are
downward-pointing triangles.

\begin{dfn}[resource theory of states]
  The \emph{resource theory of states} $\state{\cat{C}}$ is the category whose objects
  are states in $\cat{C}$ and whose morphisms $(I\xto{s}X)\to (I\xto{t}Y)$ are
  maps $X\xto{f} Y$ such that $fs = y$. Composition is as in $\cat{C}$.
\end{dfn}

When $\cat{C}$ is interpreted a category of types of resources and conversions
between them, we can think of $\state{\cat{C}}$ states as a category
of specific resources and of conversions between them, forgetting the type
information.

The resource theory of states has a canonical symmetric monoidal structure
induced by that of $\cat{C}$: the monoidal product of states $I\xto{s} X$ and
$I\xto{t} Y$ is just the state $I \to X\otimes Y$ given by\footnote{
  It may worry the careful reader that there are two seemingly distinct, albeit
  coherently naturally isomorphic, morphisms this diagram could represent: \[
    I\xto{\lambda_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y\quad\text{and}\quad 
    I\xto{\rho_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y.
  \]
  Fortunately, it is a non-obvious but standard result of Kelly that $\lambda_I
  = \rho_I$ in any SMC~\cite{kelly-1964}, so these morphisms agree.
}
\[
        \begin{pic}
          \node[state,scale=.75] (f) at (0,0) {$s$};
          \draw (f.north) to ++(0,.6) node[left] {$X$};
          \node[state,scale=.75] (g) at (.7,0) {$t$};
          \draw (g.north) to ++(0,.6) node[right] {$Y$};
        \end{pic},
\]while the monoidal product of morphisms is just their product in $X$. The unit is
the state $1_I$, while the associator and unitor are inherited from $\cat{C}$.

It will be useful to be a little more general. Let $F: \cat{D}\to\cat{C}$ be a
lax monoidal functor. Then an \emph{$F$-state} is a pair of $X\in\cat{D}$ and a
map $I\to FX$ in $\cat{C}$. The \emph{resource theory of $F$-states} $\state{F}$
is the category whose objects are $F$-states and whose morphisms $(I\xto{s}
FX)\to (I\xto{t} FY)$ are maps $X\xto{f}Y$ in $\cat{D}$ such that $(Ff)s =
t$. Note what then $\cat{C} = \cat{D}$ and $F = 1_\cat{C}$, we recover
  $\state{\cat{C}}$.

Since $F$ is lax monoidal, there is again general recipe for taking the monoidal
product in this category: given $I\xto{s} FX$ and $I\xto{t} FY$, the product of $s$ and
$t$ is the state \[
  \begin{pic}
    \draw[functor=cyan] (-.5, -.3) -- (0, -.3) -- (0, .2) -- (.5, .2) -- (.5,
      -.3) -- (1, -.3) -- (1, .7) -- (-.5, .7) -- cycle;
    \draw[rounded corners] (-.25, -.75) node[rounded corners=0, state, scale=.75] {$s$} -- (-.25, .45) --
      (.75, .45) -- ++(0, -1.2) node[rounded corners=0, state, scale=.75] {$t$} node[right, xshift=4mm, yshift=5mm] {\normalsize.};
    \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(X\otimes_\cat{D} Y)$};
  \end{pic}
\]

With a little more machinery: $\state{F}$ is the \emph{category of elements}
of the functor $\cat{D}\xto{F}\cat{C}\xto{C(I, -)}\scat{Set}$. In general, the
category of elements of a functor $F: \cat{C}\to\scat{Set}$ has as objects pairs
$(c, x)$ where $c\in Fx$, and as morphisms $(c, x)\to (c', x')$, maps $f: c\to
c'$ such that $Ff(x) = x'$. The category of elements of any lax monoidal functor
has a canonical monoidal structure on it induced by that of the codomain; this
is the monoidal structure with which we endow $\state{F}$. Observe the
similarity of the monoidal product in $\state{F}$ with the coherence map for the
functor $C(I, -)$ from \Cref{ex:monoidal-functors}. 

Following~\cite{broadbent-karvonen-2022}, we are especially interested in the category
$\state{\cat{C}^2\xto{\otimes}\cat{C}}$. Objects in this category are morphisms
$I\to X\otimes Y$ in $\cat{C}$, which we can think of as \emph{joint states}.
When $\cat{C} = \scat{Set}$, every joint state is \emph{independent}, in that it
splits into the product of two morphisms $I\to X$ and $I\to Y$, but in more
complicated categories like \scat{PPT} or \scat{Hilb} this may fail, representing a
kind of \emph{entanglement}. In this way, we can express the idea that two
parties $A$ and $B$ have a shared uniform random key by the map $I\to X\otimes
X$ in \scat{PPT} that sends $*$ to a uniform random choice of pairs $(k, k)$ for
$k\in X$. This map does not split into a pair of stochastic maps $I\to X$ and $I\to X$.

Morphisms $(I\xto{s} X\otimes Y)\to(I\xto{t}X'\otimes Y')$ in this category are
maps $(f,g)$ in $\cat{C}^2$ satisfying $(f\otimes g)s = t$. The maps $f$ and $g$
prescribe the computations undertaken by the respective parties in order to
transform the joint state $s$ into the joint state $t$. Note that there is a
kind of locality to morphisms in this category, since they are morphisms in the
product category; all of the interaction between the two parties is encoded in
the initial joint state. This separation is actually desirable: it will make it
easier for us to reason about the security of protocols. However, it means we
need a way to describe objects which represent more complicated forms of
interaction; we will do so in the next two sections.

It is worth remarking that more generally, we can model computations on
$n$-party states via the category
\[
  \state{\cat{C}^N\xto{\otimes^{N-1}}\cat{C}},
\] where the $i$th copy of $\cat{C}$ represents computations taken by the $i$th
party in the computation\footnote{There is a choice of associativity to be made, but any
choice yields a coherently isomorphic category, so we will not worry about it
here. A stanard assumption---justified by the \emph{strictification theorem for
monoidal categories}, which says that every monoidal category is equivalent to
strict one---is that the underlying cateogry $\cat{C}$ is strict.}.

Finally, there is a forgetful functor $\Pi: \state{\cat{D}\xto{F}\cat{C}}\to
\cat{D}$, which sends a state $I\xto FX$ to the object $X$ and a map to its
underlying map in $\cat{D}$. This functor is monoidal, since the monoidal
structure on $\state{\cat{D}\xto{F}\cat{C}}$ is induced by that of $\cat{D}$.
This functor composes with $F$ to get a forgetful functor with codomain
$\cat{C}$. We will use these functors to help organize information about the
relationship between these categories.

\subsection{Flat Process Conversions}

Recall that we can think of morphisms in $X\xto{f} Y$ in $\cat{C}$ as processes
converting $X$ to $Y$. Before arriving at the more general strategy
of~\cite{broadbent-karvonen-2022}, we first treat a simpler case. We will
construct a category $\onecomb{\cat{C}}$ of \emph{flat process conversions}, whose
objects are ``type signatures'' of processes and whose morphisms are recipes for
converting between processes with the appropriate signatures.

By type signature, we mean a pair of objects $(X, Y)$ in $\cat{C}$. The idea is
that the resource $(X, Y)$ should be ``inhabited'' by the morphisms $X\to Y$ in
$\cat{C}$. To make this work out, whatever notion of morphism in $\onecomb{\cat{C}}$
we end up with, it should be the case that $\onecomb{\cat{C}}(I, (X, Y)) \cong
\cat{C}(X, Y)$, i.e. that the morphisms $I\to (X, Y)$ in $\onecomb{\cat{C}}$ should
be in (natural) correspondence with the morphisms $X\to Y$ in $\cat{C}$.

To make this work out, a morphism $(X, Y)\to (X', Y')$ in $\onecomb{\cat{C}}$
consists of the following structure, called a \emph{1-comb}: \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[midway, left] {$X$};
    \draw (xi2.south west) -- (f.north) node[midway, left] {$Y$};
  \end{pic}
\]

Explicitly, a 1-comb consists of an object $Z$ and two morphisms $\xi_1: X'\to
X\otimes Z$ and $\xi_2: Y\otimes Z\to Y'$. The point is that, if we ``plug in''
a morphism $X\to Y$ for the hole, we obtain a morphism $X'\to Y'$; $Z$
represents some auxiliary data that isn't needed by the plugged-in morphism.
We often call $Z$ the \emph{residual} of the comb. It is a theorem
of~\cite{coecke-2016} that in an SMC, any morphism $X'\to Y'$ obtainable as a
string diagram which uses exactly one occurrence of a morphism $f: X\to Y$ may
be obtained as a 1-comb with $f$ filled in the hole.

Composition of 1-combs is defined by ``nesting'': given 1-combs
$(Z, \xi_1, \xi_2): (X, Y)\to (X', Y')$ and $(Z', \xi_1', \xi_2'): (X', Y')\to
(X'', Y'')$, we have a composite 1-comb $(X, Y)\to (X'', Y'')$ defined by:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{10mm}
    \node[morphism] (xi1') at (0,0) {$\xi_1'$};
    \node[morphism] (xi2') at (0,3.5) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[left] {$X''$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2'.north) to ++(0,.5) node[left] {$Y''$};
    \draw ([xshift=2.5pt]xi1'.north east) to ([xshift=2.5pt]xi2'.south east);
    \node[morphism,scale=.6] (xi1) at ($(xi1'.north west)!.2!(xi2'.south west)$)
    {\normalsize$\xi_1$};
    \node[morphism,scale=.6] (xi2) at ($(xi1'.north west)!.8!(xi2'.south west)$)
    {\normalsize$\xi_2$};
    \draw (xi1'.north west) -- (xi1.south);
    \draw (xi2'.south west) -- (xi2.north);
    \draw (xi1.north east) to (xi2.south east);

    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism,scale=.75] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
This does indeed form a 1-comb: explicitly, the composite 1-comb is the
tuple \[
  ((Z\otimes Z'), (\xi_1\otimes 1_{Z'})\circ \xi_1', (1_{Z}\otimes \xi_2')\circ \xi_2).
\]

Meanwhile, the monoidal product of 1-combs is as follows:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,4) {$\xi_2$};
    \node[dashedmorphism] (f) at ($(xi1.north)!.5!(xi2.south)$) {};

    \draw (xi1.south) to ++(0,-.5);
    \draw (xi2.north) to ++(0,.5);
    \draw (xi1.north west) -- (f.south west);
    \draw (xi2.south west) -- (f.north west);
    % \draw (0,0) to[out=80,in=-100] (.6,1);

    \node[morphism] (xi1') at (2,0) {$\xi_1'$};
    \node[morphism] (xi2') at (2,4) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[right, xshift=2em, yshift=1.5em] {\normalsize.};
    \draw (xi2'.north) to ++(0,.5);

    \draw
      let
        \p1=(xi1'.north west),
        \p2=(f.south),
        \p3=(f.north)
      in
      (xi1.north east) to[out=90,in=-90]
      (\x1,\y2) --
      (\x1,\y3) to[out=90,in=-90]
      (xi2.south east);
        
    % (xi1.north east) to[out=90,in=-90] ($(xi1'.north west)!.5!(xi2'.south west)$) to[out=90, in=-90] (xi2.south east);
    \draw (xi1'.north west) to[out=90,in=-90] (f.south east);
    \draw (f.north east) to[out=90,in=-90] (xi2'.south west);
    \draw (xi1'.north east) to (xi2'.south east);
  \end{pic}
\]Again, this forms a 1-comb.

We now return to the assertion from the beginning of the section: since a map $I\to
I$ carries no data, a 1-comb $I\to (X, Y)$ looks like \[
  \begin{pic}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,1) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X$} node[right, xshift=1em,
    yshift=1.5em]
    {\normalsize;};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y$};
    \draw (xi1.north) -- (xi2.south);
  \end{pic}
\]these are morphisms $X\to Y$, but not bijectively so. To resolve this, we take
equivalence classes of 1-combs, where two 1-combs are equivalent if they
yield the same morphism when any morphism $W\otimes X\to W\otimes Y$ is plugged
into their hole\footnote{This is an extensional notion of equality of
  combs. With significantly more machinery, it is also possible to define combs
intensionally, via so-called \emph{coend optics}~\cite{riley-2018,hefford-2023}: a 1-comb
$(X, Y)\to (X', Y')$ is precisely an element of the set $\int^{M\in \cat{C}}
\cat{C}(X', X\otimes M)\times\cat{C}(Y\otimes M, Y')$.}
Finally, we can formally define the category.

\begin{dfn}[category of flat process conversions]
  The \emph{category of flat process conversions} $\onecomb{\cat{C}}$ has as
  objects pairs $(X, Y)$ of objects in $\cat{C}$ and as morphisms equivalence
  classes of 1-combs in $\cat{C}$.
\end{dfn}

\begin{ex}
  The construction $\state{\onecomb{\cat{C}}}$ is the \emph{category of
  parallel-combinable processes} of~\cite{coecke-2016}.
\end{ex}

Now suppose that $F: \cat{C}\to \cat{D}$ is a strong monoidal functor; recall that this
means there is a natural isomorphism
$\phi_{X,Y}: FX\otimes_\cat{D} FY\to F(X\otimes_\cat{C} Y)$. Now there
is an induced functor $\onecomb{F}:\,
\onecomb{\cat{C}}\to\,\onecomb{\cat{D}}$ which acts on 1-combs by
\[
  \begin{pic}
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$X'$};
    \draw (xi2.north) to ++(0,.75) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}\quad\mapsto\quad\begin{pic}
    \draw[functor=cyan] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=cyan] (-.75,3) -- (.75,3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$FX'$} node[right, xshift=2em,
    yshift=1.5em] {\normalsize.};
    \draw (xi2.north) to ++(0,.75) node[left] {$FY'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
Symbolically, the action of $\onecomb{F}$ is \[
  (Z, \xi_1, \xi_2)\mapsto (FZ, \phi^{-1}_{X,Z}F\xi_1, (F\xi_2)\phi_{Y,Z}).
\] We have that $\onecomb{F}$ preserves
identities and composition because $F$ does. Furthermore, this construction
turns 1-comb into an endofunctor on the category of SMCs and strong monoidal
functors.

Cryptographically, we are primarily interested in the category \[
  \state{\onecomb{\cat{C}^2}\xto{\onecomb{\otimes}}\onecomb{\cat{C}}}.
\]

Objects in this category are maps $I\to (X\otimes Y, X'\otimes Y')$ in
$\onecomb{\cat{C}}$, hence maps $X\otimes Y\to X'\otimes Y'$ in $\cat{C}$.
Morphisms $(X\otimes Y\xto{f} X'\otimes Y')\to(A\otimes B\xto{g} A'\otimes B')$
are 1-combs $(X\otimes Y, X'\otimes Y')\to (A\otimes B, A'\otimes B')$, which,
when the hole is ``filled in'' with $f$, yield the morphism $g$. The idea is
that $f$ represents some shared cryptographic resources which the two parties
already have access to; the one-comb is a protocol the parties can use to
transform it into the resource $g$.

We emphasize that these $1$-combs ``live in $\cat{C}^2$: the morphisms $\xi_1$
and $\xi_2$ must be in the image of $\otimes$. As before, this means that they
satisfy a kind of disjointness: they are really two separate computations
running in parallel but independently. All of the interaction between the two
parties is encapsulated in the resource $f$, which is shared between them. As
such, it is a general rule that \emph{protocols cannot create extra
  interactivity on their own; they need input resources enabling interaction}.

Finally, we note that to model $n$-party computation we can work in the category \[
  \state{\onecomb{\cat{C}^n}\xto{\onecomb{\otimes^{n-1}}}\onecomb{\cat{C}}}.
\]

As an example, let $\cat{C} = \scat{Set}$, and let $f$ be the map $X\times *\to
*\times X$ given by $(x, *)\mapsto (*, x)$. Then $f$ is a \emph{one-shot channel}
from the first party to the second party. However, we have no way to represent
protocols which use multiple input resources: our combs only have one hole. We
fix this by working with \emph{n-combs}.

\subsection{Linear Process Conversions}
\label{sec:libear-process-conversions}

The extension from 1-combs to the n-combs of~\cite{broadbent-karvonen-2022} is
conceptually straightforward, but technically somewhat messy. An n-comb is just
a stack of 1-combs; we can combine the top of one comb with the bottom of the
next, so we may as well write\footnote{
  As with 1-combs, there is a more abstract definition of n-combs using coend
  optics: an n-comb $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')$ is an
  element of the set \[
    \int^{M_1,\dots,M_n\in\cat{C}}\cat{C}(X', X_1\otimes
    M_1)\times\prod_{i=1}^{n-1} \cat{C}(Y_i\otimes M_i, X_{i+1}\otimes M_{i+1})
    \times \cat{C}(Y_n\otimes M_n, Y').
  \]
}
\[
  \begin{pic}
    \comb[0,0][0,2][$\xi_1'$][$\xi_2'$]
    \comb[0,3][0,5][$\xi_3'$][$\xi_4'$]

    \node at (0,6.5) {\normalsize$\vdots$};

    \comb[0,8][0,10][$\xi_{2n-1}'$][$\xi_{2n}'$]
  \end{pic}\quad\quad\quad\text{as}\quad\quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xi3) at (0,4) {$\xi_3$};
    \node[morphism] (xin) at (0,7) {$\xi_n$};
    \node[morphism] (xin1) at (0,9) {$\xi_{n+1}$};

    \node at (0,5.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi3.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi3.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xi2.north east) to ([xshift=2.5pt]xi3.south east);
    \node[dashedmorphism] (g) at ($(xi2.north west)!.5!(xi3.south west)$)
    {\phantom{$f$}};
    \draw (xi2.north west) -- (g.south);
    \draw (xi3.south west) -- (g.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]
Again by a theorem of~\cite{coecke-2016}, any circuit which is obtainable as a
string diagram using exactly one occurance of each of a list of $n$ morphisms
can also be obtained as the result of plugging those morphisms in to an
appropriate n-comb.

Generalizing the case of 1-combs, the objects in the category of n-combs should
be finite lists of pairs of objects: a resource of type $[(X_1, Y_1), \ldots,
(X_n, Y_n)]$ is a list of maps $X_i\to Y_i$ in $\cat{C}$. It is worth mentioning that We can proceed directly to defining the
category, but we find it easier to first define a symmetric multicategory of
n-combs. The advantage is that this requires us only to define morphisms with
one pair in the codomain---what~\cite{broadbent-karvonen-2022} call the ``basic
morphisms''---and then construct a full SMC via a general procedure.

Objects in this multicategory are pairs of objects in $\cat{C}$. Morphisms
$[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')$ consist of a permutation $\sigma$
and an n-comb
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xin) at (0,5) {$\xi_n$};
    \node[morphism] (xin1) at (0,7) {$\xi_{n+1}$};

    \node at (0,3.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[left, midway] {$X_{\sigma(1)}$};
    \draw (xi2.south west) -- (f.north) node[left, midway] {$Y_{\sigma(1)}$};

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south) node[left, midway] {$X_{\sigma(n)}$};
    \draw (xin1.south west) -- (h.north) node[left, midway] {$Y_{\sigma(n)}$};

    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$};
    \draw (xin1.north) to ++(0,.5) node[left] {$Y'$};
    \node at (1, .5) {\normalsize.};
  \end{pic}
\] The idea is that $\sigma$ encodes the order in which the protocol uses the
input resources; we do not have to use them in the order specified by the domain
list. Composition of general combs is as with 1-combs: given an n-comb and n
$m_k$-combs such that the types line up, we nest each of the combs into the
outer n-comb. This indeed gives us a symmetric multicategory.

We can now use the following general construction to obtain the category of
n-combs:

\begin{dfn}\label{def:associated-monoidal-category}
  Let $\cat{C}$ be a (symmetric) multicategory. Then there is an associated
  (symmetric) monoidal category $\cat{C}^\otimes$ defined as follows:
  \begin{itemize}
    \item an object in $\cat{C}^\otimes$ is a finite list of objects in
      $\cat{C}$, written $x_1\otimes\dots\otimes x_n$;
    \item a morphism $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes \dots\otimes
      y_m$ consists of a \emph{partition function}
      $\alpha_f: \{1,\dots,n\}\to\{1,\dots,m\}$ and for each $i\in\{1,\dots,m\}$, a morphism \[
        x_{k_1}, \dots, x_{k_l}\xto{f_i} y_i,
      \] called the \emph{$y_i$ component}, where the $k_j$s range over
      $\alpha_f^{-1}(i)$;
    \item the composite morphism $x_1\otimes\dots\otimes
      x_n\xto{f}y_1\otimes\dots\otimes y_m\xto{g}z_1\otimes\dots\otimes z_p$ is
      given by the partition function $\alpha_{gf} = \alpha_g\alpha_f$ and for
      each $z_i$, the component \[
        g_i\circ(f_{\sigma_i(1)},\dots,f_{\sigma_i(k)})
      \]in $\cat{C}$, where $\sigma_i$ is from $g$;
    \item the identity on $x_1\otimes\dots\otimes x_n$ is given by the identity
      partition and the identities $1_{x_i}$ from $\cat{C}$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n$ and
      $y_1\otimes\dots\otimes y_m$ is given by the concatenation
      $x_1\otimes\dots\otimes x_n\otimes y_1\otimes \dots\otimes y_m$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes\dots\otimes y_m$
      and $z_1\otimes\dots\otimes z_p\xto{g} w_1\otimes\dots\otimes w_q$ is given
      by lifting the partitions to the disjoint union, so the $y_i$
      component is just $f_i$ while the $w_i$ component is just $g_i$.
  \end{itemize}
\end{dfn}

The idea is that each object in $x_1\otimes\dots\otimes x_n\in\cat{C}^\otimes$
represents the presence of the ``resources'' represented by the objects
$x_1,\dots,x_n\in\cat{C}$. A morphism must consume precisely one ``copy'' of
each resource in that list and produce one copy of each resource in its
codomain. The partition $\alpha$ is an allocation of input resources to output
resources: $\alpha^{-1}(i)$ is exactly the input resources used to produce the
resource $y_i$.

We can be explicit about what this construction looks like in the case of
n-combs.

\begin{dfn}
  Objects in the category $\ncomb{\cat{C}}$ are finite lists of pairs of objects
  in $\cat{C}$. A morphism $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to [(X'_1, Y'_1),
  \dots, (X'_m, Y'_m)]$ is a list of $m$ combs, one for each pair of objects in
  the codomain, and each of which has holes typed by the pairs in the domain,
  such that each pair in the domain is used in \emph{exactly one} n-comb and
  \emph{exactly once} in that n-comb. Composition is by nesting, while the
  monoidal product is by concatenation of lists.
\end{dfn}

\begin{ex}
  The category $\state{\ncomb{\cat{C}}}$ is the \emph{category of universally
  combinable processes} of~\cite{coecke-2016}.
\end{ex}

Furthermore, n-comb is functorial in the same way as 1-comb. Given a strong
monoidal functor $F: \cat{C}\to\cat{D}$, we can define a functor $\ncomb{F}:
\ncomb{\cat{C}}\to\ncomb{\cat{D}}$ by acting on each n-comb over $\cat{C}$ by \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
  \end{pic}
  \quad\quad
  \mapsto
  \quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \draw[functor=cyan] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=cyan] (-.75,3.3) -- (-.15, 3.3) -- (-.15, 2.9) -- (.15, 2.9) --
    (.15, 3.3) -- (.75,3.3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;

    \draw[functor=cyan] (-.75,8.5) -- (.75,8.5) -- (.75, 7.2) -- (.15, 7.2) --
    (.15, 7.6) -- (-.15, 7.6) -- (-.15, 7.2) -- (-.75, 7.2) -- cycle;
    \draw[functor=cyan] (-.75,4.7) -- (-.15, 4.7) -- (-.15, 5.1) -- (.15, 5.1) --
    (.15, 4.7) -- (.75,4.7) -- (.75, 6.3) -- (.15, 6.3) --
    (.15, 5.9) -- (-.15, 5.9) -- (-.15, 6.3) -- (-.75, 6.3) -- cycle;

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]

Cryptographically, still following~\cite{broadbent-karvonen-2022} we are interested in
the category \[
  \prot{N}{\cat{C}} := \state{\ncomb{\cat{C}^N}\xto{\ncomb{\otimes^{N-1}}}\ncomb{\cat{C}}},
\]
which is a category of $N$-party protocols with computations from $\cat{C}$.
Objects in this category are finite lists of maps \[
  X^i_1\otimes\dots\otimes X^i_N\xto{f_i} Y^i_1\otimes\dots\otimes Y^i_N
\] in $\cat{C}$, which represent shared access to the resources $\{f_i\}$,
themselves processes for transforming joint states in $\cat{C}$. Morphisms are
lists of $M$ combs, so that each map $f_i$ in the domain list is allocated to
exactly one comb, and so that plugging in all the $f_i$s into the appropriate
combs yields exactly the list of maps in the codomain.

Here is a convenient way to think about the situation, to our knowledge original
to us. A map in $\ncomb{\cat{C}}$ is a ``schema for a protocol''. We can look
its fiber\footnote{
  The \emph{fiber} $F^{-1}f$ of a functor $F: \cat{C}\to\cat{D}$ over a morphism
  $f\in\cat{D}$ is collection of morphisms $g\in\cat{C}$ such that $Fg = f$.
} under the functor \[
  \ncomb{\otimes^{N-1}}\Pi: \prot{N}{\cat{C}}\to\ncomb{\cat{C}}
\] to determine what the schema does when instantiated with a specific kind of
resource. In some cases, as in the next section, we only care about the maps in
$\prot{n}{\cat{C}}$ with some specific domain and codomain, and are interested
in verifying that there is an element in the fiber with that correct type: this
is a \emph{correctness property} of a protocol. However, there are more
complicated situations where we want to verify that the same protocol behaves in
one way given an input of some type, and in another way given another input; in
this case the expanded perspective provided by the forgetful functor can be
useful for organizing the data.

\subsection{The One-Time Pad}
\label{sec:otp}

As a first example, we work out in full detail the categorical description of
the one-time pad due to~\cite{broadbent-karvonen-2022}. For now, let $\cat{C} =
\scat{CompStoch}$ and $N = 3$; we label the three parties $A$, $B$, and $E$. We
pick a message space $M\in\cat{C}$; we could just say $M = \bin^*$, but instead
let us figure out what ``local'' structure, by which we mean structure in
$\cat{C}$ which is hence usable by each of the parties on their own, $M$ needs
to have.

First, we should be able to copy and delete messages from $M$; they're just
classical information. We represent this with a pair of maps \[
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$M$};
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$M$};
    \draw (mu) to ++(0, -.7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \hspace{1em}
  \quad\quad
  \begin{pic}
    \node[dot, fill=white] (eta) at (0,0) {};
    \draw (eta) to ++(0, -.7) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]called the \emph{copy} and \emph{deletion} maps. Copying is associative
(category theorists call this \emph{coassociativity}, because it is opposite to the
direction of normal associativity):
\begin{equation}\label{eqn:coassociative}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to[out=0, in=-90] ++(.7, .7) to ++(0, .5) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[left] {};
    \draw (a) to ++(0, -.7) node[left] {};
  \end{pic}
  =
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to[out=180, in=-90] ++(-.7, .7) to ++(0, .5) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[right] {};
    \draw (a) to ++(0,-.7) node[left] {};
  \end{pic}
\end{equation}and commutative (\emph{cocommutativity}): 
\begin{equation}\label{eqn:cocommutativity}
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
    \draw (mu) to ++(0, -.7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) to[out=90, in=-90] ++(1, 1);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) to[out=90, in=-90] ++(-1, 1);
    \draw (mu) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize;};
  \end{pic}
\end{equation}
deletion is the inverse of copying (\emph{counitality})\footnote{We do not
need to axiomatize both sides of this equality when we have commutativity.}:
\begin{equation}\label{eqn:counital}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to ++(0, -.7) node[left] {};
    \draw (a) to[out=180, in=-90] ++(-.5, .5) to ++(0, .4) node[left] {};
  \end{pic}
  \hspace{.4em}
  =
  \begin{pic}
    \draw(0, 0) node[left] {} to (0, 1.5) node[left]{};
  \end{pic}
  \hspace{.6em}
  =
  \hspace{.5em}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (a) to[out=0, in=-90] ++(.5, .5) to ++(0, .4);
  \end{pic}
\end{equation}
These three equations give $M$ the structure of a \emph{cocommutative
comonoid} in $\cat{C}$.

We often want to work over categories in which \emph{every} object has such copy
and delete maps. We say that an SMC $\cat{C}$ \emph{supplies cocommutative
comonoids} if every object in $\cat{C}$ is a cocommutative comonoid in such a
way that the comonoidal structure on any object $X\otimes Y$ is induced from
that on $X$ and $Y$ by the tensor. We are now very close to the definition of a
\emph{Markov category}, which is a natural categorical axiomatization of
stochastic computation~\cite{fritz-2020}.

Recall from~\Cref{ex:otp} the one-time pad
works over an arbitrary group $G$. As such, we separately need that $M$ looks
like a group in $\cat{C}$: it should have multiplication, unit, and inverse
maps \[
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[left] {$M$};
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right] {$M$}
      node[right, xshift=4mm, yshift=1mm] {\normalsize,};
    \draw (mu) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
    \draw (eta) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {};
    \draw (eta) to ++(0, .5) node[left] {$M$};
    \draw (eta) to ++(0, -.5) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]which are associative and unital in the sense of~\Cref{def:monoid object}
and satisfy the additional \emph{inverse law}:
\begin{equation}\label{eqn:inverse}
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=0, in=-90] (inv) to[out=90, in=0] (mult);
    \draw (copy) to[out=180, in=-90] (-.5,.5) to[out=90, in=180] (mult);
    \draw (copy) to ++(0, -.75);
    \draw (mult) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (del) at (0,0) {};
    \node[dot, fill=black] (id) at (0,1) {};
    \draw (del) to ++(0, -.75);
    \draw (id) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (-.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=180, in=-90] (inv) to[out=90, in=180] (mult);
    \draw (copy) to[out=0, in=-90] (.5,.5) to[out=90, in=0] (mult);
    \draw (copy) to ++(0, -.75) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (mult) to ++(0, .75);
  \end{pic}
\end{equation}
Notice that this law relies on the existence of the copy and delete maps;
indeed, it is not possible to define a group without some way to talk about
copying.

We need one more compatibility law, which says essentially that multiplication
is deterministic: performing the same multiplication twice is the same as
performing it once and then copying the result:
\begin{equation}\label{eqn:mult-deterministic}
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.5, 0) {};
    \node[dot, fill=white] (copy2) at (.5, 0) {};
    \node[dot, fill=black] (mult1) at (-.5, .8) {};
    \node[dot, fill=black] (mult2) at (.5, .8) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-10] (mult2);
    \draw (copy1) to[out=10, in=190] (mult2);
    \draw (copy2) to[out=170, in=-10] (mult1);
    \draw (copy1) to ++(0, -.7);
    \draw (copy2) to ++(0, -.7);
    \draw (mult1) to ++(0, .7);
    \draw (mult2) to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \node[dot, fill=white] (copy) at (0,.8) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2);
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right, xshift=4mm, yshift=1mm] {\normalsize.};
    \draw (mu) to ++(0, .7);
    \draw (mu) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
  \end{pic}
\end{equation}

Finally, for the one-time pad we need some way to model randomness; in
\scat{CompStoch} this is the map $I\xto{\$} M$ which draws a uniform random
value from $M$. Categorically, rather than the specific construction of the map,
we care about its properties\footnote{
  The laws \eqref{eqn:coassociative} to
  \eqref{eqn:mult-deterministic} give $M$ the structure of a
  \emph{Hopf object} in $\cat{C}$. It turns out that these objects are
  well-known, and in particular have important applications in quantum
  computation~\cite{de-felice-2017}; for instance, a Hopf object in
  $\scat{Vect}_\kk$ is just an ordinary Hopf algebra. This is a major advantage
  of the categorical machinery: we discover unexpected connections between
  different kinds of computation and mathematics.

  Somewhat surprisingly, elements of Hopf algebras satisfying
  \eqref{eqn:random-invariance} and \eqref{eqn:random-non-side-effecting} 
  have been well studied under the name
  \emph{integrals}~\cite{sweedler-1969,lomp-2004,sullivan-1971}. As such, the
  one-time pad can be instantiated over any Hopf algebra $H$ with an integral,
  by replacing the uniform random choice of key with the map $\kk\to H$ which
  sends $1$ to the chosen integral. This translation is purely syntactic;
  everything we will say about the one-time pad applies to this construction as
  well. We can now start doing cryptography inside a Hopf algebra, or using the
theory of Hopf algebras to say things about cryptography.}: it is invariant
under
multiplication, in the sense
that
\begin{equation}\label{eqn:random-invariance}
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}\quad=\quad
  \begin{pic}
    \draw (0,0) node[state, scale=.75] {\normalsize\$} to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) node[state, scale=.75] {\normalsize\$} node[right, xshift=3mm, yshift=1mm] {\normalsize,};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}
\end{equation}
and it is independent, in the sense that \begin{equation}\label{eqn:random-non-side-effecting}
  \begin{pic}
    \draw (0, 0) node[state, scale=.75] (rand) {\normalsize\$} to ++(0, .7) node[dot, fill=white] {};
  \end{pic}\quad\text{equals the empty diagram.}
\end{equation} We interpret \eqref{eqn:random-invariance} as
saying that the product of any group element with a uniform random value is
uniform random, while \eqref{eqn:random-non-side-effecting} says that
creating and then deleting a uniform random value does nothing.

All this is just the local structure. To implement the one-time pad, we need
two shared resources. First, $A$ and $B$ should have a shared random key drawn
from $M$. In $\scat{CompStoch}$, this is the map $I\to M\otimes M\otimes I$
which draws uniformly at random from the set $\{(k, k, *): k\in M\}$.
Diagramatically, we can build this map as \[
  \begin{pic}
    \node[state, scale=.75] (rand) at (0, 0) {\normalsize\$} node[right, xshift=8mm, yshift=1mm] {\normalsize,};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]where we now label the wires with the party in possession of the data, so that
for instance a wire labeled $A$ has type $M\otimes I\otimes I$, while
the two parallel wires labeled $A$ and $B$ have type $M\otimes
M\otimes I$. This is a map in $\cat{C}$ which cannot be written in $\cat{C}^3$,
because it does not factor into a product of three separate maps in $\cat{C}$.

We also need a way for $A$ to send the encoded message to $B$ and $E$. In
\scat{CompStoch}, this is the map $M\otimes I\otimes I\to I\otimes M\otimes M$
given by $(c, *, *)\mapsto (*, c, c)$. Again, this can be represented using the
structure defined above, as the map \[
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$} node[right, xshift=5mm,
    yshift=1mm] {\normalsize.};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]It is a good exercise in string diagram comprehension to spell out this map
symbolically. Assuming we chose to left-associate the functor $\otimes^2$ in the
definition of $\prot{3}{\cat{C}}$, one way to write it is as the map \[
  (M\otimes I)\otimes I\xto{\rho_{M\otimes I}} M\otimes I
  \xto{\gamma_{M,I}} I\otimes M\xto{1_I\otimes
  \text{copy}} I\otimes (M\otimes M)\xto{\alpha^{-1}_{I,M,M}} (I\otimes
    M)\otimes M.
\]The magic of the coherence theorem is that, once we agree on a choice of
associativity, any way of writing this map is the same, and so we can work with
the far simpler diagrammatic notation.

From all this, we learn that the domain of the one-time pad should be the object
\begin{equation}\label{eqn:otp-domain}
  \begin{pic}
    \node[state] (rand) at (0, 0) {\normalsize\$};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
  \otimes
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\end{equation} of $\prot{3}{\cat{C}}$. The goal of the one-time pad is to produce a channel
from $A$ to $B$, so the codomain should be the object \begin{equation}\label{eqn:otp-codomain}
  \begin{pic}
    \draw (0, 0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm] {\normalsize.} to ++(0, 1) node[left] {$B$};
  \end{pic}
\end{equation}
The reader may now object that the one-time pad does not give the eavesdropped
no information, as they learn that a message was sent. However, we are not yet
attempting to deal with adversarial behavior, so any protocol can simply have
Eve forget that information. We will discuss this issue at length in
\Cref{sec:security}.

For a second, let us not worry about preserving states, and just think in the
category $\ncomb{\cat{C}}$. Recall that the objects in this category are finite
lists of pairs of objects in $\cat{C}$. The domain of the one-time pad should be \[
  [(I\otimes I\otimes I, M\otimes M\otimes I), (M\otimes I\otimes I,
  I\otimes M\otimes M)],
\] while the codomain should be \[
  [(M\otimes I\otimes I, I\otimes M\otimes I)].
\]
A morphism between these should be a 2-comb which takes morphisms of the domain
types and produces a morphism of the codomain type. In other words, given two
``black box'' maps \[
  \begin{pic}
    \node[dashedstate] (rand) at (0, 0) {};
    \draw (rand.north west) to ++(0, .5) node[left] {$A$};
    \draw (rand.north east) to ++(0, .5) node[right] {$B$};
  \end{pic}\quad\text{and}\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .5) node[left] {$E$};
    \draw (send.north east) to ++(0, .5) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
  \end{pic},
\]the 2-comb must produce a map \[
  \begin{pic}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.south) to ++(0, -.5) node[left] {$A$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.};
    \draw (send.north) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]
The easiest such 2-comb to write, \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (send.north east) to ++(0, .7) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to ++(0, .3) node[dot, fill=white] {};
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} to ++(0, .3) node[dot, fill=white] {};
  \end{pic},
\]
represents simply sending the message unencrypted, without use of the key. Note
that the theory does require us to explicitly forget the key, as n-combs must consume
all their input resources. We will alleviate this requirement soon.

Now the schema for the one-time pad is the 2-comb \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    % \node[morphism] (send) at (0, 0) {};
    % \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    % \draw (send.north east) to ++(0, .7) node[right] {$B$};
    % \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \node[dot, fill=black] (mult) at (.5, 1) {};
    \node[dashedmorphism] (copy) at (.5, 2) {};
    \draw (copy.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (mult) to (copy.south) node[yshift=-3mm, left] {$A$};
    \draw (-.3, -1) node[left] {$A$} to (-.3, .2) to [out=90, in=180] (mult);
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to[out=90, in=0] (mult);
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} node[right, yshift=-3mm,
    xshift=5mm] {\normalsize.} to ++(0, .7) node[dot,
    fill=black] {} to ++(0, .4) node[right] {$B$} to ++(0, 1.1) to[in=0,out=90] ++(-.5, .5) node[dot, fill=black] (f) {};
    \draw (copy.north east) to ++(0, .2) node[right] {$B$} to[out=90,in=180] (f);
    \draw (f) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]

This is a morphism in $\ncomb{\cat{C}}$. To check that this protocol is correct,
we need to check that it sends the state \eqref{eqn:otp-domain} to
the state \eqref{eqn:otp-codomain}, i.e. that it is a morphism with
the right type in $\prot{3}{\cat{C}}$. Substituting the actual resources in for
their generic counterparts, we get the protocol \[
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist) node[left, xshift=-3mm] {$A$};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=3mm] {$B$} node[right, xshift=8mm,
    yshift=-2mm] {\normalsize.} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) node[above right, xshift=-.5mm] {$B$} to[out=90, in=0] (bm);
    \draw (copy) node[above right, yshift=1mm] {$B$} to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) node[left] {$E$} to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic}
\]
Now we compute, using counitality, associativity, the inverse law, unitality,
and the independence of random choice:
\begin{align*}
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist) node[left, xshift=-3mm] {$A$};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=3mm] {$B$} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) node[above right, xshift=-.5mm] {$B$} to[out=90, in=0] (bm);
    \draw (copy) node[above right, yshift=1mm] {$B$} to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) node[left] {$E$} to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6) node[left] {$B$};
    \end{pic}\quad&
  \xequals{\eqref{eqn:counital}}\quad\begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1) node[left] {$A$};
    \draw (am) to ++(0, .3) to[out=90, in=180] (bm);
    \draw (am) to[out=0, in=180] (keydist);
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) to[out=90, in=0] (bm);
    \draw (bm) to ++(0, .6) node[left] {$B$};
  \end{pic}\,\\
  &\xequals{\eqref{eqn:monoid associative}}\quad\begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) to[out=0, in=-90] ++(.5, .5)
      node[dot, fill=black] {} to[out=90, in=0] ++(-.5, .5) node[dot, fill=black] (bm) {};
      \draw (keydist) to[out=180, in=-90] ++(-.5, .5) to[out=90, in=180] (bm);
      \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
      \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
      \draw (am) to ++(0, .5) node[left] {$B$};
    \end{pic}\\
  &\xequals{\eqref{eqn:inverse}}\quad
    \begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
      \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
      \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
      \draw (am) to ++(0, .5) node[left] {$B$};
    \end{pic}\,\\
  &\xequals{\eqref{eqn:monoid unital}}\quad
  \begin{pic}
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw ($(keydist) + (-.5, -1.2)$) node[left] {$A$} to ++(0, 1.5) node[left] {$B$};
    % \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
    %   \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
    %   \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
    %   \draw (am) to ++(0, .5) node[left] {$B$};
  \end{pic}\,\\
  &\xequals{\eqref{eqn:random-non-side-effecting}}\quad
  \begin{pic}
    \draw (0,0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm]
    {\normalsize.} to ++(0, 1.5) node[left] {$B$};
    % \node[dot, fill=black] (bm) at ($(keydist) + (0, 1)$) {};
    %   \draw (bm) to[out=90, in=0] ++(-.6, .8) node[dot, fill=black] (am) {};
    %   \draw (am) to[out=180, in=90] ++(-.6, -.8) to ++(0, -2.2) node[left] {$A$};
    %   \draw (am) to ++(0, .5) node[left] {$B$};
  \end{pic}
\end{align*}
This computation proves that the one-time pad is a morphism
$\eqref{eqn:otp-domain}\to\eqref{eqn:otp-codomain}$
in $\prot{3}{\cat{C}}$; this is the categorical statement of the correctness of
the one-time pad.

% Notice that this computation is very similar to the proof of the correctness of
% the one-time pad (\Cref{ex:otp}). 

We reiterate that the entire preceeding discussion relies only on the existence
of an object satisfying the axioms \eqref{eqn:coassociative} to
\eqref{eqn:random-non-side-effecting}. The one-time pad can be
correctly implemented in any category over any object with this structure.

Of course, this entire discussion assumes that Eve does as the protocol
instructs and simply deletes the message they read. If they do not, we need
another layer of analysis, dealing with adversarial behavior. That will be the
subject of \Cref{sec:security}.

\subsection{Extensions to the Framework}

\subsubsection{Reusable Resources}
In the title of
\Cref{sec:libear-process-conversions},
we called $\ncomb{\cat{C}}$ a category of \emph{linear} process conversions.
This is because each input resource is used exactly once in the list of n-combs.
While it is often valuable to have this restriction enforced by the syntax,
there are cases where we want to model reusable resources. As suggested
by~\cite{broadbent-karvonen-2022}, we can straightforwardly modify the
construction to account for this by making two changes.

First, recall that in the definition of an n-comb at the beginning of
\Cref{sec:libear-process-conversions},
the permutation $\sigma$ determines the order in which the input resources are
used. For an $n$-comb with $m$ input resources, we can replace this permutation
with a function $n\to m$ which assigns to each comb the type of the resource
which will fill it. In this way, we can use each resource as many times
as we want, including not at all.

However, this is not enough, as in the category $\ncomb{\cat{C}}$ morphisms are
lists of n-combs, and the current definition allocates each input resource to
exactly one of these combs. One advantage of our choice to use the intermediate
step of a multicategory is that we can make the required change directly to the
construction in \Cref{def:associated-monoidal-category}. When
defining morphisms in this category, we used a partition function $\alpha$ to
assign input resources to outputs resources. By allowing this function to be a
relation, we can allow each input resource to be assigned to multiple output
resources. When $\cat{C}$ is a symmetric multicategory, we call this category
$\cat{C}^{\otimes!}$. Combining these two modifications yields the category
$\ncombb{\cat{C}}$ of~\cite{broadbent-karvonen-2022}.

We suspect that their choice of notation $!$
is not accidental: in many ways, this category behaves like the exponential
modality $!$ of linear logic. In linear logic~\cite{girard-1987}, hypotheses
must be used once and only once. The $!$ modality allows a hypothesis to be used
any number of times; this allows controlled intuitionistic reasoning with linear
frameworks, hence allowing linear logics to be both as expressive as intuitionistic
logic, and to have fine-grained control over resource usage. In the case of
n-combs, however, we currently have two separate categories $\ncomb{\cat{C}}$
and $\ncombb{\cat{C}}$, so if we want to model cryptosystems that have some
multi-use resources and some single-use resources, we need some way to relate
them. We give a solution in \Cref{def:ncomba}, but first we
digress to discuss the categorical semantics of linear logic, which motivate our
construction. This explanation uses some categorical terminology we have not
introduced, but the reader may safely skip directly to the definition.

Any symmetric monoidal category $\cat{L}$ forms a model of the
multiplicative-intuitoinistic fragment of linear logic~\cite{mellies-2009}. In such
settings, $!$ can be modeled by a lax monoidal comonad $\denote{!}$ together
with natural transformations $\denote{!}x\to I$, and
$\denote{!}x\to\denote{!}x\otimes\denote{!}x$. This data is subject to a
coherence axiom given in \cite[Equation 72]{mellies-2009}.

The modern perspective, motivated by~\cite{benton-1995}, is to focus on
resolutions of this comonad, i.e. monoidal adjunctions \[
  \begin{tikzcd}
    \cat{I}\ar[rr, bend left, "F"] & \bot & \cat{L}\ar[ll, bend left, "G"]
  \end{tikzcd}
\]such that $FG = \denote{!}$, and in particular on resolutions such that the
monoidal structure on $\cat{I}$ is cartesian, hence a model of conjunctive
intuitionistic logic\footnote{
  Normally we consider such situations with significantly more structure than just
  the multiplcatives, but the situation is the same even in this case.
}. It turns out that any monoidal adjunction between categories with this
structure gives the necessary structure on the comonad $GF$; as a consequence,
such adjunctions are called \emph{linear-non-linear}. In this way, $F$ is an
embedding of intuitionistic terms as linear terms, while $G$ forgets the
linearity of a term. A standard example of this structure is the free-forgetful
adjunction between \scat{Set} and
$\scat{Vect}_\kk$~\cite{valiron-zdancewic-2014}. Linear-non-linear adjunctions
have been widely used for designing resource-aware programming
languages~\cite{maf-2005,krishnaswami-2015,paykin-2018,lmz-2019}.

All this machinery suggests that, to give a system which allows simultaneous
reasoning about both single- and multi-use resources, we should look for
such an adjunction. There is indeed a forgetful functor $G: \ncomb{\cat{C}}\to
\ncombb{\cat{C}}$, which we may think of as forgetting the linearity of an
n-comb. Furthermore, the category $\ncombb{\cat{C}}$ is cartesian monoidal,
meaning that the concatenation of two lists is a cartesian product; the
projctions simply do not use the extra resource, while the universal property is
witnessed by concatenating lists of n-combs. As such, $\ncombb{\cat{C}}$ is a
model of conjunctive intuitionistic logic; it represents an intuitionistic,
rather than linear, calculus of resources.

However, the functor $G$ seems unlikely to be a right adjoint\footnote{
  I would like, but do not have, an explicit construction of a limit which $G$
  does not preserve; the issue is that it seems hard for $\ncomb{\cat{C}}$ to
  have very many limits in the first place.
}. The issue is that combs between the same two objects $\ncombb{\cat{C}}$ may
use different numbers of resources, and so ought to be sent to different objects
in $\ncomb{\cat{C}}$, but this is impossible for any functor. To resolve this,
we need a notion of intuitionistic resource internal to $\ncomb{\cat{C}}$. A solution
may perhaps be along the lines of the $\infty$-combs of~\cite{roman-2020}, which
are used there to model stream-like data, but these have slightly
differently-structured domains and codomains than n-combs, so the translation is
not obvious.

A more direct solution is to extend $\ncomb{\cat{C}}$ with objects $!(A, B)$,
representing reusable resources of type $A\to B$, and which are used to build
n-combs as in $\ncombb{\cat{C}}$.

\begin{dfn}\label{def:ncomba}
Objects in the category
$\ncomba{\cat{C}}$ are finite multisets\footnote{
  We use multisets instead of lists to simplify the monoidal structure; since
  all our categories and multicategories are symmetric, the distinction is not
  important.
} of pairs $(A, B)$ and/or $!(A, B)$ of objects in $\cat{C}$, called
\emph{linear} and \emph{reusable} resources respectively. Given four
finite disjoint index sets $I,J,K,$ and $L$, we now describe morphisms
 \[
   \{!(A_i, B_i), (C_j, B_j): i\in I, j\in J\}\to \{!(X_k, Y_k), (Z_l, W_l):
   k\in K, l\in L\}.
\] To construct such a morphism, we first give a relation $\alpha: K\sqcup L\to I\sqcup J$ such
that:
\begin{enumerate}
  \item each $j\in J$ $\alpha$-relates to exactly one element;
  \item each $k\in K$ $\alpha$-relates only to elements in $I$.
\end{enumerate}
Next, for each $k\in K$, we give morphism from $\ncombb{\cat{C}}$, whose domain
is the multiset $\{(A_i, B_i): i\in \alpha(k)\}$ and whose codomain is $(X_k,
Y_k)$. Finally, for each $l\in L$, we first give for some $n$ a function
$\sigma: n\to \alpha(l)$, such that for each $j\in J\cap\alpha(l)$,
$\sigma^{-1}(j)$ is a singleton. We then give an n-comb which uses the resources in
$\alpha(j)$ according to the order assigned to them by $\sigma$.
\end{dfn}
The definition is justified as follows. The first condition on $\alpha$ ensures
that each linear resource must be used in exactly one comb, while the second
ensures that we can only build reusable resources out of reusable resources.
We build reusable resources as in $\ncombb{\cat{C}}$, which was constructed
specifically for that purpose. To build linear resources, we can use
reusable resources as many times as we want, but must use linear resources
exactly once, hence the condition on $\sigma$.


% situation for combs building linear resources is slightly more complicated: we
% should be able to use intuitionistic resources to build them multiple times,
% while we should have to use linear resources exactly once. For each $l\in L$,
% the comb consists of a function $\sigma: n\to |\alpha(l)|$, such that for each
% $j\in J\cap\alpha(l)$, $\sigma^{-1}(j)$ is a singleton. Now we build an $n$-comb
% using the given resources in the order prescribed by $\sigma$.


Another semantic digression: this category is strict symmetric monoidal with the
union of multisets as the product and the empty set as the identity.
Furthermore, there is a linear-non-linear adjunction \[
  \begin{tikzcd}
    \ncombb{\cat{C}}\ar[rr, bend left, "F"] & \bot &
    \ncomba{\cat{C}}\punctuation{,}\ar[ll, bend left, "G"]
  \end{tikzcd}
\]
where $G$ forgets the difference between linear and reusable resources,
and $F$ sends all resources to reusable ones. To show this is an
adjunction, observe that all the restrictions on the construction of the combs
are on the use of linear resources in the domain. As such, when all the
resources in the domain are reusable, a morphism in $\ncomba{\cat{C}}$ is
exactly a morphism in $\ncombb{\cat{C}}$; thus the identities give a natural
isomorphism between adjoint hom-sets.

This may seem like abstract nonsense, but the point is that the theory guided us
in constructing a category which models protocols relying on both linear and
multi-use resources; this is likely of independent interest to other uses of
n-combs. We conjecture that this style of construction extends to graded linear
logic (in which resources can have a bounded number possible
uses)~\cite{girard-1992}, affine logic (in which resources must be used at most
once)~\cite{troelstra-1992}, relevance logic (in which resources must be used at
least once)~\cite{dunn-1983}, ordered logic (in which resources must be used in
a specific order)~\cite{lambek-1958}, and to other such substructural resource
logics. The general paradigm of adjoint logic~\cite{pruiksma-2018} provides
categorical semantics for embedding many of these logics in each other; giving
``comb-like'' constructions of such categorical structures would allow reasoning
about resource-bounded protocols with fairly sophisticated resource-usage
constraints.

As a final notational point, we modify $\prot{N}{\cat{C}}$ as
$\protb{N}{\cat{C}}$ and $\prota{N}{\cat{C}}$ by replacing all the invocations
of n-comb with n-comb$!$ and n-comb$^*$, respectively. In particular, these
constructions are both functorial in the same way as n-comb.

% To explicitly construct the 
% define $\denote{!} = FG$, which promotes all the resources in the domain to be
% reusable. Then the map $\denote{!}x\to I$ is the empty comb, and the map
% $\denote{!}x\to \denote{!}x\otimes \denote{!}x$ is the comb which uses each
% input resource twice to produce the output resoures.
%
%
%
% For instance, suppose
% $\cat{C}$ has two objects, $a$ and $b$, and the following morphisms:
% \begin{itemize}
%   \item for each natural number $n$, a morphism $n: a\to a$;
%   \item one morphism $f: a\to b$;
%   \item one morphism $g: b\to a$;
%   \item two morphisms $h,1_b: b\to b$.
% \end{itemize}
% Composition of morphisms $a\to a$ is by addition, while $h\circ h = 1_b$, $. Impose a strict symmetric
% monoidal structure on this category by \begin{mathpar}
%   a\otimes a = a, \and a\otimes b = b\otimes a = a, \and b\otimes b = b,
%   \and n\otimes m = n+m, \and n\otimes f = f\otimes n = n, \and n\otimes g = g\otimes n =
%   g, \and g\otimes f = f\otimes g = 0, \and 1_b\otimes 1_b = 1_b, \and 1_b\otimes f
%   = f\otimes 1_b = 1_b\otimes g = g\otimes 1_b = 0$.
% \end{mathpar}
% Then the pair $(*, *)$ is 
% $(0, 0)$ is terminal in $\ncomb{\cat{C}}$.

\subsubsection{Shading Diagrams}
While \cite{broadbent-karvonen-2022} choose to label the wires with the
identities of the parties in possession of that data, we worry that this
approach does not easily scale to protocols where multiple objects are relevant.
We now give an alternative approach using the shaded boxes of
\Cref{sec:monoidal-functors}. In addition
to being less cluttered, this approach has a fairly pleasant abstract
justification, though we emphasize that it is merely a syntactic distinction.

We begin by noting that, in addition to the tensor \[
  \cat{C}^N\xto{\otimes^{N-1}}\cat{C},
\]there are also strong monoidal projection functors \[
  \cat{C}^N\xto{\pi_i}\cat{C}.
\]
Instead of labelling each wire with the party, we can shade the wires according
to the projection functors that they live in the image of. For instance, if Alice
is blue, Bob is green, and Eve is red, then the one-time pad can be depicted
as \[
  \begin{pic}
    \node[dot, fill=black] (am) at (0,0) {};
    \node[dot, fill=white] (copy) at (0, .6) {};
    \node[dot, fill=white] (keydist) at (.8, -.5) {};
    \node[dot, fill=black] (bm) at (.8, 1.1) {};
    \draw (am) to[out=180, in=90] ++(-.5, -.5) to ++(0, -1);
    \draw (am) to (copy);
    \draw (am) to[out=0, in=180] (keydist);
    \draw (keydist) to ++(0, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (keydist) node[right, xshift=8mm,
    yshift=-2mm] {\normalsize.} to[out=0, in=-90] ++(.5, .5)
    to ++(0, .3) node[dot, fill=black] {} to++(0, .3) to[out=90, in=0] (bm);
    \draw (copy) to[out=0, in=180] (bm);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[dot, fill=white] {};
    \draw (bm) to ++(0, .6);
    \draw[functor=cyan] (-.7, .2) -- (.5, .2) -- (.5, -.6) to[out=180, in=90]
    (-.3, -1.8) -- (-.7, -1.8) node[left, opacity=1] {$A$} -- cycle;
    \draw[functor=green] (1.1,-.6) to[out=0, in=-90] (1.5, 0) node[right, opacity=1] {$B$} to[out=90, in=0]
    (.8, 2) to [out=180, in=90] (.2, .9) -- cycle;
    \draw[functor=red] (-.3, .9) -- (-.7, .9) -- (-.7, 1.6) node[left, opacity=1] {$E$} -- (-.3, 1.6) --
    cycle;
  \end{pic}
\]%

We like the visual clarity provided by this approach; it emphasizes the flow of
information and control between the parties in the protocol. As mentioned, it
also has a nice justification in terms of the functorial boxes studied
previously; unifying analogous notations is always valuable. However, we see two
potential issues. First, as usual with color in diagrams, there are
accessibility concerns; while we attempt to ameliorate these by labelling the
regions and using an accessible colorscheme due to~\cite{tol-2021}, such
measures can only go so far. Second, this approach is hard to scale to settings
with many parties, as there are only so many visually distinct colors. As such,
we think that both approaches have their place.

\subsubsection{Parties With Differing Capabilities}

It is quite common in cryptography to consider settings where different parties
have different capabilities. For instance, we may want to analyze classical
protocols which are secure against quantum attackers or zero-knowledge proofs
with polynomial verifiers and unbounded provers. While the attack models
of~\cite{broadbent-karvonen-2022}, to be studied in
\Cref{sec:attack-models}, allow treating
adversaries with different capabilities from the honest parties, the paper does
not directly address honest parties with different capabilities. This can be
done within their framework using the categories we constructed
in~\Cref{sec:computation}.

As an example, we construct the category of protocols with one unbounded but
deterministic party and one PPT party. Recall that unbounded deterministic
computation is modeled in the category \scat{Comp}, while PPT computation is
modeled in the category \scat{PPT}. Both of these include as subcategories into
$\cat{C} = \scat{CompStoch}$; call these inclusion functors $i$ and $j$. As such, we can
construct the category \[
  \state{\ncomb{\scat{Comp}\times\scat{PPT}}\xto{\ncomb{i\times
    j}}\ncomb{\cat{C}^2}\xto{\ncomb{\otimes}}\ncomb{\cat{C}}}.
\]

In general, assuming there is a clear ambient category $\cat{C}$ of
into which all the relevant categories include, we write \[
  \prot{N}{\cat{C}_1,\dots,\cat{C}_N} := \state{\ncomb{\prod_{i=1}^N
  \cat{C}_i}\into\ncomb{\cat{C}^N}\xto{\ncomb{\otimes^{N-1}}}\ncomb{\cat{C}}}.
\]
We define $\protb{N}{\cat{C}_1,\dots,\cat{C}_N}$ and
$\prota{N}{\cat{C}_1,\dots,\cat{C}_N}$ similarly.

\subsubsection{Joint Input}

While the objects in the category $\prot{N}{\cat{C}}$ are morphisms representing
joint computations in $\cat{C}$, the domains and codomains of these computations
are $N$-fold tensor products of objects in $\cat{C}$, and so cannot themselves be
entangled. However, it is extremely common in cryptography to want to represent
joint or otherwise correlated input. For instance, if $\cat{C} =
\scat{Set}$, we may only care about inputs from a subset $\{(x, x)\}\subseteq
X\times X$. In the framework as described, it is impossible to restrict inputs
in such a way that does not decompose into a product.

There are various ad-hoc low-tech solutions to this problem, such as giving
the parties an oracle which rejects bad inputs, but we can also modify the
construction of our categories to allow for this kind of entangled input to
resources. Our goal will be to define a \emph{category of refinements on joint
states} which will allow us to refine the domains of our resources.

What is the categorical notion of subset? Every subset $A\subseteq X$ comes with
an \emph{inclusion function} $i: A\into X$, which is always an injection. As
usual, the categorical approach is to forefront the role of the morphism, in
this case the injection. It turns out there is a categorical generalization of
injections which makes no reference to objects having elements: a morphism $f:
x\to y$ is a \emph{monomorphism} if for all objects $z$ and maps $g, h: z\to x$,
if $fg = fh$, then $g = h$. In the category of sets, monomorphisms are exactly
injections. Given two monomorphisms $i: y\into x$ and $j: z\into x$, we say that
$i\leq j$ if there is a (necessarily unique) morphism $k: y\into z$ such that \[
  \begin{tikzcd}
    y\ar[hook, r, "i"]\ar[hook, dr, "k"'] & x\\
    & z\ar[hook, u, "j"']
  \end{tikzcd}
\]commutes. A \emph{subobject} of $x$ is an equivalence class of monomorphisms
into $x$ under the relation $i\sim j$ if $i\leq j$ and $j\leq i$.

To make a category of subobjects, we need a way to talk about morphisms between
subobjects of different objects. It turns out that in many categories there is a
way to talk about images of subobjects under morphisms, though we have not given
the background to go into detail here\footnote{For the categorically inclined:
  we have in mind a factorization system whose right class is the monomorphisms.
The direct image of a subobject $i: z\into x$ under a map $f: x\to y$ is the
monic part of the factorization of $fi$.}. We write $f_*i$ for the image of $i$
under the morphism $f$; in all our examples, this is the familiar image of a
subset.

Now we define the category $\pred{\cat{C}}$ of predicates on objects in
$\cat{C}$. Objects in this category are pairs $(x, i)$ where $x\in\cat{C}$ and
$i$ is a subobject of $x$. Morphisms $(x, i)\to (y, j)$ are maps $f: x\to y$ in
$\cat{C}$ such that $f_*i\leq j$, i.e. so that the image of $i$ under $f$ is
contained in $j$. Composition and identities are as in $\cat{C}$.

More generally, as with state we define $\pred{\cat{C}\xto{F}\cat{D}}$ for any
functor. Objects are pairs $(x, i)$ where $x\in\cat{C}$ and $i$ is a subobject
of $Fx$, while morphisms are maps $f: x\to y$ in $\cat{C}$ such that
$(Ff)_*i\leq j$.

If $F$ is strong monoidal and $\otimes_{\cat{D}}$ preserves monomorphisms (as it does in all
our categories of interest), then this category is also monoidal, with the
structure induced by the respective monoidal structures: \[
  (x, i)\otimes (y, j) = (x\otimes_{\cat{C}} y, (i\otimes_{\cat{D}} j)\phi^{-1}_{x,y}).
\]

Given a (strong monoidal) functor $F: \cat{C}\to\cat{D}$, there is a (strong
monoidal) functor $\pred{F}\to\pred{\cat{D}}$, which due to the notational
ambiguity\footnote{ Observe that pred is not functorial. Given a functor $F:
  \cat{C}\to\cat{D}$, the natural thing is to define a functor
  $\pred{\cat{C}}\to\pred{\cat{D}}$ which sends $(x, i)$ to $(Fx, Fi)$, but $Fi$
is not necessarily a monomorphism. } we call $\overline{F}$. This functor sends
a predicate $(x, i)$ to the predicate $(Fx, i)$, and a map $f$ to the map $Ff$.

Given an SMC $\cat{C}$, consider the category \[
  \oprot{N}{\cat{C}} := \state{\ncomb{\pred{\otimes^{N-1}}}\xto{\ncomb{\overline{\otimes^{N-1}}}}\ncomb{\pred{\cat{C}}}}.
\]
Basic objects in this category consists of a subobject $i$ of $X_1\otimes \dots\otimes
X_N$, a subobject $j$ of $Y_1\otimes \dots\otimes Y_N$, and a morphism
$f: X_1\otimes\dots\otimes X_N\to Y_1\otimes\dots\otimes Y_N$ in $\cat{C}$ such
that $f_*i\leq j$. The domain and codomain of this map are refinements of a
product state, which specify the allowable input and output states; the map must
send allowable inputs to allowable outputs.

Finally, objects are finite lists of basic objects. Morphisms are lists of
n-combs in $\cat{C}^N$ whose domains and codomains may be augmented with
predicates, and whose maps must respect those predicates. We define
$\overline{\operatorname{prot}}!$ and $\overline{\operatorname{prot}}^*$
similarly.

We expect that most readers are somewhat overwhelmed by the proliferation of
constructions on categories. However, once this initial conceptual barrier is
overcome, this proliferation of constructions is actually very helpful; they
allow us to fine-tune our base category for any specific use-case.

\subsection{Interactive Proof}

We now give an original representation of interactive proofs within the
framework. Recall from \Cref{sec:zkp}
that an \emph{interactive proof} for a
language $\cL$ consists of a prover and a verifier, both given an input $x$,
such that the verifier accepts if $x\in\cL$ and does not if $x\not\in\cL$, even
if the prover is behaving maliciously. While we do not yet know how to model
malicious behavior, we are already able to model the honest case. Fix a universe
of strings $A$ and a decidable\footnote{
  Note that $\cL$ needs to be decidable so that its characteristic function is
  in $\scat{CompStoch}$, which allows us to represent it as a resource. This
  restriction can technically be relaxed if we choose a bigger ambient category
  of computations, even while still requiring our prover to be computable.
} language $\cL$. This can be made significantly more
general, but for simplicitly we will work over the category $\scat{CompStoch}$,
and let the verifier be bounded in $\scat{PPT}$. We will work in the category
$\oprota{2}{\scat{CompStoch}, \scat{PPT}}$.

We need to know what the input and output resources of an interactive proof
should be. Certainly we need a two-way channel between the prover and verifier.
Since our proofs are interactive, this needs to be multi-use, so it should be
the resource\footnote{
  The reader may wonder which type this channel carries; this is a good
  question. Since all our computations are binary-encoded, we can let this be a
  channel over the object $\bin^*$, but this requires forgetting type
  information that may be useful. With more categorical machinery, we could
  instead make this a \emph{polymorphic} channel. Again, we would need to adapt
  the standard categorical semantics of the polymorphic lambda
  calculus~\cite{seely-1987} to the comb framework. As the type theories
  involved get increasingly sophisticated, so too do the categorical
  requirements: we would need to give a kind of indexed carestian closed
  category called a \emph{hyperdoctrine} satisfying a fairly intricate
  equational theory (the key difficulty turns out to be demonstrating the
  Beck-Chevalley condition for this hypothetical category of polymorphic combs,
  in case anyone is keeping score at home).
} \[
  !\begin{pic}
    \draw (0,0) node[left] {$P$} -- ++(0, 1) node[left] {$V$};
  \end{pic}\quad\otimes\quad !\begin{pic}
  \draw (0,0) node[left] {$V$} node[right, xshift=3mm, yshift=1mm] {\normalsize.} -- ++(0, 1) node[left] {$P$};
  \end{pic}
\]
As output, the protocol should give a resource such that, on an input $(x, x):
x\in A$, the verifier outputs $\ind_\cL(x)$. Thanks to our work in the
previous section, we know how to encode this: the input to this resource should
be the subset $\{(x, x)\}\subseteq A\otimes A$. It should output a value of
$*\times \{0, 1\}$; the prover has no output, while the verifier outputs either
to accept or reject. The actual resource we want to produce is the map \[
  \begin{pic}
    \draw[functor=cyan] (-1.3, -.8) -- (-.7, -.8) -- (-.7, .5) -- (-1.3, .5) node[left, opacity=1] {$P$} -- cycle;
    \draw[functor=green] (-.5, -.8) -- (.65, -.8) node[right, opacity=1]
    {$V$\normalsize,} -- (.65, .8) -- (-.5, .8) -- cycle;
    \draw (-1, -.6) node[left,xshift=.4mm] {$A$} -- ++(0, .7) node[dot, fill=white] {};
    \node[morphism] (i) at (0,0) {$\ind_\cL$};
    \draw (i) to ++(0, -.6) node[left] (a) {$A$};
    \draw (i) to ++(0, .6) node[right, xshift=-1mm] (b) {$\{0, 1\}$};
  \end{pic}
\]where the prover is blue and the verifier is green. The point is that a
correct interactive proof should amount to the prover doing nothing with its
input, while the verifier outputs the characteristic function of the language
under proof.

\section{Security}
\label{sec:security}

[I am rewriting this (again), using 2-categories as a middle
ground between bicategories and Eqn-categories. This will be the last attempt
even if I'm not satisfied with it.]

\subsection{Attack Models}
\label{sec:attack-models}

[left in to make the references not broken]


% \section{Paths Not Taken}

% - functorality
% - internalization of owf/indistinguishability/etc
