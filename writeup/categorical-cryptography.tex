A theory of cryptography should define at least four things: computation,
protocols, adversarial behavior, and security. A major advantage of categorical
models of cryptography is that they conveniently separate these issues. In
particular, we have some underlying category of computations, while we represent
categories of protocols with certain constructions on categories; as such, our
notions of interaction and security are completely independent of the underlying
model of computation.

[todo: lots more intro,
cite \cite{broadbent-karvonen-2022};
categorical crypto theories~\cite{hines-2020,pavlovic-2012,pavlovic-2014,stay-vicary-2013},
caterogies for specific crypto protocols~\cite{bkm-2019, bmr-2019}; categorical
qm
\cite{abramsky-coecke-2004,coecke-perdrix-2012,heunen-vicary-2014,coecke-kissinger-2017,chitambar-gour-2019}]

\section{Computation}

The categorical theory of computation is well-developed, going back at least to
the work of Jim Lambek and several contemporaries around the
1970s~\cite{lambeck-1974,lambeck-1980,lawvere-1969,seely-1984}. The essential
idea generalizes~\Cref{ex:functional programming}: objects are types
and morphisms are typed computations. The most disciplined approach is to
consider the categorical structure needed to model certain forms of computation, so that
for instance models of simply typed computation are \emph{bicartesian closed
categories}~\cite{lambeck-1974}, of linear computation are \emph{star-autonomous
categories}~\cite{seely-1989}, of quantum computation are \emph{compact-closed
categories}~\cite{abramsky-coecke-2004}, and of probabilistic computation are \emph{Markov
categories}~\cite{fritz-2020}. We will not review this approach here. Instead,
our focus will be on constructing specific categorical models of forms of
computations of interest to cryptographers.

\subsection{Deterministic Computation}

We would like a category of deterministic computations to have computable
functions as morphisms. However, the natural choice, taking sets as objects and
computable functions as morphisms, is actually not yet precise. The first issue
is that there are several distinct notions of computability on uncountable sets.
Each such notion forms a category, but formal definitions are outside our scope,
as cryptographers tend not to care about uncountable sets anyway\footnote{These
issues are studied in the field of \emph{computable analysis}; see for instance
the PhD thesis of Andre Bauer~\cite{bauer-2000}.}.

We can resolve this issue simply, by limiting ourselves to finite sets, in which
case every function is computable (simply by a lookup table):

\begin{dfn}[category of finite sets]
  The \emph{category of finite sets}, $\scat{FinSet}$, has finite sets as
  objects and functions as morphisms.
\end{dfn}

However, we often want to work with larger input spaces. The natural guess is to
take countable sets and computable functions. The issue here is one of encoding:
there is a canonical notion of computability on the set of finite binary
strings, but elements of arbitrary sets do not generally have canonical
encodings as binary strings. We could solve this issue by limiting
ourselves to working only with binary strings:
\begin{dfn}[category of computable binary functions]
  The \emph{category of computable binary functions} \scat{BinComp} has sets of binary strings
  $A\subseteq\bin^*$ as objects and computable functions as morphisms.
\end{dfn}

In practice, however, we like to think of computations as working over arbitrary
sets, which in particular may have more algebraic structure than sets of binary
strings. Our strategy, following~\cite{pavlovic-2014}, will be to work over sets
with fixed binary encodings.
\begin{dfn}[binary-encoded set]
  A \emph{binary-encoded set} is a set $X$ together with an injection
  $\denote{-}_X: X\to\bin^*$, called the \emph{encoding}.
\end{dfn}

Note that every binary-encoded set is finite or countable; as such, we avoid the
issues with uncountable sets mentioned above.

\begin{ntn}
  When the context is clear, we will generally drop the subscript of
  $\denote{-}$. We write $\denote{X}$ for the image of $\denote{-}_X$, i.e.
  $\denote{X} = \{s\in\bin^*: s = \denote{x}\text{ for some }x\in X\}$.
\end{ntn}

Given a function $f: X\to Y$ of binary-encoded sets, we can define a function
  \begin{align*}
    \denote{f} \colon \denote{X} &\to \denote{Y}\\
    \denote{x} &\mapsto \denote{f(x)}.
  \end{align*}
This is well-defined exactly because $\denote{-}_X$ is injective.

\begin{dfn}[category of computable functions]
  A function $f: X\to Y$ of binary-encoded sets is \emph{computable} if
  $\denote{f}$ is computable. The \emph{category of computable functions},
  \scat{Comp}, has binary-encoded sets as objects and computable functions as
  morphisms.
\end{dfn}

It needs to be shown that this is a category. First, the identities
$1_X$ are computable, as $\denote{1_X} = 1_{\denote{X}}$ is computable. Second,
the composite of computable functions is computable, as the composition of
computable binary functions is computable, and composition is preserved by
$\denote{-}$. As this argument indicates, there is a functor $\denote{-}:
\scat{Comp}\to\scat{BinComp}$; in fact this functor is an \emph{equivalence of
categories}. Nevertheless, the expanded perspective provided by $\scat{Comp}$ will be
convenient.

% [TODO: SMC structure]

Finally, we now define a symmetric monoidal structure on \scat{Comp}.
In particular, for two binary-encoded sets $X$ and $Y$, we would like to define
the product $X\otimes Y$ as the set $X\times Y$, but it is unclear what
$\denote{-}_{X\times Y}$ should be. We first fix an injective pairing map
$\<-,-\>: \bin^*\times\bin^*\to \bin$ which is efficiently computable\footnote{%
  One such map is computed as follows: given inputs $(m,n)$, start by encoding the
  length of $m$ in $2\log\log m$ bits: first write a bit of the length, then
  write a $1$ if the length continues and a $0$ if it doesn't. Now knowing the
  length of $m$, we can append the binary representation of $m$ and then $n$,
  which takes $O(\log m + \log n) = O(\log (mn))$ bits. Since $\log\log m =
  O(\log m)$, in total this algorithm takes $O(\log(mn))$ bits, and just writes
  across the tape, hence is computable in linear time.
}. We can then define $\denote{(x, y)} = \<\denote{x}, \denote{y}\>$; it is a
standard check that this defines a symmetric monoidal structure inherited from
$\scat{Set}$\footnote{
  Here is a more abstract way to see this. A suitable pairing function $\<-,-\>$
  turns $\{0,1\}$ into an internal commutative monoid in $\scat{Set}$. In other
  work, we show that the category of subobjects of any internal monoid is a
  monoidal category~\cite{shahar-zdancewic-2024}. The construction here is
  approximately an application of that general theorem.
}.

\subsection{Probabilistic Computation}

Again, there is some subtelty with probabilistic computation. Even in the case
of finite sets, not every stochastic function is computable by algorithms with
access to fair coin flips\footnote{
  We believe this is a slight conceptual problem with the strategy
  of~\cite[Section 6]{broadbent-karvonen-2022}, which models unbounded
  probabilistic computation in the category of finite sets and stochastic
  functions: this category is too powerful to reasonably model computation. This
  does not pose a technical issue in their specific example.
}. However, there is again a standard notion of computable stochastic function
of binary strings, so we can proceed much as before, defining:
\begin{dfn}[category of computable stochastic functions]
  The category \scat{BinCompStoch} has sets of binary strings as objects and
  computable stochastic functions as morphisms.

  A stochastic function $f:X\to Y $ between binary-encoded sets is
  \emph{computable} if $\denote{f}$ is computable. The \emph{category of
  computable stochastic functions} \scat{CompStoch} has binary-encoded sets as
  objects and computable stochastic functions as morphisms.
\end{dfn}

Again, it needs to be shown that this is a category. The identities are
computable (and stochastic, since every determinstic function is stochastic),
and composition commutes with $\denote{-}$, so the composite of computable
functions is computable. Furthermore, this category is symmetric monoidal, with
pairing of encodings as in \scat{Comp}.

We give a more abstract characterization of this category. There
are only countably many computable probability distributions on $\bin^*$, since
there are only countably many Turing machines. Fix a choice $\varphi$ of
bijection witnessing this fact. Note further that any probability distribution
$P$ on a binary-encoded set $X$ induces a probability distribution
$\denote{P}$ on $\bin^*$ by \[
  \Pr_{s\from \denote{P}}[s = s_0] = \Pr_{x\from P}[\denote{x} = s_0].
\]
There is now a monad $G_c: \scat{Comp}\to\scat{Comp}$, which we call the
\emph{computable Giry monad}, which takes any binary-encoded set $X$ to the set
of computable probability distributions on $X$, i.e. those such that
$\denote{P}$ is a computable probability distribution on $\bin^*$, with encoding
given by $\denote{P}_{G_c X} = \varphi(\denote{P}_X)$. Given $f: X\to Y$ and
$P\in G_c X$, we define the probability distribution $G_c f(P)$ on $Y$ by
\[
  \Pr_{y\from G_c f(P)}[y = y_0] = \Pr_{x\from P}[f(x) = y_0].
\]
The unit of $G_c$ is the function $X\to G_c X$ taking $x$ to the point
distribution at x. The multiplication is the function $\mu_X: G_c G_c X\to G_c X$
acting by summation: given a probability distribution $Q$ on $G_c X$, we define
a distribution $\mu_X (Q)$ on $X$ by \begin{equation*}\label{eqn:giry-sum}
  \Pr_{x\from \mu_X(Q)}[x = x_0] = \sum_{P_0\in G_c X} \Pr_{P\from Q}[P =
  P_0]\Pr_{x\from P}[x = x_0],
\end{equation*}which converges because $Q$ is a probability distribution. The proofs of
functorality and the monad laws as exactly as for the ordinary Giry
monad~\cite{giry-1982}, so we do not give them here. Now \scat{CompStoch} is in
fact (isomorphic to) the Kleisi category of $G_c$.

\subsection{Efficient and Effectful Computation}

Suppose that we are given some wide subcategory \scat{EffBin} of \scat{BinComp},
for instance that of poly-time computable maps. We can define the category
\scat{EffComp} of efficient computations as the wide subcategory of \scat{Comp}
consisting of morphisms $f$ whose encodings $\denote{f}$ are in $\scat{EffBin}$:
this is the \emph{preimage} of $\scat{EffBin}$ under the functor $\denote{-}$.

\begin{dfn}
  The category \scat{P} of poly-time computable maps is the wide subcategory
  of $\scat{Comp}$ consisting of those morphisms $f$ such that $\denote{f}$ is
  poly-time computable.
\end{dfn}

Similarly, suppose that we are give some wide subcategory of
\scat{BinCompStoch}, for instance that of poly-time computable stochastic maps.
We can similarly define the cateogry \scat{EffCompStoch}.

\begin{dfn}
  The category \scat{PPT} of poly-time computable stochastic maps is the wide is
  the wide subcategory of $\scat{CompStoch}$ consisting of those morphisms $f$
  such that $\denote{f}$ is probabilistic poly-time-computable.
\end{dfn}

In general, we can perform this construction for any complexity class $C$ which
is closed under composition.

Even more generally, let \scat{Bin} be the category of sets of binary strings and
(maybe uncomputable) set-functions between them. Let \scat{Enc} be the category
of binary-encoded sets and (maybe uncomputable) set-functions between them. Then
$\denote{-}$ is an equivalence of categories $\scat{Enc}\simeq \scat{Bin}$.

Now let \scat{EffBin} be any subcategory of \scat{Bin}. Then the \emph{category
of efficient computations} \scat{Eff} is the subcategory of \scat{Enc}
consisting of morphisms $f$ such that $\denote{f}$ is in \scat{EffBin}, i.e. the
preimage of \scat{EffBin} under $\denote{-}$. Finally, let $T$ be any monad on
\scat{Enc} which restricts to a monad on \scat{Eff}. Then the \emph{category of
efficient $T$-computations} is the Kleisi category of the restriction of $T$ to
\scat{Eff}. When $T$ is symmetric lax monoidal, this category is symmetric
monoidal.

\begin{ex}
  Each example in the previous three sections is a special case of this
  construction.
  \begin{itemize}
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the identity
      monad, we recover \scat{Comp}.
    \item When $\scat{EffBin}$ consists of computable functions and $T$ is the
      computable Giry monad, we recover \scat{CompStoch}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the identity monad, we recover \scat{P}.
    \item When $\scat{EffBin}$ consists of poly-time computable functions and $T$
      is the \emph{poly-time Giry monad}, which sends a set $X$ to the set of
      poly-time computable probability distributions on $X$, we recover
      \scat{PPT}.
  \end{itemize}
\end{ex}

The point is that for any notion of efficient computation, and any notion of
computational effect (since effects are generally
monadic~\cite{wadler-thiemann-2003}), as long as the effect can be efficiently
represented, we can use the machinery of binary-encoded sets to define a
category of efficient computations carrying the given effect.

\subsection{Quantum Computation}

While an complete introduction to quantum computation is outside our scope, we
can sketch a categorical perspective; a standard introduction
is~\cite{nielsen-chuang-2010}. The \emph{category of quantum computations}
\scat{FinHilb} is the category of finite-dimensional Hilbert spaces over $\CC$ and
linear maps. Since nontrivial complex Hilbert spaces have
uncountably many vectors, we cannot directly model this category using the
machinery of the previous section, as there is no way to encode a complex
Hilbert space as an object of \scat{Bin}. If we had developed a more general
theory relying on a notion of computability over uncountable sets, then we could
now unify these perspectives; indeed, there have been several attempts to
monadically embed quantum computation into classical
calculi~\cite{altenrich-green-2009,abramsky-2017}. As we have chosen not to
develop such a general theory, in this section we will treat Hilbert spaces as
our primitive object.

A \emph{quantum computation} is a sequence of unitary transformations and
\emph{measurements}. There are several ways to provide categorical semantics to
quantum measurement; we follow~\cite{heunen-vicary-2014}.

Let $I$ be the one-dimensional Hilbert space. Note that the maps $I\to I$
correspond to choices of scalars $\lambda\in\CC$; as such, we say that a
\emph{scalar} is a map $I\to I$. Given a Hilbert space $V$, a \emph{state} is a
map $I\to V$, so that a state is determined by a choice of vector in $V$. If
$I\xto{a} V$ and $I\xto{b} V$ are states, then the projection of $a$ onto $b$
has amplitude \[
  I\xto{a}V\xto{b^\dag} I,
\]where $(-)^\dag$ denotes the adjoint; the corresponding element of $\CC$ is
the inner product $\<b,a\>$. Now the \emph{Born rule} of quantum mechanics
asserts that the probability of measuring the outcome $b$ from the state $a$ is
$|\<b, a\>|^2$. Categorically, if $I\xto{a,b} V$ are states, then the
\emph{probability of measuring $b$ from the state $a$} is the scalar \[
    I\xto{a}V\xto{b^\dag} I\xto{b} V\xto{a^\dag} I.
  \]

This is just a brief sketch of a very rich theory; see especially the work of
Bob Coecke such
as~\cite{abramsky-coecke-2004,coecke-perdrix-2012,coecke-kissinger-2017}, or the
book by Heunen and Vicary~\cite{heunen-vicary-2014}. The key point is that any
fully categorical treatment of cryptography should obtain quantum cryptography as
a special case.

\section{Protocols}

The categorical semantics of interactive computation---in particular, of
protocols---originates from the study of quantum cryptography, especially of
so-called \emph{resource theories}~\cite{coecke-2016}. The idea is to start with
some underlying SMC $\cat{C}$ of computations---fixed throughout this
section---and to construct a category of ``protocols built from computations in
$\cat{C}$.'' Exactly which such construction we choose depends on what we want
our protocols to look like.

In all these categories, the basic idea is that we will think of objects as
resources and morphisms as protocols, which convert some resources into others.
For instance, in the category $\ncomb{\cat{C}}$, morphisms will be ``protocols with
holes''---when instantiated with specific implementations of the resources they
are waiting for, they provide some new resource.

\subsection{Products}

While the product category is used implicitly in the definition of monoidal
categories, it is worth exploring it explicitly. Given two categories $\cat{C}$
and $\cat{D}$, the \emph{product category} $\cat{C}\times\cat{D}$ has:
\begin{itemize}
  \item as objects, pairs $(X,Y)$ of objects in $\cat{C}$ and $\cat{D}$;
  \item as morphisms $(X,Y)\to (X',Y')$, pairs $(f,g)$ of morphisms so that $f:
    X\to X'$ and $g: Y\to Y'$;
  \item composition and identities defined componentwise.
\end{itemize}

When $\cat{C}$ and $\cat{D}$ are categories of computations, we think of
$\cat{C}\times\cat{D}$ as a category of non-interfering parallel computations: a
computation in $\cat{C}\times\cat{D}$ is a computation in $\cat{C}$ and a
computation in $\cat{D}$, but they cannot interact.

\subsection{States}

In the symmetric monoidal category \scat{Set}, the morphisms $\{*\}\to X$
are in natural correspondence with the elements of $X$, by the bijection \[
  (*\mapsto x) \mapsto x.
\]
Similarly, in the symmetric monoidal category $\scat{Vect}_\kk$, the morphisms
$\kk\to V$ are in natural correspondence with vectors in $V$, since such maps
are determined by their action on the vector $1\in\kk$. This pattern holds more
generally, motivating the following definition.

\begin{dfn}[state]
  A \emph{state} or \emph{generalized element} of $\cat{C}$ is a morphism $I\to
  X$ for some object $X$.
\end{dfn}

As we know, it is easy to recognize states string-diagramatically: they are
downward-pointing triangles.

\begin{dfn}[resource theory of states]
  The \emph{resource theory of states} $\state{\cat{C}}$ is the category whose objects
  are states in $\cat{C}$ and whose morphisms $(I\xto{s}X)\to (I\xto{t}Y)$ are
  maps $X\xto{f} Y$ such that $fs = y$. Composition is as in $\cat{C}$.
\end{dfn}

When $\cat{C}$ is interpreted a category of types of resources and conversions
between them, we can think of $\state{\cat{C}}$ states as a category
of specific resources and of conversions between them, forgetting the type
information.

The resource theory of states has a canonical symmetric monoidal structure
induced by that of $\cat{C}$: the monoidal product of states $I\xto{s} X$ and
$I\xto{t} Y$ is just the state $I \to X\otimes Y$ given by\footnote{
  It may worry the careful reader that there are two seemingly distinct, albeit
  coherently naturally isomorphic, morphisms this diagram could represent: \[
    I\xto{\lambda_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y\quad\text{and}\quad 
    I\xto{\rho_I^{-1}} I\otimes I\xto{s\otimes t}X\otimes Y.
  \]
  Fortunately, it is a non-obvious but standard result of Kelly that $\lambda_I
  = \rho_I$ in any SMC~\cite{kelly-1964}, so these morphisms agree.
}
\[
        \begin{pic}
          \node[state,scale=.75] (f) at (0,0) {$s$};
          \draw (f.north) to ++(0,.6) node[left] {$X$};
          \node[state,scale=.75] (g) at (.7,0) {$t$};
          \draw (g.north) to ++(0,.6) node[right] {$Y$};
        \end{pic},
\]while the monoidal product of morphisms is just their product in $X$. The unit is
the state $1_I$, while the associator and unitor are inherited from $\cat{C}$.

It will be useful to be a little more general. Let $F: \cat{D}\to\cat{C}$ be a
lax monoidal functor. Then an \emph{$F$-state} is a map $I\to FX$ in $\cat{C}$ for some object
$X\in\cat{D}$. The \emph{resource theory of $F$-states} $\state{F}$ is the category whose
objects are $F$-states and whose morphisms $(I\xto{s} FX)\to (I\xto{t} FY)$ are
maps $X\xto{f}Y$ in $\cat{D}$ such that $(Ff)s = t$\footnote{
  With a little more machinery: $\state{F}$ is the \emph{category of elements}
    of the functor $\cat{D}\xto{F}\cat{C}\xto{C(I, -)}\scat{Set}$. The
    category of elements of any lax monoidal functor has a canonical monoidal
    structure on it induced by that of the codomain; this is the monoidal
    structure with which we endow $\state{F}$. Observe the similarity of the
    monoidal product in $\state{F}$ with the coherence map for the functor $C(I, -)$
    from \Cref{ex:monoidal-functors}.
  }. Note what then $\cat{C} = \cat{D}$ and $F = 1_\cat{C}$, we recover
  $\state{\cat{C}}$.

Since $F$ is lax monoidal, there is again general recipe for taking the monoidal
product in this category: given $I\xto{s} FX$ and $I\xto{t} FY$, the product of $s$ and
$t$ is the state \[
  \begin{pic}
    \draw[functor=blue] (-.5, -.3) -- (0, -.3) -- (0, .2) -- (.5, .2) -- (.5,
      -.3) -- (1, -.3) -- (1, .7) -- (-.5, .7) -- cycle;
    \draw[rounded corners] (-.25, -.75) node[rounded corners=0, state, scale=.75] {$s$} -- (-.25, .45) --
      (.75, .45) -- ++(0, -1.2) node[rounded corners=0, state, scale=.75] {$t$} node[right, xshift=4mm, yshift=5mm] {\normalsize.};
    \draw (.25, .45) -- ++(0, 1.2) node[left] {$F(X\otimes_\cat{D} Y)$};
  \end{pic}
\]

Following~\cite{broadbent-karvonen-2022}, we are especially interested in the category
$\state{\cat{C}^2\xto{\otimes}\cat{C}}$. Objects in this category are morphisms
$I\to X\otimes Y$ in $\cat{C}$, which we can think of as \emph{joint states}.
When $\cat{C} = \scat{Set}$, every joint state is \emph{independent}, in that it
splits into the product of two morphisms $I\to X$ and $I\to Y$, but in more
complicated categories like \scat{PPT} or \scat{Hilb} this may fail, representing a
kind of \emph{entanglement}. In this way, we can express the idea that two
parties $A$ and $B$ have a shared uniform random key by the map $I\to X\otimes
X$ in \scat{PPT} that sends $*$ to a uniform random choice of pairs $(k, k)$ for
$k\in X$. This map does not split into a pair of stochastic maps $I\to X$ and $I\to X$.

Morphisms $(I\xto{s} X\otimes Y)\to(I\xto{t}X'\otimes Y')$ in this category are
maps $(f,g)$ in $\cat{C}^2$ satisfying $(f\otimes g)s = t$. The maps $f$ and $g$
prescribe the computations undertaken by the respective parties in order to
transform the joint state $s$ into the joint state $t$. Note that there is a
kind of locality to morphisms in this category, since they are morphisms in the
product category; all of the interaction between the two parties is encoded in
the initial joint state. This separation is actually desirable: it will make it
easier for us to reason about the security of protocols. However, it means we
need a way to describe objects which represent more complicated forms of
interaction; we will do so in the next two sections.

It is worth remarking that more generally, we can model computations on
$n$-party states via the category
\[
  \state{\cat{C}^n\xto{\otimes^{n-1}}\cat{C}},
\] where the $i$th copy of $\cat{C}$ represents computations taken by the $i$th
party in the computation\footnote{There is a choice of associativity to be made, but any
choice yields a coherently isomorphic category, so we will not worry about it
here.}.

\subsection{Flat Process Conversions}

Recall that we can think of morphisms in $X\xto{f} Y$ in $\cat{C}$ as processes
converting $X$ to $Y$. Before arriving at the more general strategy
of~\cite{broadbent-karvonen-2022}, we first treat a simpler case. We will
construct a category $\onecomb{\cat{C}}$ of \emph{flat process conversions}, whose
objects are ``type signatures'' of processes and whose morphisms are recipes for
converting between processes with the appropriate signatures.

By type signature, we mean a pair of objects $(X, Y)$ in $\cat{C}$. The idea is
that the resource $(X, Y)$ should be ``inhabited'' by the morphisms $X\to Y$ in
$\cat{C}$. To make this work out, whatever notion of morphism in $\onecomb{\cat{C}}$
we end up with, it should be the case that $\onecomb{\cat{C}}(I, (X, Y)) \cong
\cat{C}(X, Y)$, i.e. that the morphisms $I\to (X, Y)$ in $\onecomb{\cat{C}}$ should
be in (natural) correspondence with the morphisms $X\to Y$ in $\cat{C}$.

To make this work out, a morphism $(X, Y)\to (X', Y')$ in $\onecomb{\cat{C}}$
consists of the following structure, called a \emph{1-comb}: \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[midway, left] {$X$};
    \draw (xi2.south west) -- (f.north) node[midway, left] {$Y$};
  \end{pic}
\]

Explicitly, a 1-comb consists of an object $Z$ and two morphisms $\xi_1: X'\to
X\otimes Z$ and $\xi_2: Y\otimes Z\to Y'$. The point is that, if we ``plug in''
a morphism $X\to Y$ for the hole, we obtain a morphism $X'\to Y'$; $Z$
represents some auxiliary data that isn't needed by the plugged-in morphism.
We often call $Z$ the \emph{residual} of the comb. It is a theorem
of~\cite{coecke-2016} that in an SMC, any morphism $X'\to Y'$ obtainable as a
string diagram which uses exactly one occurrence of a morphism $f: X\to Y$ may
be obtained as a 1-comb with $f$ filled in the hole.

Composition of 1-combs is defined by ``nesting'': given 1-combs
$(Z, \xi_1, \xi_2): (X, Y)\to (X', Y')$ and $(Z', \xi_1', \xi_2'): (X', Y')\to
(X'', Y'')$, we have a composite 1-comb $(X, Y)\to (X'', Y'')$ defined by:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{10mm}
    \node[morphism] (xi1') at (0,0) {$\xi_1'$};
    \node[morphism] (xi2') at (0,3.5) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[left] {$X''$} node[right, xshift=2em,
    yshift=1.5em]
    {\normalsize.};
    \draw (xi2'.north) to ++(0,.5) node[left] {$Y''$};
    \draw ([xshift=2.5pt]xi1'.north east) to ([xshift=2.5pt]xi2'.south east);
    \node[morphism,scale=.6] (xi1) at ($(xi1'.north west)!.2!(xi2'.south west)$)
    {\normalsize$\xi_1$};
    \node[morphism,scale=.6] (xi2) at ($(xi1'.north west)!.8!(xi2'.south west)$)
    {\normalsize$\xi_2$};
    \draw (xi1'.north west) -- (xi1.south);
    \draw (xi2'.south west) -- (xi2.north);
    \draw (xi1.north east) to (xi2.south east);

    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism,scale=.75] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
This does indeed form a 1-comb: explicitly, the composite 1-comb is the
tuple \[
  ((Z\otimes Z'), (\xi_1\otimes 1_{Z'})\circ \xi_1', (1_{Z}\otimes \xi_2')\circ \xi_2).
\]

Meanwhile, the monoidal product of 1-combs is as follows:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,4) {$\xi_2$};
    \node[dashedmorphism] (f) at ($(xi1.north)!.5!(xi2.south)$) {};

    \draw (xi1.south) to ++(0,-.5);
    \draw (xi2.north) to ++(0,.5);
    \draw (xi1.north west) -- (f.south west);
    \draw (xi2.south west) -- (f.north west);
    % \draw (0,0) to[out=80,in=-100] (.6,1);

    \node[morphism] (xi1') at (2,0) {$\xi_1'$};
    \node[morphism] (xi2') at (2,4) {$\xi_2'$};
    \draw (xi1'.south) to ++(0,-.5) node[right, xshift=2em, yshift=1.5em] {\normalsize.};
    \draw (xi2'.north) to ++(0,.5);

    \draw
      let
        \p1=(xi1'.north west),
        \p2=(f.south),
        \p3=(f.north)
      in
      (xi1.north east) to[out=90,in=-90]
      (\x1,\y2) --
      (\x1,\y3) to[out=90,in=-90]
      (xi2.south east);
        
    % (xi1.north east) to[out=90,in=-90] ($(xi1'.north west)!.5!(xi2'.south west)$) to[out=90, in=-90] (xi2.south east);
    \draw (xi1'.north west) to[out=90,in=-90] (f.south east);
    \draw (f.north east) to[out=90,in=-90] (xi2'.south west);
    \draw (xi1'.north east) to (xi2'.south east);
  \end{pic}
\]Again, this forms a 1-comb.

We now return to the assertion from the beginning of the section: since a map $I\to
I$ carries no data, a 1-comb $I\to (X, Y)$ looks like \[
  \begin{pic}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,1) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.5) node[left] {$X$} node[right, xshift=1em,
    yshift=1.5em]
    {\normalsize;};
    \draw (xi2.north) to ++(0,.5) node[left] {$Y$};
    \draw (xi1.north) -- (xi2.south);
  \end{pic}
\]these are morphisms $X\to Y$, but not bijectively so. To resolve this, we take
equivalence classes of 1-combs, where two 1-combs are equivalent if they
yield the same morphism when any morphism $W\otimes X\to W\otimes Y$ is plugged
into their hole\footnote{This is an extensional notion of equality of
  combs. With significantly more machinery, it is also possible to define combs
intensionally, via so-called \emph{coend optics}~\cite{riley-2018,hefford-2023}: a 1-comb
$(X, Y)\to (X', Y')$ is precisely an element of the set $\int^{M\in \cat{C}}
\cat{C}(X', X\otimes M)\times\cat{C}(Y\otimes M, Y')$.}
Finally, we can formally define the category.

\begin{dfn}[category of flat process conversions]
  The \emph{category of flat process conversions} $\onecomb{\cat{C}}$ has as
  objects pairs $(X, Y)$ of objects in $\cat{C}$ and as morphisms equivalence
  classes of 1-combs in $\cat{C}$.
\end{dfn}

\begin{ex}
  The construction $\state{\onecomb{\cat{C}}}$ is the \emph{category of
  parallel-combinable processes} of~\cite{coecke-2016}.
\end{ex}

Now suppose that $F: \cat{C}\to \cat{D}$ is a strong monoidal functor; recall that this
means there is a natural isomorphism
$\phi_{X,Y}: FX\otimes_\cat{D} FY\to F(X\otimes_\cat{C} Y)$. Now there
is an induced functor $\onecomb{F}:\,
\onecomb{\cat{C}}\to\,\onecomb{\cat{D}}$ which acts on 1-combs by
\[
  \begin{pic}
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$X'$};
    \draw (xi2.north) to ++(0,.75) node[left] {$Y'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}\quad\mapsto\quad\begin{pic}
    \draw[functor=blue] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=blue] (-.75,3) -- (.75,3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;
    \setlength\minimummorphismwidth{8mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \draw (xi1.south) to ++(0,-.75) node[left] {$FX'$} node[right, xshift=2em,
    yshift=1.5em] {\normalsize.};
    \draw (xi2.north) to ++(0,.75) node[left] {$FY'$};
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \setlength\minimummorphismwidth{0mm}
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);
  \end{pic}
\]
Symbolically, the action of $\onecomb{F}$ is \[
  (Z, \xi_1, \xi_2)\mapsto (FZ, \phi^{-1}_{X,Z}F\xi_1, (F\xi_2)\phi_{Y,Z}).
\] We have that $\onecomb{F}$ preserves
identities and composition because $F$ does. Furthermore, this construction
turns 1-comb into an endofunctor on the category of SMCs and strong monoidal
functors.

Cryptographically, we are primarily interested in the category \[
  \state{\onecomb{\cat{C}^2}\xto{\onecomb{\otimes}}\onecomb{\cat{C}}}.
\]

Objects in this category are maps $I\to (X\otimes Y, X'\otimes Y')$ in
$\onecomb{\cat{C}}$, hence maps $X\otimes Y\to X'\otimes Y'$ in $\cat{C}$.
Morphisms $(X\otimes Y\xto{f} X'\otimes Y')\to(A\otimes B\xto{g} A'\otimes B')$
are 1-combs $(X\otimes Y, X'\otimes Y')\to (A\otimes B, A'\otimes B')$, which,
when the hole is ``filled in'' with $f$, yield the morphism $g$. The idea is
that $f$ represents some shared cryptographic resources which the two parties
already have access to; the one-comb is a protocol the parties can use to
transform it into the resource $g$.

We emphasize that these $1$-combs ``live in $\cat{C}^2$: the morphisms $\xi_1$
and $\xi_2$ must be in the image of $\otimes$. As before, this means that they
satisfy a kind of disjointness: they are really two separate computations
running in parallel but independently. All of the interaction between the two
parties is encapsulated in the resource $f$, which is shared between them. As
such, it is a general rule that \emph{protocols cannot create extra
  interactivity on their own; they need input resources enabling interaction}.

Finally, we note that to model $n$-party computation we can work in the category \[
  \state{\onecomb{\cat{C}^n}\xto{\onecomb{\otimes^{n-1}}}\onecomb{\cat{C}}}.
\]

As an example, let $\cat{C} = \scat{Set}$, and let $f$ be the map $X\times *\to
*\times X$ given by $(x, *)\mapsto (*, x)$. Then $f$ is a \emph{one-shot channel}
from the first party to the second party. However, we have no way to represent
protocols which use multiple input resources: our combs only have one hole. We
fix this by working with \emph{n-combs}.

\subsection{Linear Process Conversions}

The extension from 1-combs to the n-combs of~\cite{broadbent-karvonen-2022} is
conceptually straightforward, but technically somewhat messy. An n-comb is just
a stack of 1-combs; we can combine the top of one comb with the bottom of the
next, so we may as well write\footnote{
  As with 1-combs, there is a more abstract definition of n-combs using coend
  optics: an n-comb $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')$ is an
  element of the set \[
    \int^{M_1,\dots,M_n\in\cat{C}}\cat{C}(X', X_1\otimes
    M_1)\times\prod_{i=1}^{n-1} \cat{C}(Y_i\otimes M_i, X_{i+1}\otimes M_{i+1})
    \times \cat{C}(Y_n\otimes M_n, Y').
  \]
}
\[
  \begin{pic}
    \comb[0,0][0,2][$\xi_1'$][$\xi_2'$]
    \comb[0,3][0,5][$\xi_3'$][$\xi_4'$]

    \node at (0,6.5) {\normalsize$\vdots$};

    \comb[0,8][0,10][$\xi_{2n-1}'$][$\xi_{2n}'$]
  \end{pic}\quad\quad\quad\text{as}\quad\quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xi3) at (0,4) {$\xi_3$};
    \node[morphism] (xin) at (0,7) {$\xi_n$};
    \node[morphism] (xin1) at (0,9) {$\xi_{n+1}$};

    \node at (0,5.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi3.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi3.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xi2.north east) to ([xshift=2.5pt]xi3.south east);
    \node[dashedmorphism] (g) at ($(xi2.north west)!.5!(xi3.south west)$)
    {\phantom{$f$}};
    \draw (xi2.north west) -- (g.south);
    \draw (xi3.south west) -- (g.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]
Again by a theorem of~\cite{coecke-2016}, any circuit which is obtainable as a
string diagram using exactly one occurance of each of a list of $n$ morphisms
can also be obtained as the result of plugging those morphisms in to an
appropriate n-comb.

Generalizing the case of 1-combs, the objects in the category of n-combs should
be finite lists of pairs of objects: a resource of type $[(X_1, Y_1), \ldots,
(X_n, Y_n)]$ is a list of maps $X_i\to Y_i$ in $\cat{C}$. It is worth mentioning that We can proceed directly to defining the
category, but we find it easier to first define a symmetric multicategory of
n-combs. The advantage is that this requires us only to define morphisms with
one pair in the codomain---what~\cite{broadbent-karvonen-2022} call the ``basic
morphisms''---and then construct a full SMC via a general procedure.

Objects in this multicategory are pairs of objects in $\cat{C}$. Morphisms
$[(X_1, Y_1), \ldots, (X_n, Y_n)]\to (X', Y')$ consist of a permutation $\sigma$
and an n-comb
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2) {$\xi_2$};
    \node[morphism] (xin) at (0,5) {$\xi_n$};
    \node[morphism] (xin1) at (0,7) {$\xi_{n+1}$};

    \node at (0,3.5) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.2);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.2);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.2);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.2);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south) node[left, midway] {$X_{\sigma(1)}$};
    \draw (xi2.south west) -- (f.north) node[left, midway] {$Y_{\sigma(1)}$};

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south) node[left, midway] {$X_{\sigma(n)}$};
    \draw (xin1.south west) -- (h.north) node[left, midway] {$Y_{\sigma(n)}$};

    \draw (xi1.south) to ++(0,-.5) node[left] {$X'$};
    \draw (xin1.north) to ++(0,.5) node[left] {$Y'$};
    \node at (1, .5) {\normalsize.};
  \end{pic}
\] The idea is that $\sigma$ encodes the order in which the protocol uses the
input resources; we do not have to use them in the order specified by the domain
list. Composition of general combs is as with 1-combs: given an n-comb and n
$m_k$-combs such that the types line up, we nest each of the combs into the
outer n-comb. This indeed gives us a symmetric multicategory.

We can now use the following general construction to obtain the category of
n-combs:

\begin{dfn}
  Let $\cat{C}$ be a (symmetric) multicategory. Then there is an associated
  (symmetric) monoidal category $\cat{C}^\otimes$ defined as follows:
  \begin{itemize}
    \item an object in $\cat{C}^\otimes$ is a finite list of objects in
      $\cat{C}$, written $x_1\otimes\dots\otimes x_n$;
    \item a morphism $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes \dots\otimes
      y_m$ consists of a \emph{partition function}
      $\alpha_f: \{1,\dots,n\}\to\{1,\dots,m\}$ and for each $i\in\{1,\dots,m\}$, a morphism \[
        x_{k_1}, \dots, x_{k_l}\xto{f_i} y_i,
      \] called the \emph{$y_i$ component}, where the $k_j$s range over
      $\alpha_f^{-1}(i)$;
    \item the composite morphism $x_1\otimes\dots\otimes
      x_n\xto{f}y_1\otimes\dots\otimes y_m\xto{g}z_1\otimes\dots\otimes z_p$ is
      given by the partition function $\alpha_{gf} = \alpha_g\alpha_f$ and for
      each $z_i$, the component \[
        g_i\circ(f_{\sigma_i(1)},\dots,f_{\sigma_i(k)})
      \]in $\cat{C}$, where $\sigma_i$ is from $g$;
    \item the identity on $x_1\otimes\dots\otimes x_n$ is given by the identity
      partition and the identities $1_{x_i}$ from $\cat{C}$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n$ and
      $y_1\otimes\dots\otimes y_m$ is given by the concatenation
      $x_1\otimes\dots\otimes x_n\otimes y_1\otimes \dots\otimes y_m$;
    \item the monoidal product of $x_1\otimes\dots\otimes x_n\xto{f} y_1\otimes\dots\otimes y_m$
      and $z_1\otimes\dots\otimes z_p\xto{g} w_1\otimes\dots\otimes w_q$ is given
      by lifting the partitions to the disjoint union, so the $y_i$
      component is just $f_i$ while the $w_i$ component is just $g_i$.
  \end{itemize}
\end{dfn}

The idea is that each object in $x_1\otimes\dots\otimes x_n\in\cat{C}^\otimes$
represents the presence of the ``resources'' represented by the objects
$x_1,\dots,x_n\in\cat{C}$. A morphism must consume precisely one ``copy'' of
each resource in that list and produce one copy of each resource in its
codomain. The partition $\alpha$ is an allocation of input resources to output
resources: $\alpha^{-1}(i)$ is exactly the input resources used to produce the
resource $y_i$.

We can be explicit about what this construction looks like in the case of
n-combs.

\begin{dfn}
  Objects in the category $\ncomb{\cat{C}}$ are finite lists of pairs of objects
  in $\cat{C}$. A morphism $[(X_1, Y_1), \ldots, (X_n, Y_n)]\to [(X'_1, Y'_1),
  \dots, (X'_m, Y'_m)]$ is a list of $m$ combs, one for each pair of objects in
  the codomain, and each of which has holes typed by the pairs in the domain,
  such that each pair in the domain is used in \emph{exactly one} n-comb and
  \emph{exactly once} in that n-comb. Composition is by nesting, while the
  monoidal product is by concatenation of lists.
\end{dfn}

\begin{ex}
  The category $\state{\ncomb{\cat{C}}}$ is the \emph{category of universally
  combinable processes} of~\cite{coecke-2016}.
\end{ex}

Furthermore, n-comb is functorial in the same way a 1-comb. Given a strong
monoidal functor $F: \cat{C}\to\cat{D}$, we can define a functor $\ncomb{F}:
\ncomb{\cat{C}}\to\ncomb{\cat{D}}$ by acting on each n-comb over $\cat{C}$ by \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
  \end{pic}
  \quad\quad
  \mapsto
  \quad\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (xi1) at (0,0) {$\xi_1$};
    \node[morphism] (xi2) at (0,2.5) {$\xi_2$};
    \node[morphism] (xin) at (0,5.5) {$\xi_n$};
    \node[morphism] (xin1) at (0,8) {$\xi_{n+1}$};

    \node at (0,4) {\normalsize$\vdots$};
    \draw ([xshift=2.5pt]xi2.north east) to ++(0,.8);
    \draw ([xshift=-2.5pt]xi2.north west) to ++(0,.8);
    \draw ([xshift=2.5pt]xin.south east) to ++(0,-.8);
    \draw ([xshift=-2.5pt]xin.south west) to ++(0,-.8);

    \draw[functor=blue] (-.75,-.5) -- (.75,-.5) -- (.75, .8) -- (.15, .8) --
    (.15, .4) -- (-.15, .4) -- (-.15, .8) -- (-.75, .8) -- cycle;
    \draw[functor=blue] (-.75,3.3) -- (-.15, 3.3) -- (-.15, 2.9) -- (.15, 2.9) --
    (.15, 3.3) -- (.75,3.3) -- (.75, 1.7) -- (.15, 1.7) --
    (.15, 2.1) -- (-.15, 2.1) -- (-.15, 1.7) -- (-.75, 1.7) -- cycle;

    \draw[functor=blue] (-.75,8.5) -- (.75,8.5) -- (.75, 7.2) -- (.15, 7.2) --
    (.15, 7.6) -- (-.15, 7.6) -- (-.15, 7.2) -- (-.75, 7.2) -- cycle;
    \draw[functor=blue] (-.75,4.7) -- (-.15, 4.7) -- (-.15, 5.1) -- (.15, 5.1) --
    (.15, 4.7) -- (.75,4.7) -- (.75, 6.3) -- (.15, 6.3) --
    (.15, 5.9) -- (-.15, 5.9) -- (-.15, 6.3) -- (-.75, 6.3) -- cycle;

    \setlength\minimummorphismwidth{0mm}
    \draw ([xshift=2.5pt]xi1.north east) to ([xshift=2.5pt]xi2.south east);
    \node[dashedmorphism] (f) at ($(xi1.north west)!.5!(xi2.south west)$)
    {\phantom{$f$}};
    \draw (xi1.north west) -- (f.south);
    \draw (xi2.south west) -- (f.north);

    \draw ([xshift=2.5pt]xin.north east) to ([xshift=2.5pt]xin1.south east);
    \node[dashedmorphism] (h) at ($(xin.north west)!.5!(xin1.south west)$)
    {\phantom{$f$}};
    \draw (xin.north west) -- (h.south);
    \draw (xin1.south west) -- (h.north);

    \draw (xi1.south) to ++(0,-.5);
    \draw (xin1.north) to ++(0,.5);
    \node at (1, .5) {\normalsize.};
  \end{pic}
\]

Cryptographically, still following~\cite{broadbent-karvonen-2022} we are interested in
the category \[
  \prot{N}{\cat{C}} := \state{\ncomb{\cat{C}^N}\xto{\ncomb{\otimes^{N-1}}}\ncomb{\cat{C}}},
\]
which is a category of $N$-party protocols with computations from $\cat{C}$.
Objects in this category are finite lists of maps \[
  X^i_1\otimes\dots\otimes X^i_N\xto{f_i} Y^i_1\otimes\dots\otimes Y^i_N
\] in $\cat{C}$, which represent shared access to the resources $\{f_i\}$,
themselves processes for transforming joint states in $\cat{C}$. Morphisms are
lists of $M$ combs, so that each map $f_i$ in the domain list is allocated to
exactly one comb, and so that plugging in all the $f_i$s into the appropriate
combs yields exactly the list of maps in the codomain.

\subsection{The One-Time Pad}

As a first example, we work out in full detail the categorical description of
the one-time pad due to~\cite{broadbent-karvonen-2022}. For now, let $\cat{C} =
\scat{CompStoch}$ and $N = 3$; we label the three parties $A$, $B$, and $E$. We
pick a message space $M\in\cat{C}$; we could just say $M = \bin^*$, but instead
let us figure out what ``local'' structure, by which we mean structure in
$\cat{C}$ which is hence usable by each of the parties on their own, $M$ needs
to have.

First, we should be able to copy and delete messages from $M$; they're just
classical information. We represent this with a pair of maps \[
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$M$};
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$M$};
    \draw (mu) to ++(0, -.7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \hspace{1em}
  \quad\quad
  \begin{pic}
    \node[dot, fill=white] (eta) at (0,0) {};
    \draw (eta) to ++(0, -.7) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]called the \emph{copy} and \emph{deletion} maps. Copying is associative
(category theorists call this \emph{coassociativity}, because it is opposite to the
direction of normal associativity):
\begin{equation}\label{eqn:coassociative}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to[out=0, in=-90] ++(.7, .7) to ++(0, .5) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[left] {};
    \draw (a) to ++(0, -.7) node[left] {};
  \end{pic}
  =
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to[out=180, in=-90] ++(-.7, .7) to ++(0, .5) node[left] {};
    \draw (b) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {};
    \draw (b) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[right] {};
    \draw (a) to ++(0,-.7) node[left] {};
  \end{pic}
\end{equation}and commutative (\emph{cocommutativity}): 
\begin{equation}\label{eqn:cocommutativity}
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
    \draw (mu) to ++(0, -.7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) to[out=90, in=-90] ++(1, 1);
    \draw (mu) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) to[out=90, in=-90] ++(-1, 1);
    \draw (mu) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize;};
  \end{pic}
\end{equation}
deletion is the inverse of copying (\emph{counitality})\footnote{We do not
need to axiomatize both sides of this equality when we have commutativity.}:
\begin{equation}\label{eqn:xounital}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (.5,.5) {};
    \draw (a) to[out=0, in=-90] (b);
    \draw (a) to ++(0, -.7) node[left] {};
    \draw (a) to[out=180, in=-90] ++(-.5, .5) to ++(0, .4) node[left] {};
  \end{pic}
  \hspace{.4em}
  =
  \begin{pic}
    \draw(0, 0) node[left] {} to (0, 1.5) node[left]{};
  \end{pic}
  \hspace{.6em}
  =
  \hspace{.5em}
  \begin{pic}
    \node[dot, fill=white] (a) at (0,0) {};
    \node[dot, fill=white] (b) at (-.5,.5) {};
    \draw (a) to[out=180, in=-90] (b);
    \draw (a) to ++(0, -.7) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (a) to[out=0, in=-90] ++(.5, .5) to ++(0, .4);
  \end{pic}
\end{equation}
These three equations give $M$ the structure of a \emph{cocommutative
comonoid} in $\cat{C}$\footnote{
  We often want to work over categories in which \emph{every} object has such
  copy and delete maps. We say that an SMC $\cat{C}$ \emph{supplies
  cocommutative comonoids} if every object in $\cat{C}$ is a cocommutative
  comonoid in such a way that the comonoidal structure on any object $X\otimes
  Y$ is induced from that on $X$ and $Y$ by the tensor. We are now very close
  to the definition of a \emph{Markov category}, which is the natural
  categorical axiomatization of stochastic computation~\cite{fritz-2020}.
}.

Recall from~\Cref{ex:otp} the one-time pad
works over an arbitrary group $G$. As such, we separately need that $M$ looks
like a group in $\cat{C}$: it should have multiplication, unit, and inverse
maps \[
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2) node[left] {$M$};
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right] {$M$}
      node[right, xshift=4mm, yshift=1mm] {\normalsize,};
    \draw (mu) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
    \draw (eta) to ++(0, .7) node[left] {$M$};
  \end{pic}
  \quad\quad
  \text{and}
  \quad\quad
  \begin{pic}
    \node[dot, fill=black] (eta) at (0,0) {};
    \draw (eta) to ++(0, .5) node[left] {$M$};
    \draw (eta) to ++(0, -.5) node[left] {$M$} node[right, xshift=2mm, yshift=1mm] {\normalsize,};
  \end{pic}
\]which are associative and unital in the sense of~\Cref{def:monoid object}
and satisfy the additional \emph{inverse law}:
\begin{equation}\label{eqn:inverse}
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=0, in=-90] (inv) to[out=90, in=0] (mult);
    \draw (copy) to[out=180, in=-90] (-.5,.5) to[out=90, in=180] (mult);
    \draw (copy) to ++(0, -.75);
    \draw (mult) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (del) at (0,0) {};
    \node[dot, fill=black] (id) at (0,1) {};
    \draw (del) to ++(0, -.75);
    \draw (id) to ++(0, .75);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \node[dot, fill=black] (inv) at (-.5,.5) {};
    \node[dot, fill=black] (mult) at (0,1) {};
    \draw (copy) to[out=180, in=-90] (inv) to[out=90, in=180] (mult);
    \draw (copy) to[out=0, in=-90] (.5,.5) to[out=90, in=0] (mult);
    \draw (copy) to ++(0, -.75) node[right, xshift=2mm, yshift=1mm] {\normalsize.};
    \draw (mult) to ++(0, .75);
  \end{pic}
\end{equation}
Notice that this law relies on the existence of the copy and delete maps;
indeed, it is not possible to define a group without some way to talk about
copying.

We need one more compatibility law, which says essentially that multiplication
is deterministic: performing the same multiplication twice is the same as
performing it once and then copying the result:
\begin{equation}\label{eqn:mult-deterministic}
  \begin{pic}
    \node[dot, fill=white] (copy1) at (-.5, 0) {};
    \node[dot, fill=white] (copy2) at (.5, 0) {};
    \node[dot, fill=black] (mult1) at (-.5, .8) {};
    \node[dot, fill=black] (mult2) at (.5, .8) {};
    \draw (copy1) to[out=170, in=190] (mult1);
    \draw (copy2) to[out=10, in=-10] (mult2);
    \draw (copy1) to[out=10, in=190] (mult2);
    \draw (copy2) to[out=170, in=-10] (mult1);
    \draw (copy1) to ++(0, -.7);
    \draw (copy2) to ++(0, -.7);
    \draw (mult1) to ++(0, .7);
    \draw (mult2) to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mu) at (0,0) {};
    \node[dot, fill=white] (copy) at (0,.8) {};
    \draw (mu) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.2);
    \draw (mu) to[out=0, in=90] ++(.5, -.5) to ++(0, -.2) node[right, xshift=4mm, yshift=1mm] {\normalsize.};
    \draw (mu) to ++(0, .7);
    \draw (mu) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2);
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2);
  \end{pic}
\end{equation}
All these laws give $M$ the structure of a \emph{Hopf object} in $\cat{C}$. It
turns out that these objects are well-known, and in particular have important
applications in quantum computation~\cite{de-felice-2017}; for instance, a
Hopf object in $\scat{Vect}_\kk$ is just an ordinary Hopf algebra. This is a major
advantage of the categorical machinery: we discover unexpected connections
between different kinds of computation and mathematics.

Finally, for the one-time pad we need some way to model randomness; in
\scat{CompStoch} this is the map $I\xto{\$} M$ which draws a uniform random
value from $M$. Categorically, rather than the specific construction of the map,
we care about its properties\footnote{
  Somewhat surprisingly, elements of Hopf algebras satisfying
  \eqref{eqn:random-invariance} and \eqref{eqn:random-non-side-effecting} 
  have been well studied under the name
  \emph{integrals}~\cite{sweedler-1969,lomp-2004,sullivan-1971}. As such, the
  one-time pad can be instantiated over any Hopf algebra $H$ with an integral,
  by replacing the uniform random choice of key with the map $\kk\to H$ which
  sends $1$ to the chosen integral. This translation is purely syntactic;
  everything we will say about the one-time pad applies to this construction as
  well. We can now start doing cryptography inside a Hopf algebra, or using the
theory of Hopf algebras to say things about cryptography.}: it is invariant
under
multiplication, in the sense
that
\begin{equation}\label{eqn:random-invariance}
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) node[state, scale=.75] {\normalsize\$};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}\quad=\quad
  \begin{pic}
    \draw (0,0) node[state, scale=.75] {\normalsize\$} to ++(0, .7);
  \end{pic}\quad=\quad
  \begin{pic}
    \node[dot, fill=black] (mult) at (0,0) {};
    \draw (mult) to[out=0, in=90] ++(.5, -.5) node[state, scale=.75] {\normalsize\$} node[right, xshift=3mm, yshift=1mm] {\normalsize,};
    \draw (mult) to[out=180, in=90] ++(-.5, -.5) to ++(0, -.7);
    \draw (mult) to ++(0, .5);
  \end{pic}
\end{equation}
and it is non-side-effecting, in the sense that \begin{equation}\label{eqn:random-non-side-effecting}
  \begin{pic}
    \draw (0, 0) node[state, scale=.75] (rand) {\normalsize\$} to ++(0, .7) node[dot, fill=white] {};
  \end{pic}\quad\text{equals the empty diagram.}
\end{equation} We interpret \eqref{eqn:random-invariance} as
saying that the product of any group element with a uniform random value is
uniform random, while \eqref{eqn:random-non-side-effecting} says that
creating and then deleting a uniform random value does nothing.

All this is just the local structure. To implement the one-time pad, we need
two shared resources. First, $A$ and $B$ should have a shared random key drawn
from $M$. In $\scat{CompStoch}$, this is the map $I\to M\otimes M\otimes I$
which draws uniformly at random from the set $\{(k, k, *): k\in M\}$.
Diagramatically, we can build this map as \[
  \begin{pic}
    \node[state, scale=.75] (rand) at (0, 0) {\normalsize\$} node[right, xshift=8mm, yshift=1mm] {\normalsize,};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]where we now label the wires with the party in possession of the data, so that
for instance a wire labeled $A$ is an element of $M\otimes I\otimes I$, while
the two parallel wires labeled $A$ and $B$ denote an element of $M\otimes
M\otimes I$. This is a map in $\cat{C}$ which cannot be written in $\cat{C}^3$,
because it does not factor into a product of three separate maps in $\cat{C}$.

We also need a way for $A$ to send the encoded message to $B$ and $E$. In
\scat{CompStoch}, this is the map $M\otimes I\otimes I\to I\otimes M\otimes M$
given by $(c, *, *)\mapsto (*, c, c)$. Again, this can be represented using the
structure defined above, as the map \[
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$} node[right, xshift=5mm,
    yshift=1mm] {\normalsize.};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\]It is a good exercise in string diagram comprehension to spell out this map
symbolically. Assuming we chose to left-associate the functor $\otimes^2$ in the
definition of $\prot{3}{\cat{C}}$, one way to write it is as the map \[
  (M\otimes I)\otimes I\xto{\rho^{-1}_{M\otimes I}} M\otimes I
  \xto{\gamma_{M,I}} I\otimes M\xto{1_I\otimes
  \text{copy}} I\otimes (M\otimes M)\xto{\alpha^{-1}_{I,M,M}} (I\otimes
    M)\otimes M.
\]The magic of the coherence theorem is that, once we agree on a choice of
associativity, any way of writing this map is the same, and so we can work with
the far simpler diagrammatic notation.

From all this, we learn that the domain of the one-time pad should be the object
\begin{equation}\label{eqn:otp-domain}
  \begin{pic}
    \node[state] (rand) at (0, 0) {\normalsize\$};
    \node[dot, fill=white] (copy) at (0, .5) {};
    \draw (rand) to (copy);
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$A$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
  \otimes
  \begin{pic}
    \node[dot, fill=white] (copy) at (0,0) {};
    \draw (copy) to ++(0, -.7) node[left] {$A$};
    \draw (copy) to[out=180, in=-90] ++(-.5, .5) to ++(0, .2) node[left] {$E$};
    \draw (copy) to[out=0, in=-90] ++(.5, .5) to ++(0, .2) node[right] {$B$};
  \end{pic}
\end{equation} of $\prot{3}{\cat{C}}$. The goal of the one-time pad is to produce a channel
from $A$ to $B$, so the codomain should be the object \begin{equation}\label{eqn:otp-codomain}
  \begin{pic}
    \draw (0, 0) node[left] {$A$} node[right, xshift=3mm, yshift=1mm] {\normalsize.} to ++(0, 1) node[left] {$B$};
  \end{pic}
\end{equation}
The reader may now object that the one-time pad does not give the eavesdropped
no information, as they learn that a message was sent. However, we are not yet
attempting to deal with adversarial behavior, so any protocol can simply have
Eve forget that information. We will discuss this issue at length in
\Cref{sec:security}.

For a second, let us not worry about preserving states, and just think in the
category $\ncomb{\cat{C}}$. Recall that the objects in this category are finite
lists of pairs of objects in $\cat{C}$. The domain of the one-time pad should be \[
  [(I\otimes I\otimes I, M\otimes M\otimes I), (M\otimes I\otimes I,
  I\otimes M\otimes M)],
\] while the codomain should be \[
  [(M\otimes I\otimes I, I\otimes M\otimes I)].
\]
A morphism between these should be a 2-comb which takes morphisms of the domain
types and produces a morphism of the codomain type. In other words, given two
``black box'' maps \[
  \begin{pic}
    \node[dashedstate] (rand) at (0, 0) {};
    \draw (rand.north west) to ++(0, .5) node[left] {$A$};
    \draw (rand.north east) to ++(0, .5) node[right] {$B$};
  \end{pic}\quad\text{and}\quad
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .5) node[left] {$E$};
    \draw (send.north east) to ++(0, .5) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
  \end{pic},
\]the 2-comb must produce a map \[
  \begin{pic}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.south) to ++(0, -.5) node[left] {$A$} node[right, xshift=3mm,
    yshift=1mm] {\normalsize.};
    \draw (send.north) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]
The easiest such 2-comb to write, \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[dashedmorphism] (send) at (0, 0) {};
    \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (send.north east) to ++(0, .7) node[right] {$B$};
    \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to ++(0, .3) node[dot, fill=white] {};
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} to ++(0, .3) node[dot, fill=white] {};
  \end{pic},
\]
represents simply sending the message unencrypted, without use of the key. Note
that the theory does require us to explicitly forget the key, as n-combs must consume
all their input resources. We will alleviate this requirement soon.

Now the schema for the one-time pad is the 2-comb \[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    % \node[morphism] (send) at (0, 0) {};
    % \draw (send.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    % \draw (send.north east) to ++(0, .7) node[right] {$B$};
    % \draw (send.south) to ++(0, -.5) node[left] {$A$};
    \node[dashedstate] (rand) at (1.5, 0) {};
    \node[dot, fill=black] (mult) at (.5, 1) {};
    \node[dashedmorphism] (copy) at (.5, 2) {};
    \draw (copy.north west) to ++(0, .2) node[left] {$E$} to ++(0, .3) node[dot, fill=white] {};
    \draw (mult) to (copy.south) node[yshift=-3mm, left] {$A$};
    \draw (-.3, -1) node[left] {$A$} to (-.3, .2) to [out=90, in=180] (mult);
    \draw (rand.north west) to ++(0, .2) node[left] {$A$} to[out=90, in=0] (mult);
    \draw (rand.north east) to ++(0, .2) node[right] {$B$} node[right, yshift=-3mm,
    xshift=5mm] {\normalsize.} to ++(0, .7) node[dot,
    fill=black] {} to ++(0, .4) node[right] {$B$} to ++(0, 1.1) to[in=0,out=90] ++(-.5, .5) node[dot, fill=black] (f) {};
    \draw (copy.north east) to ++(0, .2) node[right] {$B$} to[out=90,in=180] (f);
    \draw (f) to ++(0, .5) node[left] {$B$};
  \end{pic}
\]

This is a morphism in $\ncomb{\cat{C}}$. To check that this protocol is correct,
we need to check that it sends the state \eqref{eqn:otp-domain} to
the state \eqref{eqn:otp-codomain}, i.e. that it is a morphism with
the right type in $\prot{3}{\cat{C}}$.



While \cite{broadbent-karvonen-2022} choose to label the wires with the
identities of the parties in possession of that data, we worry that this
approach does not easily scale to protocols where multiple objects are relevant.
We prefer an approach using the shaded boxes of \Cref{sec:monoidal-functors}. 

\section{Security}
\label{sec:security}

%
% In the title of the section, we called this a category of \emph{linear} process
% conversions. This is because each input resource is used exactly once in the
% list of n-combs.

% % TODO: proof?
% % \begin{proof}
% %   Associativity and unitality come directly from the axioms of a multicategory.

% %   Functorality of the monoidal product is 
% % \end{proof}
% % \section{Resource Theories}

% \subsection{Process Conversions}

% \section{Paths Not Taken}

% - functorality
% - internalization of owf/indistinguishability/etc
