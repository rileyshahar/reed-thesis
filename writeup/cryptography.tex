[TODO: An introduction to the chapter;
cite~\cite{katz-lindell-2014, pass-shelat-2020, rosulek-2021}.]

\section{Foundations}

\subsection{One-Way Functions}

Many cryptographic protocols rely on \emph{one-way functions}, which are
informally functions that are easy to compute, but hard to invert. The former
notion is easy to formalize in terms of time complexity, but the latter is more
difficult. We typically ask that any ``reasonably efficient'' algorithm---called
the \emph{adversary}---attempting to invert the function has a negligible chance
of success.

In computer science, we generally assume that algorithms are efficient if and
only if they are polynomial-time; this assumption has been borne out by decades
of practice. This motivates our definition of a ``negligible'' chance: we say
that a function $f$ is \emph{negligible} if $f(n) = o(n^{-k})$
for every $k$; in other words, if it is asymptotically smaller than any rational
function. In this case, we write $f = \negl$ or just $f = \negl[]$.) The set
of negligible functions has all the nice closure properties we expect; in
particular, the sum of negligible functions is negligible.

% The difficulty is in determining which adversaries are ``reasonable''. We
% generally ask that adversaries are non-uniform probabilistic polynomial-time
% algorithms. The non-uniformity primarily serves to simplify proofs, by allowing
% us to not worry about the size of the adversary.

\begin{ntn}
  We will use PPT as shorthand for probabilistic polynomial-time. When we refer
  to an \emph{adversary}, \emph{distinguisher}, or \emph{simulator}, we always
  mean a non-uniform PPT algorithm.
\end{ntn}

\begin{dfn}[one-way function]\label{def:one-way function}
  A function $f$ is \emph{one-way} if:
  \begin{itemize}
    \item (easy to compute) $f$ is PPT-computable;
    \item (hard to invert) for any adversary $\cA$, natural number $n$, and
      uniform random choice of input $x$ such that $|x| = n$, \[
        \Pr[f(\cA(1^n, f(x))) = f(x)] = \negl.
      \]
  \end{itemize}
  Note that $|x|$ here is \emph{not} the absolute value, but is instead the
  length of $x$ as a binary string: if $x$ is a number, then by encoding in
  binary have that $|x| = \Theta(\log_2 x)$.
\end{dfn}

The idea is that, given $y = f(x)$, $\cA$ attempts to find some $x'$ such that
$f(x') = y$. If some adversary can do this with non-negligible probability, then the
function is not one-way. While the probability must be negligible in $|x|$, the
adversary is given $f(x)$ and $1^n$ as an input, and hence must run polynomially
only in $|f(x)| + n$. This is a common technique called \emph{padding}, wherein
algorithms are given an extra input of $1^n$ to ensure they have enough time to
run.

We do not know that one-way functions exist. In fact, while the existence of
one-way functions implies that P $\neq$ NP, the converse is not
known\footnote{\cite{impagliazzo-1995} gives a classic discussion of the
  implications of various resolutions to P vs. NP on cryptography, including the
case where P $\neq$ NP but one-way functions nevertheless do not exist.}.
However, as in the following examples, we have excellent candidates under fairly
modest assumptions.

\begin{ex}[Factoring {\cite[subsection 2.3]{pass-shelat-2020}}]
  Suppose that for any adversary $\cA$ and for uniform random choice of primes
  $p,q<2^n$, \[
    \Pr[\cA(pq) = \{p, q\}] = \negl[n].
  \] This is the \emph{factoring hardness assumption}, for which there is
  substantial evidence. Then $(x,y)\mapsto xy$ is one-way\footnote{This
    statement is slightly imprecise: technically, $(x,y)\mapsto xy$ is \emph{weakly
    one-way}; to get the stronger notion of~\Cref{def:one-way function}
    requires a process called \emph{hardness
    amplification}. See~\cite[Section 2.4]{pass-shelat-2020}
for details.}.
\end{ex}

\begin{ex}[Discrete Logarithm {\cite[subsection 8.3.2]{katz-lindell-2014}}]
  Let $\{G_n\}$ be a fixed sequence of finite groups. The \emph{discrete logarithm hardness assumption}
  for $\{G_n\}$ is that, for any adversary $\cA$ and for uniform random choice of
  $g\in G_n$ and $h\in\<g\>$ such that $h = g^k$, \[
    \Pr[\cA(g,h) = k] = \negl[n].
  \]
  Under the discrete logarithm hardness assumption, $(g,k)\mapsto g^k$ is one-way.

  The discrete logarithm hardness assumption is known to be false for certain groups, such
  as the additive groups $\ZZ_p$ for prime $p$, in which case $g^k = gk$ and the
  Euclidean algorithm solves the problem. However, it is believed to hold for
  groups such as $\ZZ^*_p$. For a survey of various versions of this assumption,
  see~\cite{sadeghi-steinerr-2002}.
\end{ex}

\subsection{Proofs by Reduction}

Many cryptographic definitions, including \Cref{def:one-way function},
take the form \begin{quote}\emph{for any adversary $\cA$, natural number $n$, and uniform
random choice of input $x$ such that $|x| = n$, some predicate on the output
of $\cA$ has negligible probability.}\end{quote} The basic technique for proving results
using these definitions is called \emph{proof by reduction}. The idea is to
reduce one problem into another by starting with an arbitrary adversary
attacking the second and constructing an adversary attacking the first,
such that the probability of their successes is related. If we assume the first
problem is hard, then by studying the structure of the reduction we can learn
about the hardness of the second problem. As such, we often say that reductions
prove \emph{relative hardness results}, so that for instance \Cref{ex:reduction}
below proves the hardness of $g$ relative to $f$.


More specifically, to prove hardness of a problem $\Pi$ relative to $\Pi'$, a
proof by reduction generally goes as follows:
\begin{enumerate}
  \item Fix an arbitrary adversary $\cA$ attacking a problem $\Pi$.
  \item Construct an adversary $\cA'$ attacking a problem $\Pi'$ which:
    \begin{enumerate}
      \item Receives an input $x'$ to $\Pi'$.
      \item Translates $x'$ into an input $x$ to $\Pi$.
      \item Simulates $\cA(x)$, getting back an output $y$ which solves
        $\Pi(x)$.
      \item Translates $y$ into an output $y'$ which solve $\Pi(x')$.
    \end{enumerate}
  \item Analyze the structure of the translations to conclude that $\cA'$ solves
    $\Pi'$ with probability related to that with which $\cA$ solves $\Pi$.
  \item Given the hardness assumptions on $\Pi'$, conclude relative hardness of
    $\Pi$.
\end{enumerate}

The point is that $\cA'$'s job is to ``simulate'' the problem $\Pi$ to $\cA$,
using the data it gets from $\Pi'$ to construct an input to $\Pi$. We illustrate
this concept now.

\begin{ex}[a straightforward proof by reduction {\cite[subsection
  2.4.1]{pass-shelat-2020}}]\label{ex:reduction} Let $f$ be a one-way function. Then we claim $g:
  (x,y)\mapsto (f(x), f(y))$ is a one-way function. We can compute $g$ in
  polynomial time by computing $f$ twice, so it remains to show that $g$ is hard
  to invert.

  Let $\cA$ be any adversary. We will construct an adversary $\cA'$ such
  that, if $\cA$ can non-negligibly invert $g$, then $\cA'$ can non-negligibly
  invert $f$.

  The adversary $\cA'$ takes input $1^n$ and $y$. It then uniformly randomly
  chooses $u$ of length $n$ and computes $v = f(u)$, which is possible because $f$ is easy to
  compute. Now $\cA'$ computes $(u', x') := \cA(1^{2n}, (v,y))$ and outputs
  $x'$.

  When $\cA'$ simulates $\cA$, it passes $v$, which is $f(u)$ for a uniform
  random $u$, and $y$, which is (on well-formed inputs) $f(x)$ for a uniform
  random $x$. Thus, this looks like exactly the input that $\cA$ would
  ``expect'' to receive if it is attempting to break $g$. As such, whenever
  $\cA$ successfully inverts $g$, $\cA'$ successfully inverts $f$. Since
  everything is uniform we may pass to probabilities, and so: \begin{align*}
    \Pr &[g(\cA(1^{2n}, g(u, x))) = g(u, x)] \\
        &= \Pr[g(\cA(1^{2n}, (f(u), f(x)))) = (f(u), f(x))] &&\text{by definition of $g$}  \\
        &\leq \Pr[f(\cA'(1^n, f(x))) = f(x)] &&\text{by the above argument} \\
        &= \negl &&\text{by the hardness assumption for $f$}.
     \end{align*}

   Thus $g$ is one-way.
\end{ex}

Comparing this example to the above schema, we see that the problem $\Pi'$ is to
invert $f$, while the problem $\Pi$ is to invert $g$. The input $x'$ to $\Pi'$
is $y$, while the computed input $x$ to $\Pi$ is $(v, y)$. The output $y$ of
$\cA$ is $(x', u')$, while the computed output $y'$ is $x'$.

Diagramatically, we can represent the algorithm $\cA'$ as follows:
\[
  \begin{pic}
    \setlength\minimummorphismwidth{6mm}
    \node[morphism] (A) at (0,0) {$\cA$};
    \draw ([xshift=-2.5pt]A.south west) to ++(0,-1.5) node[left] {$y$};
    \draw ([xshift=-2.5pt]A.north west) to ++(0,1.05) node[left] {$x'$};
		\draw ([xshift=2.5pt]A.south east) to ++(0,-.5) node[state,scale=0.75] {\normalsize$\$$};
    \draw ([xshift=2.5pt]A.north east) to ++(0,.5) node[right] {};
    \draw[dotted] (-.8, -1.5) rectangle (.9, 1);
    \node at (1.2, -1.3) {$\cA'$\punctuation{.}};
  \end{pic}
\]

While this is not standard notation in cryptography, it will be useful for our future purposes.
We read these diagrams---called \emph{circuit} or \emph{string diagrams}---from
bottom to top. This diagram says that $\cA'$ is an algorithm which takes $y$,
uniformly randomly generates another input (this is what the $\$$ means), calls
$\cA$, and returns its first output.

\subsection{Computational Indistinguishability}

Computational indistinguishability formalizes the notion of two probability
distributions which ``look the same'' to adversarial processes. We begin with
probability distributions, but because we want to do asymptotic analysis, we
will eventually need to switch to working with sequences of probability
distributions.

\begin{dfn}[computational advantage]\label{def:computational advantage}
  Let $X$ and $Y$ be probability distributions. The \emph{computational
  advantage} of an adversary $\cD$, called the
  \emph{distinguisher}, over $X$ and $Y$ is \[
    \ca_\cD(X, Y) = \left|\Pr_{x\from X}[\cD(x) = 1] - \Pr_{y\from Y}[\cD(y) = 1]\right|.
  \]
\end{dfn}

The idea is that the distinguisher $\cD$ is trying to guess whether its input
was drawn from $X$ or $Y$; the computational advantage is how often it can do
so.

\begin{prop}\label{thm:advantage is metric}
  Let $\cD$ be a fixed distinguisher. Then $\ca_\cD$ is a
  pseudometric\footnote{
    A \emph{pseudometric} on a space $X$ is a function $d: X\times X\to\RR_{\geq 0}$ which
    is zero on identical points, symmetric, and satisfies the triangle
    inequality; in other words, it is a metric which does not necessarily
    differentiate distinct points.
  } on the
  space of probability distributions over an underlying set $A$.
\end{prop}

\begin{proof}
  Symmetry and non-negativity are immediate from the definition, while the
  triangle inequality follows from the triangle inequality for real numbers.
\end{proof}

We now turn to the asymptotic case.

\begin{dfn}[probability ensemble]\label{def:probability ensemble}
  A \emph{probability ensemble} is a sequence $\{X_n\}$ of probability
  distributions.
\end{dfn}

We say that two ensembles are computationally indistinguishable if there is no
efficient way to tell between them. Formally:

\begin{dfn}[computational indistinguishability]\label{def:computational indistinguishability}
  Two probability ensembles $\{X_n\}$ and $\{Y_n\}$ are \emph{computationally
  indistinguishable} if for any (non-uniform PPT) distinguisher $\cD$ and any
  natural number $n$,
  \[
    \ca_\cD(X_n, Y_n) = \negl.
  \]
  In this case, we write $\{X_n\}\cind\{Y_n\}$.
\end{dfn}

\begin{rmk}
  A natural thought is to define a metric on probability distributions by
  \[
    \ca(X, Y) = \sup_{\cD}\ca_\cD(X, Y),
  \] and extend to ensembles by asking
  that $\ca(X_n, Y_n) = \negl$. Unfortunately, this does not quite yield the
  correct notion, as there exist ensembles which are computationally
  indistinguishable, but have sequences of distinguishers whose advantages for
  any fixed $n$ converge to $1$.
\end{rmk}

\begin{prop}
  Computational indistinguishability is an equivalence relation on the space of
  probability ensembles over a fixed set $A$.
\end{prop}

\begin{proof}
  Reflexivity and symmetry follow from the case of distributions. To show
  transitivity, let $\{X_n\} \cind \{Y_n\}$ and $\{Y_n\} \cind \{Z_n\}$. Let
  $\cD$ be any distinguisher. Then for any $n$, \begin{align*}
    \ca_\cD(X_n, Z_n) &\leq \ca_\cD(X_n, Y_n) + \ca_\cD(Y_n, Z_n) &&\text{by the triangle inequality} \\
                        &= \negl + \negl &&\text{by assumption} \\
                        &= \negl. &&\qedhere
  \end{align*}
\end{proof}

It is necessary to be precise about what is being claimed here. Transitivity
states that for any \emph{constant, finite sequence} of probability ensembles,
if each is computationally indistinguishable from its neighbors, then the two
ends of the sequence are computationally indistinguishable. In cryptography, we
sometimes want to consider the more general case of a countable sequence of
probability ensembles. We can do slightly better than the previous result:

\begin{prop}
  Let $\{X^k\}$ be a sequence of probability ensembles, so
  that each $X^k = \{X^k_n\}$ is itself a sequence of probability distributions.
  Let $\{X^i\}\cind\{X^{i+1}\}$ for each $i$. Let $\{Y_n = X^{K(n)}_n\}$ for
  some polynomial $K$. Then $\{X^1_n\}\cind\{Y_n\}$.
\end{prop}

\begin{proof}
  Let $\cD$ be any distinguisher. Then for any $n$, \begin{align*}
    \ca_\cD(X^1_n, Y_n) &= \ca_\cD(X^1_n, X^{K(n)}_n) \\
                          &\leq \ca_\cD(X^1_n, X^2_n) + \cdots + \ca_\cD(X^{K(n) - 1}_n, X^{K(n)}_n) \\
                          &= K(n)\negl \\
                          &= \negl.
   \end{align*}
   In particular, the last equality follows because $K$ is polynomial.
\end{proof}

On the other hand, the result does not hold for arbitrary $K$. As we will see,
this is a fundamental limitation for cryptographic composition: we only expect
composition to work up to polynomial bounds.

One more closure result is valuable:

\begin{prop}\label{thm:ci-composition}
  Let $\{X_n\}\cind\{Y_n\}$, and let $\cM$ be a non-uniform PPT algorithm. Then
  $\{\cM(X_n)\} \cind \{\cM(Y_n)\}$.
\end{prop}

\begin{proof}
  The proof is by reduction. Let $\cD$ be a distinguisher. Then construct $\cD'$
  which, on input $x$, simulates $\cD(\cM(x))$. Then $\cD'$ outputs $1$ on $x$ if and
  only if $\cD$ outputs $1$ on $\cM(x)$, so \[
    \ca_\cD(\cM(X_n), \cM(Y_n)) = \ca_{\cD'}(X_n, Y_n) = \negl
  \] by the computational indistinguishability assumption.
\end{proof}

\begin{ex}[pseudorandom generators~{\cite[Sections 3.2-3.3]{pass-shelat-2020}}]\label{ex:pseudorandomness}
  We can use computational indistinguishability to formalize the notion of
  pseudorandomness.

  Let $\{\cX_n\}$ be a sequence of spaces, and let $\{X_n\}$ be a sequence of
  probability distributions. We say that $\{X_n\}$ is \emph{pseudorandom for
  $\cX$} if there exists a polynomial $p$ such that \[
    \{X_n\} \cind \{\cX_{p(n)}\},
  \]where the latter is equipped with the uniform distribution. In other words,
  pseudorandom ensembles look uniformly random to distinguishers.

  For simplicity, we now work over $\cX_n = \ZZ_2^n$. Let $G:
  \ZZ_2^*\to\ZZ_2^*$ be a \emph{deterministic} function. We say $G$
  is a \emph{pseudorandom generator} if \begin{itemize}
    \item $G$ is polynomial-time computable;
    \item for any $x$, $|G(x)| > |x|$;
    \item $\{G(\ZZ_2^n)\}$ is pseudorandom.
  \end{itemize}
  The idea is that $G$ gets some input $x\in\ZZ_2^n$ and produces an output in
  $\ZZ_2^{p(n)}$ which looks uniformly random to distinguishers if $x$ is chosen
  uniformly at random. The polynomial $p(n)$ in the definition of
  pseudorandomness is now called the \emph{expansion factor}. It this sense, pseudorandom generators allow us to
  ``bootstrap'' randomness from random draws even on very small inputs.

  As usual, while we have excellent candidates, we have no proof that
  pseudorandom generators exist. However, there is a known procedure, due
  to \citeauthor{hastad-1999}~\cite{hastad-1999}, to turn any one-way function
  into a pseudorandom generator.
\end{ex}

\subsection{Interactive and Zero-Knowledge Computation}
\label{sec:interactive computation}
\label{sec:zero-knowledge}

Cryptographic protocols do not occur in a vacuum; instead, they rely on
computations involving multiple parties. We call such situations \emph{interactive
computations}. In general, a model of interaction depends on
the underlying model of computation; this is for instance the case with the
popular notion of interactive Turing machines~\cite[Definition
4.2.1]{goldreich-2001}. As our approach in this chapter has been
model-independent, we can only give an informal discussion of interaction.

An \emph{interactive computation} consists of a finite number of \emph{parties},
which we think of as algorithms $\cA_i$, who may potentially communicate by
sending messages to each other, and whose behavior may change in response to
messages they receive. An \emph{interactive protocol}
just consists of descriptions of some interactive algorithms $\<\cA_1, \dots,
\cA_N\>$.

We often think of interactive computations as being indexed by a \emph{security
parameter} $n\in\NN$. Instead of asking each algorithm to be polynomial-time in
its inputs, we ask it to be polynomial in $n$, with the stipulation that the
inputs themselves are no more than polynomial in $n$, so that each algorithm has
time to read its own inputs. Intuitively, the security parameter represents a
``tuning'' of the security of the system, so that a bigger $n$ incurs greater
computational cost but gives stronger security guarantees. Often, the security
parameter is formalized by ensuring that all parties get an extra input of $1^n$ at
the start of the computation, as we did in~\Cref{def:one-way function};
we assume this formalization in every protocol we give here.

At the start of an interactive computation, there is a \emph{global input} $x$
known to all parties, and each party $\cA_i$ may have a \emph{private} or
\emph{auxiliary input} $x_i$ known only to itself. We generally assume that
there are known sequences of \emph{input spaces} $\cX_n$ and $\cX^i_n$, such that
when the security parameter is $n$, $x\in \cX_n$ and $x_i\in \cX^i_n$. At the end of
the computation, each party may make some output, the sequence of which we
denote $\<\cA_1, \dots, \cA_N\>(x, x_1, \dots, x_N)$, so that party $i$'s output
is $\<\cA_1, \dots, \cA_N\>(x, x_1, \dots, x_N)_i$. When any of these algorithms
are potentially probabilistic, we think of this value as a distribution over
possible outputs, and we always assume that the internal randomness of the
parties is independent.

\begin{ex}\label{ex:swap}
  Here is a simple interactive protocol. We have two algorithms, $\cA$ and
  $\cB$. The input spaces are $\cX^\cA_n$ and $\cX^\cB_n$; there is no global
  input (which means the global input is just the security parameter $1^n$.) The
  algorithm $\cA$ takes its input $x\in\cX^\cA_n$, sends it to $\cB$, and outputs
  the first message it recieves from $\cB$. The algorithm $\cB$ takes its input
  $y\in\cX_n^\cB$, sends it to $\cA$, and outputs the first message it recieves
  from $\cA$. Then we have that $
    \<\cA,\cB\>(x,y) = (y,x).
  $
\end{ex}

The \emph{view} of a party is roughly all of the information it has available to
it over the course of the computation. This includes the global input, its
private input, any random bits it uses, and all the messages it receives. We
denote the view of party $i$ by $\view_i^{\<\cA_1, \dots, \cA_N\>}(x, x_1,
\dots, x_N)$. When the algorithms are clear from context, we may omit the
superscript. Importantly, while each private input $x_k$ is a parameter of each
view $\view_i$, the view does not necessarily include each of these inputs; they
are parameters merely because they may affect the messages received by party
$i$.

\begin{ex}
  In the protocol of \Cref{ex:swap}, \[
    \view_\cA^{\<\cA, \cB\>}(1^n, x, y) = \view_\cB^{\<\cA, \cB\>}(1^n, x, y) = \{1^n, x, y\}.
  \]
  Suppose that $\cB'$ always sends the string $0^n$ to $\cA$, instead of its input. Then \[
    \view_\cA^{\<\cA, \cB'\>}(1^n, x, y) = \{1^n, x, 0\},\quad\quad \view_{\cB'}^{\<\cA, \cB'\>}(1^n, x, y) = \{1^n, x, y\}.
  \]
  Notice that $\view_{\cB'}$ does not include the messages which it sends $\cA$.
\end{ex}

% There may be limitations on these messages: for instance,
% it may only be possible to send messages broadcasted to all the parties, or it
% may be possible to send ``private'' party-to-party messages. When necessary, we
% will always be clear about our assumptions here. 

The \emph{running time} of an interactive algorithm $\cA$ is now the function
$T_\cA: \NN\to\NN$ which, for any $n$, gives the maximum number of ``steps'' it
takes $\cA$ to halt over any choice of:
\begin{itemize}
  \item global input $x$ and private input $y$ of total length $n = |x| + |y|$;
  \item other algorithms involved in the computation;
  \item internal randomness of $\cA$ and of any other algorithms involved in the computation.
\end{itemize}
Essentially, when we say an algorithm is polynomial-time, we mean it is
\emph{always} polynomial-time, no matter what. We sometimes assume that each
algorithm has a ``clock'' that it uses to count the number of steps it has taken
and ensure it halts in some fixed polynomial number of steps.

We can now formalize the idea of a party ``learning something'' from an
interaction. We say that an interactive protocol $\<\cA_1, \dots, \cA_N\>$ is
\emph{zero-knowledge for party $i$} if there exists a non-uniform PPT algorithm
$\cS$ such that for any choice of inputs $(x, x_1, \dots, x_N)$, \[
  \cS(x, x_i) \cind \view_i^{\<\cA_1, \dots, \cA_N\>}(x, x_1, \dots, x_N).
\]
The idea is that the ``simulator'' $\cS$ gets only the inputs to $\cA_i$ and is
responsible for producing a distribution that is indistinguishable from the
actual view of $\cA_i$. If they can do this, then $\cA_i$ must not have learned
anything that they could not have computed directly from their inputs.

More often, we want to consider the situation where $\cA_i$ is supposed to learn
\emph{something} from the computation, but should not learn anything
\emph{extra}.

\begin{dfn}[zero-knowledge]\label{def:zero-knowledge}
  Let $f$ be a function. An interactive protocol $\<\cA_1, \dots, \cA_n\>$ is
  \emph{zero-knowledge for party $i$ relative to $f$} if there exists a
  (non-uniform PPT) simulator $\cS$ such that for any choice of
  inputs $(x, x_1, \dots, x_N)$, \[
  \cS(x, x_i, f(x, x_1, \dots, x_N)) \cind \view_i^{\<\cA_1, \dots, \cA_N\>}(x, x_1, \dots, x_N).
\]
\end{dfn}

In the above definition, we are asking that the simulator produces a
distribution which is negligibly close, in the sense of computational
indistinguishability, to the actual view. While this is all that is possible in
many situations in practice, we could ask for the stronger condition that the
produced distribution is \emph{identical} to the view. We call this notion
\emph{perfect} or \emph{information-theoretic} zero-knowledge, and refer to
\Cref{def:zero-knowledge} as
\emph{computational} zero-knowledge when we wish to emphasize the distinction.

\begin{ex}\label{ex:trivial-protocol}
  We show that the \emph{trivial protocol}, in which two algorithms $\cA$ and
  $\cB$ do nothing, is zero-knowledge for $\cB$. Our goal is to give a
  simulator $\cS$ such that for any choice of security parameter $n$,
  \[
    \cS(1^n) \cind \view_\cB^{\<\cA, \cB\>}(1^n).
  \] Since $\cB$ never gets sent any messages, its view is just the input
  $1^n$. We therefore let $\cS$ compute the identity, so that the two
  distributions are both constantly $\{1^n\}$. This shows that the trivial
  protocol is perfect zero-knowledge.
\end{ex}

\begin{ex}\label{ex:non-zero-knowledge}
  Consider the following protocol: $\cA$ gets input $x\in\ZZ_2^n$, which it
  then sends to $\cB$. To show this is not zero knowledge for $\cB$, we must
  show that for any simulator $\cS$, there exists a choice of input $x$ and a
  distinguisher $\cD$ which distinguishes $\cS(1^n)$ from $\view_\cB(1^n, x) =
  \{1^n, x\}$ with non-negligible probability.

  Let $\cS$ be fixed. If $\cS$ does anything other than outputting $1^n$ and
  some $y\in\ZZ_2^n$, then we will be able to distinguish it syntactically.
  We may therefore safely assume that $\cS$ outputs $(1^n, y)$ for some
  (potentially random) choice of $y$. For each $n$, now choose $x$ such that
  $\Pr[y = x]\leq 2^{-n}$, which is possible by the pigeonhole principle. Let
  $\cD$ output $1$ on input $\{1^n, x\}$, and $0$ otherwise. Then \[
    \Pr[\cD(\cS(1^n)) = 1] = \Pr[y = x] \leq 2^{-n},
  \] while \[
    \Pr[\cD(\view_\cB(1^n, x)) = 1] = 1.
  \] Since $|1 - 2^{-n}|$ is not negligible, the protocol is not
  zero-knowledge for $\cB$.
\end{ex}

\subsection{Adversaries and the Real-Ideal Paradigm}
\label{sec:real-ideal}

Zero-knowledge is a surprisingly general tool for formalizing security
definitions, but in some cases it is not enough. For instance, we may want to
verify that protocols for electronic coin-flips are fair: in this case, the
issue is not that the parties may learn something extra, but that they may be
able to unduly influence the outcome of the computation. The general approach
taken in the literature is to define security on an ad-hoc basis for each such
task by enumerating the properties we want the protocol to have and formalizing
them as adversarial games. We will take a more systematic approach, sometimes
called the \emph{real-ideal paradigm}.

The idea is to define an \emph{ideal protocol}---also called an \emph{ideal
functionality}---which represents the desired behavior of the cryptosystem. The
protocol under study---the \emph{real protcol}---is then supposed to emulate the
ideal protocol, in the sense that its outcomes should be computationally
indistinguishable from the outcomes of the ideal protocol. The subtelty here is
our use of the term \emph{outcome}; which necessarily looks different for
different protocols: it may just be the information learned by a party, in which
case we recover zero-knowledge, it may be some function of the party's outputs,
or it may be something else altogether. We will see several different examples
of this in \Cref{sec:crypto-problems}, but the important point is that to define
security in this paradigm requires both a definition of the ideal protocol and
of the data to be compared.

Unlike in the case of zero-knowledge, where we only cared about what parties
could learn from the protocol assuming it was executed correctly, in this
setting we also want to discuss security against \emph{malicious behavior}, in
which one or more parties deliberately try to sabotage the outcome of the
protocol. We often refer to these parties as the \emph{adversaries}, and allow
them to be non-uniform even when ordinary parties in the protocol are uniform.
Since a protocol is not secure if even one possible attack is likely to succeed,
we say that a protocol is \emph{secure in the presence of malicious adversaries}
if for any choice of algorithms taking over some fixed number of parties, the
outcomes of the protocol are indistinguishable from the ideal. Again, we will
see examples of this notion in the next section.

In contrast, sometimes we do want to talk about a protocol being zero-knowledge
without dealing with arbitrary adversarial behavior. In this case, we use the
term \emph{semi-honest adversaries}, which informally refers to adversaries
which follow the prescriptions of the protocol, but attempt to learn as much as
they can within those bounds. There are several other notions of adversarial
strength considered in the literature---for instance, adaptive vs. static
adversaries~\cite{cramer-et-al-1999}, Byzantine
adversaries~\cite{lindell-et-al-2002}, and ``coercible''
parties~\cite{canetti-et-al-2015}. We do not explore all these models here.

\section{Cryptographic Problems}
\label{sec:crypto-problems}

\subsection{Encryption}

Much of the machinery defined in the previous section was originally developed
in the 1970s and 80s for the purpose of analyzing \emph{encryption problems},
culminating in the work of
\citeauthor{goldwasser-micali-1982}~\cite{goldwasser-micali-1982}. The idea of
an encryption problem is that a party Alice has a message $m$ in the
\emph{message space} $\cM_n$ which they want to send to Bob, but any message
they send to Bob must also be sent to the eavesdropping Eve. In the simpler
\emph{shared-key encryption problem}, which we consider here, Alice and Bob
share some secret key $k$ from the \emph{key space $\cK_n$}, which is unknown to
Eve.

% In this case, the problem reduces to a choice of three probabilistic
% polynomial-time algorithms\footnote{Here, as is general practice, we omit the
% dependence of the message and key spaces on the security parameter $n$.}:\begin{itemize}
%   \item $\alg{Gen}$, which takes as input a security parameter $1^n$ and
%     outputs a key $k\in\cK$;
%   \item $\alg{Enc}$, which takes as input a security parameter $1^n$, a key
%     $k\in\cK$, and a message $m\in\cM$, and outputs a ciphertext $c\in\cM$;
%   \item $\alg{Dec}$, which takes as input a security parameter $1^n$, a key
%     $k\in\cK$, and a ciphertext $c\in\cM$, and outputs a message $m\in\cM$.
% \end{itemize}

% An encryption scheme is \emph{correct} if for any choice of $m$ and $k$ output
% by $\alg{Gen}(1^n)$, \[
%   \alg{Dec}(1^n, k, \alg{Enc}(1^n, k, m)) = m.
% \]

% It is not hard to show that we may assume that $\alg{Gen}$ outputs a key chosen
% uniformly at random from $\cK$. As a result, and now using the language
% of~\Cref{sec:interactive computation}, we
% say that:

\begin{dfn}[shared-key encryption scheme]
Let $\{\cM_n\}$ and $\{\cK_n\}$ be sequences of sets. An $(\cM, \cK)$-shared-key
encryption scheme is an interactive protocol consisting of three interactive
algorithms $\cA$, $\cB$, and $\cE$, where:
\begin{itemize}
  \item the global input is $1^n$, the security parameter;
  \item $\cA$ gets a uniform random key $k\in\cK_n$ and a message $m\in\cM_n$ as private input;
  \item $\cB$ gets the same\footnote{
    Notice that this definition includes the stipulation that $\cA$ and $\cB$ share a
    uniform random key as input, which is not directly possible using the machinery
    of~\Cref{sec:interactive computation}.
    One way to formalize this notion is to add a fourth machine $\cG$ (the
    ``generator''), which can message $\cA$ and $\cB$ freely (but not recieve
    messages from them), whose job is to generate the key and send it to both
    parties. For our purposes, the important point is that while the input $m$
    is seen as a parameter of the system which can be controlled in
    indistinguishability proofs, the input $k$ is instead always randomly
    generated.
    } key $k$ as private input;
  \item $\cE$ gets no private input;
  \item $\cA$ and $\cB$ only send messages to each other if they also send the
    message to $\cE$.
\end{itemize}

A shared-key encryption scheme is \emph{correct} if $\cB$ outputs $m$ at the
end of the computation. A shared-key encryption scheme is \emph{secure} if it
is zero-knowledge for $\cE$; explicitly, if there exists a simulator $\cS$
such that for any choice of security parameter $n$ and message $m$, \[
  \cS(1^n) \cind \view_\cE^{\<\cA, \cB, \cE\>}(1^n, k, m),
\]where the randomness of the second distribution is over both the randomness of
the algorithms and uniform random choice of $k$.
\end{dfn}

The point is that the eavesdropper should learn nothing from the interaction,
while the intended recipient should learn the message.

\begin{ex}
  We can construct both a secure-but-not-correct and a correct-but-not-secure
  encryption scheme using work already done.
  \begin{itemize}
    \item For a secure-but-not-correct scheme, simply have each machine do
      nothing. The security proof is exactly the same as
      in~\Cref{ex:trivial-protocol}.
    \item For a correct-but-not-secure scheme, have $\cA$ send $m$ to $\cB$ (and
      therefore also to $\cE$) as a message, and have $\cB$ output that message. The
      insecurity proof is exactly the same as in~\Cref{ex:non-zero-knowledge}.
  \end{itemize}
\end{ex}

\begin{ex}[the one-time pad]\label{ex:otp}
We now give a secure and correct shared key encryption scheme, called the
\emph{one-time pad}. Let $\{G_n\}$ be a sequence of finite additive groups\footnote{
  We also want that $\{G_n\}$ is \emph{efficiently sampleable}, so that it is
  possible to generate an element from it uniformly at random in polynomial
  time.
} such that $|G_n| = \Omega(2^n)$, for instance $G_n = \ZZ_2^n$. We work over
$\cM_n = \cK_n = G_n$. Given a message $m$ and key $k$, $\cA$ computes $c = m +
k$, which it sends to $\cB$ (and $\cE$). $\cB$ then computes $c - k$, which it
outputs.

Correctness of this scheme is immediate, as $\cB$ outputs $c - k = m + k - k =
m$. To prove security, our goal is to construct a simulator $\cS$ such that
$\cS(1^n)$ is indistinguishable from $\view_\cE(1^n, k, m) = \{1^n, m + k\}$. Because
addition by $m$ is a bijection, and $k$ is chosen uniformly at random, the
distribution $\{m + k\}$ is just a uniform random sample from $G_n$. As such, we
simply let $\cS(1^n)$ draw $g$ uniformly at random from $G_n$ and output $\{1^n,
g\}$. This is again a perfectly-secure encryption scheme, since the two
distributions are identical.

Because the security is perfect, we don't need the asymptotics, so the one-time
pad is more commonly defined on a fixed group $G$, usually $\ZZ_2^m$ for some
fixed $m$.
\end{ex}

\begin{ex}[the bootstrap one-time-pad]\label{ex:botp}
  One disadvantage of the one-time pad is that the key must be drawn from the
  same space as the message. We now show how to rectify this, assuming a
  pseudorandom generator
  (\Cref{ex:pseudorandomness})
  $\cG$ with expansion factor $p$ is available.
  The idea is to use the pseudorandom generator to expand a short
    key into a longer one.

  The protocol is as follows. We let $\cK_n = \ZZ_2^n$ and $\cM_n =
  \ZZ_2^{p(n)}$. Given a message $m\in\ZZ_2^{p(n)}$ and a key $k\in\ZZ_2^n$,
  $\cA$ first computes $\cG(k)$ to get a key $k'\in\ZZ_2^{p(n)}$. It then sends
  $c = m + k$ to $\cB$. Similarly, $\cB$ computes $k'$ and then $c - k'$, which
  it outputs. Since $\cG$ is deterministic, both $\cA$ and $\cB$ get the same
  value for $k'$, and so the protocol is correct.

  Security can be shown by a reduction to the hardness assumption entailed by
  pseudorandomness of $\cG$, but an easier route is available. By definition of
  pseudorandomness, the distributions $\{\cG(\ZZ_2^n)\}$ and $\{\ZZ_2^{p(n)}\}$
  are computationally indistinguishable. To obtain $c$ in this protocol and in
  the one-time pad, we perform the same computation on these
  distributions---merely adding the fixed message $m$. As such,
  by~\Cref{thm:ci-composition} the view of $\cE$ in this
  protocol is indistinguishable from the view of $\cE$ in the one-time pad. Now
  we obtain the desired result by security of the one-time pad and transitivity
  of indistinguishability.
\end{ex}

\subsection{Interactive Function Computation}

% TODO: cite \cite{lindell-2017}.

Suppose we are given a (potentially stochastic) series of functions \[
  f: X_1\times\cdots\times X_N\to Y_1\times\cdots\times Y_N.
\] Each such function yields the following cryptographic problem\footnote{
  Here we need to assume that there is a canonical grading on each input set, for
  instance given by the length of a bitstring, so that each $X_i$ can also be
  thought of as a sequence of sets $\cX^i_n$ in the style of
  \Cref{sec:interactive computation}.
}:
\begin{quote}
  Can $N$ parties, each given a private input $x_i\in X_i$, work together so
  that the $i$th party outputs the value $f_i(x_1,\dots,x_n)$?
\end{quote}
Here, $f_i$ is the projection $\pr_i\circ f$. In particular:

\begin{dfn}
An interactive protocol $\<\cA_1,\dots,\cA_N\>$ \emph{computes the function $f$}
if for any choice of inputs $x_1,\dots,x_N$, \[ \<\cA_1, \dots,
  \cA_N\>(x_1,\dots,x_N) = f(x_1,\dots,x_N),
\] where if $f$ is stochastic the equality should be interpreted in the
distributional sense.
\end{dfn}

\begin{ex}
  The protocol of \Cref{ex:swap} computes the function $f(x,y) = (y,x)$.
\end{ex}

On the other hand, there are several possible notions of security in this
setting, roughly following the lines discussed
in~\Cref{sec:real-ideal}.
We first consider the more straightforward semi-honest case, in which we ask
that no party should learn anything from the computation other than the value
they are intended to output.

\begin{dfn}\label{def:semi-honest-secure}
  A protocol $\<\cA_1,\dots,\cA_N\>$ \emph{securely computes the function $f$ in
  the presence of semi-honest adversaries} if it computes $f$ and it is
  zero-knowledge for each $i$th party relative to $f_i$.
\end{dfn}

\begin{ex}
  Consider the following protocol for $f(x, y, *) = (*, *, xy)$: the first two
  algorithms each send their inputs two the third, which computes and outputs the
  product. This protocol is not secure in the presence of semi-honest
  adversaries, because the third party learns the two factors, not just the
  product; this insecurity can be proved very similarly to
  \Cref{ex:non-zero-knowledge}.

  On the other hand, consider the following protocol for $f(x, y) = (*, xy)$:
  the first algorithm sends $x$ to the second, which computes and outputs the
  product. This protocol is secure in the presence of semi-honest adversaries.
  The simulator for the second algorithm, which gets its input $y$ and output
  $xy$, is responsible for producing a distribution indistinguishable from $\{x,
  y\}$; it can do this by computing $xy / y$.
\end{ex}

\begin{ex}[oblivious bit-transfer]
  The \emph{oblivious bit-transfer problem} is as follows.Alice has two
  bits $b_1,b_2\in\ZZ_2$, and Bob has a query $\sigma\in\{1,2\}$.
  The goal is for Bob to learn the appropriate bit from Alice,
  without revealing which bit they asked for. We can formalize this
  using~\Cref{def:semi-honest-secure}: the problem is to securely
  compute \[
    f: \ZZ_2^2\times \{1,2\}\to \{*\}\times\ZZ_2,\quad\quad ((b_1,b_2), \sigma) \mapsto (*, b_\sigma)
  \]in the presence of semi-honest adversaries. While the solution is outside
  our scope, this is possible (under standard complexity-theoretic assumptions)
  via a protocol originally due to~\cite{even-et-al-1985}.
\end{ex}

The situation with malicious adversaries is much more complicated. [TODO:
malicious adversaries.]

% \begin{dfn}
%   Let $f$ be an $N$-party function. The \emph{ideal protocol for computing $f$}
%   has $N$ parties $\cA_1,\dots,\cA_N$ and a \emph{trusted party} $\cT$,
%   proceeding as follows:
%   \begin{itemize}
%     \item $\cA_i$ gets $x_i$ as input and sends it to $\cT$;
%     \item $\cT$ computes $y_1,\dots,y_n = f(x_1,\dots,x_N)$ and sends $y_i$ to
%       $\cA_i$;
%     \item $\cA_i$ outputs the received value $y_i$.
%   \end{itemize}

%   The \emph{outcome of the ideal protocol} is the distribution \[
%     \ideal^\<\cA_1,\dots,\cA_N\>_f(x_1,\dots,x_N) =
%     \{\view^{\<\cA_1,\dots,\cA_N,\cT\>}_{\cA_i}(x_1,\dots,x_N): i\in\{1,\dots,N\}\}.
%   \]
% \end{dfn}


% \section{Composition}
